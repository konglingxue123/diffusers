{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录为 /home/ubunto/Project/konglx/generate/diffusers/UI\n",
      "目录修改成功 /home/ubunto/Project/konglx/generate/diffusers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 查看当前工作目录\n",
    "retval = os.getcwd()\n",
    "print(\"当前工作目录为 %s\" % retval)\n",
    "os.chdir('/home/ubunto/Project/konglx/generate/diffusers')\n",
    "\n",
    "# 查看修改后的工作目录\n",
    "retval = os.getcwd()\n",
    "\n",
    "print(\"目录修改成功 %s\" % retval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from share import *\n",
    "# import config\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# from pytorch_lightning import seed_everything\n",
    "from annotator.util import resize_image, HWC3\n",
    "from annotator.midas import MidasDetector\n",
    "# from cldm.model import create_model, load_state_dict\n",
    "# from cldm.ddim_hacked import DDIMSampler\n",
    "from diffusers import DDPMPipeline, DDIMPipeline, DDIMScheduler\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import PIL\n",
    "\n",
    "######################\n",
    "# rough深度的onnx推理准备\n",
    "import onnxruntime as ort\n",
    "\n",
    "import cv2\n",
    "from typing import Tuple, Dict, List\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "onnx_model_dir=\"/home/ubunto/Project/konglx/mono_depth/Metric3D-main/onnx/metric3d-vit-small/onnx/model.onnx\"\n",
    "\n",
    "def prepare_input(\n",
    "    rgb_image: np.ndarray, input_size: Tuple[int, int]\n",
    ") -> Tuple[Dict[str, np.ndarray], List[int]]:\n",
    "\n",
    "    h, w = rgb_image.shape[:2] # 原图尺寸\n",
    "    scale = min(input_size[0] / h, input_size[1] / w)\n",
    "    rgb = cv2.resize(\n",
    "        rgb_image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    padding = [123.675, 116.28, 103.53]\n",
    "    h, w = rgb.shape[:2]\n",
    "    pad_h = input_size[0] - h\n",
    "    pad_w = input_size[1] - w\n",
    "    pad_h_half = pad_h // 2  # h方向，每边padding的尺寸\n",
    "    pad_w_half = pad_w // 2  # w方向，每边padding的尺寸\n",
    "    rgb: np.ndarray = cv2.copyMakeBorder(\n",
    "        rgb,\n",
    "        pad_h_half,\n",
    "        pad_h - pad_h_half,\n",
    "        pad_w_half,\n",
    "        pad_w - pad_w_half,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=padding,\n",
    "    )\n",
    "    pad_info = [pad_h_half, pad_h - pad_h_half, pad_w_half, pad_w - pad_w_half]\n",
    "\n",
    "    onnx_input = {\n",
    "        # \"image\": np.ascontiguousarray(\n",
    "        \"pixel_values\": np.ascontiguousarray(\n",
    "            np.transpose(rgb, (2, 0, 1))[None], dtype=np.float32\n",
    "        ),  # 1, 3, H, W\n",
    "    }\n",
    "    return onnx_input, pad_info\n",
    "\n",
    "def onnx_inference(onnx_model_dir: str, input_image: np):\n",
    "\n",
    "    ## Dummy Test\n",
    "    B = 1\n",
    "    if \"vit\" in onnx_model_dir:\n",
    "        input_size = (616, 1064)  # [H, W]\n",
    "        if 'fp16' in onnx_model_dir:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float16)\n",
    "        else:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "    else:\n",
    "        input_size = (544, 1216)  # [H, W]\n",
    "        dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "\n",
    "    providers = [\n",
    "        (\n",
    "            \"CUDAExecutionProvider\",\n",
    "            {\"cudnn_conv_use_max_workspace\": \"0\", \"device_id\": str(0)},\n",
    "        )\n",
    "    ]\n",
    "    # providers = [(\"TensorrtExecutionProvider\", {'trt_engine_cache_enable': True, 'trt_fp16_enable': True, 'device_id': 0, 'trt_dla_enable': False})]\n",
    "    ort_session = ort.InferenceSession(onnx_model_dir, providers=providers)\n",
    "\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "    out_name = ort_session.get_outputs()[0].name\n",
    "    print(input_name, out_name, sep='\\n')\n",
    "    # outputs = ort_session.run(None, {\"image\": dummy_image})\n",
    "    outputs = ort_session.run(None, {input_name: dummy_image})\n",
    "\n",
    "    print(\n",
    "        f\"The actual output of onnxruntime session for the dummy set: outputs[0].shape={outputs[0].shape}\"\n",
    "    )\n",
    "    # input_iamge = input_image\n",
    "    # print(np.unique(input_image))\n",
    "\n",
    "    original_shape = input_image.shape[:2]\n",
    "    onnx_input, pad_info = prepare_input(input_image, input_size)  # rgb_image是原图形状[512,512], input_size = (616, 1064)\n",
    "    outputs = ort_session.run(None, onnx_input)\n",
    "    depth = outputs[0].squeeze()  # [H, W]\n",
    "    # plt.imshow(depth)\n",
    "    # Reshape the depth to the original size\n",
    "    depth = depth[\n",
    "        pad_info[0] : input_size[0] - pad_info[1],\n",
    "        pad_info[2] : input_size[1] - pad_info[3],\n",
    "    ]\n",
    "    depth = cv2.resize(\n",
    "        depth, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "    return depth\n",
    "################################\n",
    "\n",
    "\n",
    "def show_image(img, detect_resolution=512):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    input_image_np = img\n",
    "\n",
    "    rgb_image =resize_image(input_image_np, detect_resolution)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "\n",
    "    return tiff_np_uint8,tiff_pil_uint8\n",
    "\n",
    "\n",
    "inputs_np=gr.Image(type=\"numpy\")\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=show_image, \n",
    "    inputs=gr.Image(type=\"numpy\"), \n",
    "    outputs=[gr.Image(type=\"numpy\"),\n",
    "             gr.Image(type=\"pil\"),\n",
    "            ]\n",
    ")\n",
    "    \n",
    "# demo.launch(share=True)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## depth + corrosion -> 结合深度预测，应用腐蚀的mask进行腐蚀生成包含功能：\n",
    "### ** 注意此版本gradio问题，左边原图框输入图片后，在右边的绘图取先点击画笔，再点击upload，才能upload成功，否则会报错。\n",
    "### 1. 结合深度预测+现有mask，生成腐蚀 （2024.9.12完成）\n",
    "### 2. 结合深度预测+绘制mask，生成腐蚀 （2024.9.12完成）\n",
    "### 3. 结合深度预测+构件检测+绘制mask，生成腐蚀 （未完成）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录为 /home/ubunto/Project/konglx/generate/diffusers/UI\n",
      "目录修改成功 /home/ubunto/Project/konglx/generate/diffusers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rgb(0, 128, 0)']\n",
      "this is org_img: ()\n",
      "this is org_img: ()\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7fae80487eb0>\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7fae80462bb0>\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******type(im_in), im_in.shape,im:****** <class 'numpy.ndarray'> (512, 512, 3) {'background': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)}\n",
      " shape:(512, 512, 3), ndim:3, size:786432\n",
      "im: {'background': array([[[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255]],\n",
      "\n",
      "       [[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255]],\n",
      "\n",
      "       [[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 91, 109, 112, 255],\n",
      "        [ 91, 109, 112, 255],\n",
      "        [ 91, 109, 112, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[132, 119, 112, 255],\n",
      "        [133, 120, 113, 255],\n",
      "        [136, 124, 117, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]],\n",
      "\n",
      "       [[130, 117, 110, 255],\n",
      "        [132, 119, 112, 255],\n",
      "        [135, 123, 116, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]],\n",
      "\n",
      "       [[130, 117, 110, 255],\n",
      "        [132, 119, 112, 255],\n",
      "        [135, 123, 116, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255]],\n",
      "\n",
      "       [[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255]],\n",
      "\n",
      "       [[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 91, 109, 112, 255],\n",
      "        [ 91, 109, 112, 255],\n",
      "        [ 91, 109, 112, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[132, 119, 112, 255],\n",
      "        [133, 120, 113, 255],\n",
      "        [136, 124, 117, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]],\n",
      "\n",
      "       [[130, 117, 110, 255],\n",
      "        [132, 119, 112, 255],\n",
      "        [135, 123, 116, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]],\n",
      "\n",
      "       [[130, 117, 110, 255],\n",
      "        [132, 119, 112, 255],\n",
      "        [135, 123, 116, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]]], dtype=uint8)}\n",
      "im: {'background': array([[[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255]],\n",
      "\n",
      "       [[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255]],\n",
      "\n",
      "       [[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 91, 109, 112, 255],\n",
      "        [ 91, 109, 112, 255],\n",
      "        [ 91, 109, 112, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[132, 119, 112, 255],\n",
      "        [133, 120, 113, 255],\n",
      "        [136, 124, 117, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]],\n",
      "\n",
      "       [[130, 117, 110, 255],\n",
      "        [132, 119, 112, 255],\n",
      "        [135, 123, 116, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]],\n",
      "\n",
      "       [[130, 117, 110, 255],\n",
      "        [132, 119, 112, 255],\n",
      "        [135, 123, 116, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255]],\n",
      "\n",
      "       [[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255],\n",
      "        [ 90, 107, 111, 255]],\n",
      "\n",
      "       [[100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        [100, 114, 113, 255],\n",
      "        ...,\n",
      "        [ 91, 109, 112, 255],\n",
      "        [ 91, 109, 112, 255],\n",
      "        [ 91, 109, 112, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[132, 119, 112, 255],\n",
      "        [133, 120, 113, 255],\n",
      "        [136, 124, 117, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]],\n",
      "\n",
      "       [[130, 117, 110, 255],\n",
      "        [132, 119, 112, 255],\n",
      "        [135, 123, 116, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]],\n",
      "\n",
      "       [[130, 117, 110, 255],\n",
      "        [132, 119, 112, 255],\n",
      "        [135, 123, 116, 255],\n",
      "        ...,\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255],\n",
      "        [149, 125,  90, 255]]], dtype=uint8)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.23it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.25it/s]\n"
     ]
    }
   ],
   "source": [
    "## 这个只有绘制腐蚀和腐蚀贴图\n",
    "# from share import *\n",
    "# import config\n",
    "import imgviz\n",
    "import os\n",
    "# 查看当前工作目录\n",
    "retval = os.getcwd()\n",
    "print(\"当前工作目录为 %s\" % retval)\n",
    "os.chdir('/home/ubunto/Project/konglx/generate/diffusers')\n",
    "\n",
    "# 查看修改后的工作目录\n",
    "retval = os.getcwd()\n",
    "\n",
    "print(\"目录修改成功 %s\" % retval)\n",
    "\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# from pytorch_lightning import seed_everything\n",
    "from annotator.util import resize_image, HWC3\n",
    "from annotator.midas import MidasDetector\n",
    "# from cldm.model import create_model, load_state_dict\n",
    "# from cldm.ddim_hacked import DDIMSampler\n",
    "from diffusers import DDPMPipeline, DDIMPipeline, DDIMScheduler, DDPMScheduler\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import PIL\n",
    "\n",
    "######################\n",
    "# rough深度的onnx推理准备\n",
    "import onnxruntime as ort\n",
    "\n",
    "import cv2\n",
    "from typing import Tuple, Dict, List\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "onnx_model_dir=\"/home/ubunto/Project/konglx/mono_depth/Metric3D-main/onnx/metric3d-vit-small/onnx/model.onnx\"\n",
    "\n",
    "def prepare_input(\n",
    "    rgb_image: np.ndarray, input_size: Tuple[int, int]\n",
    ") -> Tuple[Dict[str, np.ndarray], List[int]]:\n",
    "\n",
    "    h, w = rgb_image.shape[:2] # 原图尺寸\n",
    "    scale = min(input_size[0] / h, input_size[1] / w)\n",
    "    rgb = cv2.resize(\n",
    "        rgb_image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    padding = [123.675, 116.28, 103.53]\n",
    "    h, w = rgb.shape[:2]\n",
    "    pad_h = input_size[0] - h\n",
    "    pad_w = input_size[1] - w\n",
    "    pad_h_half = pad_h // 2  # h方向，每边padding的尺寸\n",
    "    pad_w_half = pad_w // 2  # w方向，每边padding的尺寸\n",
    "    rgb: np.ndarray = cv2.copyMakeBorder(\n",
    "        rgb,\n",
    "        pad_h_half,\n",
    "        pad_h - pad_h_half,\n",
    "        pad_w_half,\n",
    "        pad_w - pad_w_half,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=padding,\n",
    "    )\n",
    "    pad_info = [pad_h_half, pad_h - pad_h_half, pad_w_half, pad_w - pad_w_half]\n",
    "\n",
    "    onnx_input = {\n",
    "        # \"image\": np.ascontiguousarray(\n",
    "        \"pixel_values\": np.ascontiguousarray(\n",
    "            np.transpose(rgb, (2, 0, 1))[None], dtype=np.float32\n",
    "        ),  # 1, 3, H, W\n",
    "    }\n",
    "    return onnx_input, pad_info\n",
    "\n",
    "def onnx_inference(onnx_model_dir: str, input_image: np):\n",
    "\n",
    "    ## Dummy Test\n",
    "    B = 1\n",
    "    if \"vit\" in onnx_model_dir:\n",
    "        input_size = (616, 1064)  # [H, W]\n",
    "        if 'fp16' in onnx_model_dir:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float16)\n",
    "        else:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "    else:\n",
    "        input_size = (544, 1216)  # [H, W]\n",
    "        dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "\n",
    "    providers = [\n",
    "        (\n",
    "            \"CUDAExecutionProvider\",\n",
    "            {\"cudnn_conv_use_max_workspace\": \"0\", \"device_id\": str(0)},\n",
    "        )\n",
    "    ]\n",
    "    # providers = [(\"TensorrtExecutionProvider\", {'trt_engine_cache_enable': True, 'trt_fp16_enable': True, 'device_id': 0, 'trt_dla_enable': False})]\n",
    "    ort_session = ort.InferenceSession(onnx_model_dir, providers=providers)\n",
    "\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "    out_name = ort_session.get_outputs()[0].name\n",
    "    print(input_name, out_name, sep='\\n')\n",
    "    # outputs = ort_session.run(None, {\"image\": dummy_image})\n",
    "    outputs = ort_session.run(None, {input_name: dummy_image})\n",
    "\n",
    "    print(\n",
    "        f\"The actual output of onnxruntime session for the dummy set: outputs[0].shape={outputs[0].shape}\"\n",
    "    )\n",
    "    # input_iamge = input_image\n",
    "    # print(np.unique(input_image))\n",
    "\n",
    "    original_shape = input_image.shape[:2]\n",
    "    onnx_input, pad_info = prepare_input(input_image, input_size)  # rgb_image是原图形状[512,512], input_size = (616, 1064)\n",
    "    outputs = ort_session.run(None, onnx_input)\n",
    "    depth = outputs[0].squeeze()  # [H, W]\n",
    "    # plt.imshow(depth)\n",
    "    # Reshape the depth to the original size\n",
    "    depth = depth[\n",
    "        pad_info[0] : input_size[0] - pad_info[1],\n",
    "        pad_info[2] : input_size[1] - pad_info[3],\n",
    "    ]\n",
    "    depth = cv2.resize(\n",
    "        depth, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "    return depth\n",
    "################################\n",
    "\n",
    "######################\n",
    "#  controlnet模型准备\n",
    "def controlnet_diff(corrosion_with_bg_pil, mask_depth_pil, prompt = '',device = 'cuda',seed = 2024,use_freeu = False,controlnet_conditioning_scale_list=[1.0,1.0],\n",
    "                    config_dir = '/home/ubunto/Project/konglx/generate/ControlNet/models/stable-diffusion-v1-5',\n",
    "                    control_corrosion_with_bg_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_corrosion_with_background_merge_inpainting_h-512_w-512_2024-07-29_13:19:18_seeds-2024/checkpoint-5700/controlnet',\n",
    "                    control_depth_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_depth_h-512_w-512_2024-07-16_17:42:27_seeds-2024/checkpoint-2000/controlnet',\n",
    "                    scheduler_select = 'PNDM',\n",
    "                    inference_steps=20,\n",
    "                    guidance_scale=7.5,\n",
    "                    ):\n",
    "    with torch.no_grad():\n",
    "        print('scheduler_select:', scheduler_select)\n",
    "        controlnet_corrosion_with_bg = ControlNetModel.from_pretrained(control_corrosion_with_bg_trained_dir)\n",
    "        controlnet_depth = ControlNetModel.from_pretrained(control_depth_trained_dir)\n",
    "        if scheduler_select == 'PNDM' or scheduler_select == None:\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None).to(device)\n",
    "        elif scheduler_select == 'DDPM':\n",
    "            # scheduler DDPM\n",
    "            scheduler = DDPMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        elif scheduler_select == 'DDIM':\n",
    "            # scheduler DDIM\n",
    "            scheduler = DDIMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "        pipeline.unet.use_freeu = use_freeu \n",
    "        \n",
    "\n",
    "        mask_corrosion_with_bg_pil = load_image(corrosion_with_bg_pil)\n",
    "        mask_depth_pil = load_image(mask_depth_pil)\n",
    "        validation_image = [mask_corrosion_with_bg_pil, mask_depth_pil]\n",
    "        image = pipeline(prompt, validation_image, num_inference_steps=inference_steps, generator=generator, controlnet_conditioning_scale=controlnet_conditioning_scale_list,\n",
    "                        guidance_scale=guidance_scale,\n",
    "                            ).images[0]\n",
    "    torch.cuda.empty_cache()\n",
    "    return image\n",
    "#######################\n",
    "\n",
    "################################\n",
    "# gradio的功能接口定义\n",
    "def show_image(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "\n",
    "def show_image_draw(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img['composite']\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "# 绘图\n",
    "def create_canvas(w, h):\n",
    "    return np.zeros(shape=(h, w, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "brush_colors = gr.Brush()\n",
    "# brush_colors.colors=[\n",
    "#                 \"rgb(128, 0, 0)\", # fair\n",
    "#                 \"rgb(0, 128, 0)\", # poor\n",
    "#                 \"rgb(128, 128, 0)\",] # severe\n",
    "brush_colors.colors=[\n",
    "                \"rgb(0, 128, 0)\", # poor\n",
    "                # \"rgb(128, 0, 0)\", # fair\n",
    "                # \"rgb(128, 128, 0)\",\n",
    "                ] # severe\n",
    "\n",
    "# brush_colors.colors=[\n",
    "                \n",
    "#                 \"rgb(128, 128, 0)\",\"rgb(0, 128, 0)\",\"rgb(128, 0, 0)\",]\n",
    "# print()\n",
    "print(brush_colors.colors\n",
    "                # format=\"png\",\n",
    "                )\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "\n",
    "\n",
    "def sleep(im):\n",
    "    # # time.sleep(5)\n",
    "    # # return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1],im[\"composite\"]]\n",
    "    # return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    "    print('im:', im)\n",
    "    if len(im[\"layers\"]) == 0:\n",
    "        im[\"layers\"].append(np.zeros((512, 512, 4), np.uint8))\n",
    "    # im[\"layers\"][0]=cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB )\n",
    "    return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    " \n",
    "def upim(im_in,im):\n",
    "    print('******type(im_in), im_in.shape,im:******', type(im_in), im_in.shape,im)#, type(im), im)\n",
    "    height, width, channels = im_in.shape[:3]\n",
    "    im[\"background\"]=im_in\n",
    "    im[\"layers\"][0]=np.zeros((height, width, 4), np.uint8)\n",
    "    #im[\"layers\"][1]=None\n",
    "\n",
    "    print(f\" shape:{im_in.shape}, ndim:{im_in.ndim}, size:{im_in.size}\")\n",
    "    return gr.ImageMask(value=im,height=600,width=600)\n",
    "\n",
    "\n",
    "def saveimg(im):\n",
    "    #print(im[\"layers\"][0])\n",
    "    background=im[\"background\"]\n",
    "    composite=im[\"composite\"]\n",
    "    background=cv2.cvtColor(background, cv2.COLOR_BGR2RGB )\n",
    "    composite=cv2.cvtColor(composite, cv2.COLOR_BGR2RGB )\n",
    "    img_layer = cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"layers0.png\",img_layer)\n",
    "    cv2.imwrite(\"background.png\",background)\n",
    "    cv2.imwrite(\"composite.png\",composite)\n",
    "    return gr.ImageMask(value=im,height=600,width=600), background\n",
    "\n",
    "# inputs_np=gr.Image(type=\"numpy\")\n",
    "\n",
    "CACHE_EXAMPLES = torch.cuda.is_available() and os.getenv(\"CACHE_EXAMPLES\", \"0\") == \"1\"\n",
    "org_img_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/images/00003.jpg'\n",
    "masked_corrosion_with_bg_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/conditioning_images/00003.png'\n",
    "examples = [ [load_image(org_img_dir)]]\n",
    "examples_mask = [[load_image(masked_corrosion_with_bg_dir)]]\n",
    "\n",
    "MCD = gr.Blocks(title=\"Multi-Control corrosion generator\").queue()\n",
    "with MCD:\n",
    "    gr.Markdown('Multi-Control corrosion generator')\n",
    "    ###################################################  Tab 1  ###################################################\n",
    "\n",
    "    with gr.Tab('Draw corrosion images'):\n",
    "        # with gr.Blocks():\n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_img = gr.Image(type=\"numpy\", label=\"Original Image Tab 1\")\n",
    "                print('this is org_img:', np.array(org_img).shape)\n",
    "                \n",
    "                im = gr.ImageEditor(\n",
    "                    type=\"numpy\",\n",
    "                    crop_size=\"1:1\",\n",
    "                    height=512,\n",
    "                    width=512,\n",
    "                    brush=brush_colors,\n",
    "                    label='Draw',\n",
    "                    canvas_size=(512, 512),\n",
    "                    sources='upload',\n",
    "                )\n",
    "        \n",
    "        with gr.Row():\n",
    "            \n",
    "            uploadbtn = gr.Button(\"image upload\")\n",
    "            savebtn = gr.Button(\"save\")\n",
    "            print('this is org_img:', np.array(org_img).shape)\n",
    "            uploadbtn.click(upim,[org_img,im],[im])\n",
    "        \n",
    "        \n",
    "        # im =gr.Sketchpad(type=\"pil\",\n",
    "        #     crop_size=\"1:1\",)\n",
    "    \n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                im_out_1 = gr.Image(type=\"numpy\", label='background')\n",
    "                im_out_2 = gr.Image(type=\"numpy\", label='mask')\n",
    "                im_out_3 = gr.Image(type=\"numpy\", label='mask with background')\n",
    "                # im_out_4 = gr.Image(type=\"numpy\")\n",
    "        # btn = gr.Button()\n",
    "        im.change(sleep, outputs=[im_out_1, im_out_2, im_out_3], inputs=im)\n",
    "        savebtn.click(saveimg, outputs=[im, im_out_2], inputs=im)\n",
    "        # btn = gr.Button()\n",
    "\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "        #         org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "        #         ##\n",
    "        #         draw = gr.ImageEditor(label='Draw corrosion', type=\"numpy\")#,height=image_resolution, width=image_resolution)\n",
    "        #         print(draw, type(draw))\n",
    "\n",
    "                \n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "    # with gr.Tab('Use test images'):\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "                # org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_img, im, prompt, image_resolution, scheduler_select, inference_steps,scale, seed]\n",
    "        run_button.click(fn=show_image_draw, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=org_img,\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image_draw,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                # gr.Examples(\n",
    "                # label='Example: Masked corrosion with background',\n",
    "                # examples=examples_mask,\n",
    "                # inputs=inputs[1],\n",
    "                # outputs=[result_gallery_depth],\n",
    "                # fn=show_image,\n",
    "                # cache_examples=CACHE_EXAMPLES,\n",
    "                # )\n",
    "   ###################################################  Tab 2  ###################################################           \n",
    "    with gr.Tab('Use test images'):\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_image_pil = gr.Image(type=\"numpy\", label='Original Image Tab 2')\n",
    "                masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_image_pil, masked_corrosion_with_bg_pil, prompt, image_resolution, scheduler_select, inference_steps,scale, seed]\n",
    "        run_button.click(fn=show_image, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=inputs[0],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Masked corrosion with background',\n",
    "                examples=examples_mask,\n",
    "                inputs=inputs[1],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "        ###################################################  Tab 3  ###################################################           \n",
    "    with gr.Tab('Find members then draw corrosion images'):\n",
    "         # with gr.Blocks():\n",
    "        with gr.Group():\n",
    "            with gr.Row():\n",
    "                org_img = gr.Image(type=\"numpy\", label=\"Original Image Tab 3\")\n",
    "# MCD.launch(share=True)\n",
    "MCD.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录为 /home/ubunto/Project/konglx/generate/diffusers/UI\n",
      "目录修改成功 /home/ubunto/Project/konglx/generate/diffusers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rgb(128, 128, 0)', 'rgb(0, 128, 0)', 'rgb(128, 0, 0)']\n",
      "this is org_img: ()\n",
      "this is org_img: ()\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7f7d436c3f10>\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7f7d43663070>\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******type(im_in), im_in.shape,im:****** <class 'numpy.ndarray'> (512, 512, 3) {'background': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)}\n",
      " shape:(512, 512, 3), ndim:3, size:786432\n",
      "im: {'background': array([[[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        ...,\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[122, 120, 103, 255],\n",
      "        [124, 123, 105, 255],\n",
      "        [129, 127, 110, 255],\n",
      "        ...,\n",
      "        [ 88,  91,  86, 255],\n",
      "        [ 87,  90,  84, 255],\n",
      "        [ 85,  88,  82, 255]],\n",
      "\n",
      "       [[118, 117,  99, 255],\n",
      "        [130, 128, 111, 255],\n",
      "        [141, 139, 121, 255],\n",
      "        ...,\n",
      "        [ 93,  96,  90, 255],\n",
      "        [ 92,  95,  89, 255],\n",
      "        [ 90,  94,  88, 255]],\n",
      "\n",
      "       [[125, 124, 106, 255],\n",
      "        [137, 135, 118, 255],\n",
      "        [142, 140, 122, 255],\n",
      "        ...,\n",
      "        [103, 106, 101, 255],\n",
      "        [102, 105, 100, 255],\n",
      "        [101, 104,  98, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        ...,\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[122, 120, 103, 255],\n",
      "        [124, 123, 105, 255],\n",
      "        [129, 127, 110, 255],\n",
      "        ...,\n",
      "        [ 88,  91,  86, 255],\n",
      "        [ 87,  90,  84, 255],\n",
      "        [ 85,  88,  82, 255]],\n",
      "\n",
      "       [[118, 117,  99, 255],\n",
      "        [130, 128, 111, 255],\n",
      "        [141, 139, 121, 255],\n",
      "        ...,\n",
      "        [ 93,  96,  90, 255],\n",
      "        [ 92,  95,  89, 255],\n",
      "        [ 90,  94,  88, 255]],\n",
      "\n",
      "       [[125, 124, 106, 255],\n",
      "        [137, 135, 118, 255],\n",
      "        [142, 140, 122, 255],\n",
      "        ...,\n",
      "        [103, 106, 101, 255],\n",
      "        [102, 105, 100, 255],\n",
      "        [101, 104,  98, 255]]], dtype=uint8)}\n",
      "im: {'background': array([[[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        ...,\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[122, 120, 103, 255],\n",
      "        [124, 123, 105, 255],\n",
      "        [129, 127, 110, 255],\n",
      "        ...,\n",
      "        [ 88,  91,  86, 255],\n",
      "        [ 87,  90,  84, 255],\n",
      "        [ 85,  88,  82, 255]],\n",
      "\n",
      "       [[118, 117,  99, 255],\n",
      "        [130, 128, 111, 255],\n",
      "        [141, 139, 121, 255],\n",
      "        ...,\n",
      "        [ 93,  96,  90, 255],\n",
      "        [ 92,  95,  89, 255],\n",
      "        [ 90,  94,  88, 255]],\n",
      "\n",
      "       [[125, 124, 106, 255],\n",
      "        [137, 135, 118, 255],\n",
      "        [142, 140, 122, 255],\n",
      "        ...,\n",
      "        [103, 106, 101, 255],\n",
      "        [102, 105, 100, 255],\n",
      "        [101, 104,  98, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        ...,\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[122, 120, 103, 255],\n",
      "        [124, 123, 105, 255],\n",
      "        [129, 127, 110, 255],\n",
      "        ...,\n",
      "        [ 88,  91,  86, 255],\n",
      "        [ 87,  90,  84, 255],\n",
      "        [ 85,  88,  82, 255]],\n",
      "\n",
      "       [[118, 117,  99, 255],\n",
      "        [130, 128, 111, 255],\n",
      "        [141, 139, 121, 255],\n",
      "        ...,\n",
      "        [ 93,  96,  90, 255],\n",
      "        [ 92,  95,  89, 255],\n",
      "        [ 90,  94,  88, 255]],\n",
      "\n",
      "       [[125, 124, 106, 255],\n",
      "        [137, 135, 118, 255],\n",
      "        [142, 140, 122, 255],\n",
      "        ...,\n",
      "        [103, 106, 101, 255],\n",
      "        [102, 105, 100, 255],\n",
      "        [101, 104,  98, 255]]], dtype=uint8)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  4.52it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im: {'background': array([[[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        ...,\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[122, 120, 103, 255],\n",
      "        [124, 123, 105, 255],\n",
      "        [129, 127, 110, 255],\n",
      "        ...,\n",
      "        [ 88,  91,  86, 255],\n",
      "        [ 87,  90,  84, 255],\n",
      "        [ 85,  88,  82, 255]],\n",
      "\n",
      "       [[118, 117,  99, 255],\n",
      "        [130, 128, 111, 255],\n",
      "        [141, 139, 121, 255],\n",
      "        ...,\n",
      "        [ 93,  96,  90, 255],\n",
      "        [ 92,  95,  89, 255],\n",
      "        [ 90,  94,  88, 255]],\n",
      "\n",
      "       [[125, 124, 106, 255],\n",
      "        [137, 135, 118, 255],\n",
      "        [142, 140, 122, 255],\n",
      "        ...,\n",
      "        [103, 106, 101, 255],\n",
      "        [102, 105, 100, 255],\n",
      "        [101, 104,  98, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        ...,\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[122, 120, 103, 255],\n",
      "        [124, 123, 105, 255],\n",
      "        [129, 127, 110, 255],\n",
      "        ...,\n",
      "        [ 88,  91,  86, 255],\n",
      "        [ 87,  90,  84, 255],\n",
      "        [ 85,  88,  82, 255]],\n",
      "\n",
      "       [[118, 117,  99, 255],\n",
      "        [130, 128, 111, 255],\n",
      "        [141, 139, 121, 255],\n",
      "        ...,\n",
      "        [ 93,  96,  90, 255],\n",
      "        [ 92,  95,  89, 255],\n",
      "        [ 90,  94,  88, 255]],\n",
      "\n",
      "       [[125, 124, 106, 255],\n",
      "        [137, 135, 118, 255],\n",
      "        [142, 140, 122, 255],\n",
      "        ...,\n",
      "        [103, 106, 101, 255],\n",
      "        [102, 105, 100, 255],\n",
      "        [101, 104,  98, 255]]], dtype=uint8)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: DDPM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.44it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.66it/s]\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: DDIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  4.15it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******type(im_in), im_in.shape,im:****** <class 'numpy.ndarray'> (512, 512, 3) {'background': array([[[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        ...,\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[122, 120, 103, 255],\n",
      "        [124, 123, 105, 255],\n",
      "        [129, 127, 110, 255],\n",
      "        ...,\n",
      "        [ 88,  91,  86, 255],\n",
      "        [ 87,  90,  84, 255],\n",
      "        [ 85,  88,  82, 255]],\n",
      "\n",
      "       [[118, 117,  99, 255],\n",
      "        [130, 128, 111, 255],\n",
      "        [141, 139, 121, 255],\n",
      "        ...,\n",
      "        [ 93,  96,  90, 255],\n",
      "        [ 92,  95,  89, 255],\n",
      "        [ 90,  94,  88, 255]],\n",
      "\n",
      "       [[125, 124, 106, 255],\n",
      "        [137, 135, 118, 255],\n",
      "        [142, 140, 122, 255],\n",
      "        ...,\n",
      "        [103, 106, 101, 255],\n",
      "        [102, 105, 100, 255],\n",
      "        [101, 104,  98, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        [ 23,  39,  25, 255],\n",
      "        ...,\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255],\n",
      "        [ 45,  71,  46, 255]],\n",
      "\n",
      "       [[ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        [ 24,  40,  26, 255],\n",
      "        ...,\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255],\n",
      "        [ 46,  73,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[122, 120, 103, 255],\n",
      "        [124, 123, 105, 255],\n",
      "        [129, 127, 110, 255],\n",
      "        ...,\n",
      "        [ 88,  91,  86, 255],\n",
      "        [ 87,  90,  84, 255],\n",
      "        [ 85,  88,  82, 255]],\n",
      "\n",
      "       [[118, 117,  99, 255],\n",
      "        [130, 128, 111, 255],\n",
      "        [141, 139, 121, 255],\n",
      "        ...,\n",
      "        [ 93,  96,  90, 255],\n",
      "        [ 92,  95,  89, 255],\n",
      "        [ 90,  94,  88, 255]],\n",
      "\n",
      "       [[125, 124, 106, 255],\n",
      "        [137, 135, 118, 255],\n",
      "        [142, 140, 122, 255],\n",
      "        ...,\n",
      "        [103, 106, 101, 255],\n",
      "        [102, 105, 100, 255],\n",
      "        [101, 104,  98, 255]]], dtype=uint8)}\n",
      " shape:(512, 512, 3), ndim:3, size:786432\n",
      "im: {'background': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8)}\n",
      "im: {'background': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: DDIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.96it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.77it/s]\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: PSNR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.26it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im: {'background': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: PSNR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.34it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.21it/s]\n"
     ]
    }
   ],
   "source": [
    "## 这个只有绘制腐蚀和腐蚀贴图\n",
    "# from share import *\n",
    "# import config\n",
    "import imgviz\n",
    "import os\n",
    "# 查看当前工作目录\n",
    "retval = os.getcwd()\n",
    "print(\"当前工作目录为 %s\" % retval)\n",
    "os.chdir('/home/ubunto/Project/konglx/generate/diffusers')\n",
    "\n",
    "# 查看修改后的工作目录\n",
    "retval = os.getcwd()\n",
    "\n",
    "print(\"目录修改成功 %s\" % retval)\n",
    "\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# from pytorch_lightning import seed_everything\n",
    "from annotator.util import resize_image, HWC3\n",
    "from annotator.midas import MidasDetector\n",
    "# from cldm.model import create_model, load_state_dict\n",
    "# from cldm.ddim_hacked import DDIMSampler\n",
    "from diffusers import DDPMPipeline, DDIMPipeline, DDIMScheduler, DDPMScheduler\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import PIL\n",
    "\n",
    "######################\n",
    "# rough深度的onnx推理准备\n",
    "import onnxruntime as ort\n",
    "\n",
    "import cv2\n",
    "from typing import Tuple, Dict, List\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "onnx_model_dir=\"/home/ubunto/Project/konglx/mono_depth/Metric3D-main/onnx/metric3d-vit-small/onnx/model.onnx\"\n",
    "\n",
    "def prepare_input(\n",
    "    rgb_image: np.ndarray, input_size: Tuple[int, int]\n",
    ") -> Tuple[Dict[str, np.ndarray], List[int]]:\n",
    "\n",
    "    h, w = rgb_image.shape[:2] # 原图尺寸\n",
    "    scale = min(input_size[0] / h, input_size[1] / w)\n",
    "    rgb = cv2.resize(\n",
    "        rgb_image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    padding = [123.675, 116.28, 103.53]\n",
    "    h, w = rgb.shape[:2]\n",
    "    pad_h = input_size[0] - h\n",
    "    pad_w = input_size[1] - w\n",
    "    pad_h_half = pad_h // 2  # h方向，每边padding的尺寸\n",
    "    pad_w_half = pad_w // 2  # w方向，每边padding的尺寸\n",
    "    rgb: np.ndarray = cv2.copyMakeBorder(\n",
    "        rgb,\n",
    "        pad_h_half,\n",
    "        pad_h - pad_h_half,\n",
    "        pad_w_half,\n",
    "        pad_w - pad_w_half,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=padding,\n",
    "    )\n",
    "    pad_info = [pad_h_half, pad_h - pad_h_half, pad_w_half, pad_w - pad_w_half]\n",
    "\n",
    "    onnx_input = {\n",
    "        # \"image\": np.ascontiguousarray(\n",
    "        \"pixel_values\": np.ascontiguousarray(\n",
    "            np.transpose(rgb, (2, 0, 1))[None], dtype=np.float32\n",
    "        ),  # 1, 3, H, W\n",
    "    }\n",
    "    return onnx_input, pad_info\n",
    "\n",
    "def onnx_inference(onnx_model_dir: str, input_image: np):\n",
    "\n",
    "    ## Dummy Test\n",
    "    B = 1\n",
    "    if \"vit\" in onnx_model_dir:\n",
    "        input_size = (616, 1064)  # [H, W]\n",
    "        if 'fp16' in onnx_model_dir:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float16)\n",
    "        else:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "    else:\n",
    "        input_size = (544, 1216)  # [H, W]\n",
    "        dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "\n",
    "    providers = [\n",
    "        (\n",
    "            \"CUDAExecutionProvider\",\n",
    "            {\"cudnn_conv_use_max_workspace\": \"0\", \"device_id\": str(0)},\n",
    "        )\n",
    "    ]\n",
    "    # providers = [(\"TensorrtExecutionProvider\", {'trt_engine_cache_enable': True, 'trt_fp16_enable': True, 'device_id': 0, 'trt_dla_enable': False})]\n",
    "    ort_session = ort.InferenceSession(onnx_model_dir, providers=providers)\n",
    "\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "    out_name = ort_session.get_outputs()[0].name\n",
    "    print(input_name, out_name, sep='\\n')\n",
    "    # outputs = ort_session.run(None, {\"image\": dummy_image})\n",
    "    outputs = ort_session.run(None, {input_name: dummy_image})\n",
    "\n",
    "    print(\n",
    "        f\"The actual output of onnxruntime session for the dummy set: outputs[0].shape={outputs[0].shape}\"\n",
    "    )\n",
    "    # input_iamge = input_image\n",
    "    # print(np.unique(input_image))\n",
    "\n",
    "    original_shape = input_image.shape[:2]\n",
    "    onnx_input, pad_info = prepare_input(input_image, input_size)  # rgb_image是原图形状[512,512], input_size = (616, 1064)\n",
    "    outputs = ort_session.run(None, onnx_input)\n",
    "    depth = outputs[0].squeeze()  # [H, W]\n",
    "    # plt.imshow(depth)\n",
    "    # Reshape the depth to the original size\n",
    "    depth = depth[\n",
    "        pad_info[0] : input_size[0] - pad_info[1],\n",
    "        pad_info[2] : input_size[1] - pad_info[3],\n",
    "    ]\n",
    "    depth = cv2.resize(\n",
    "        depth, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "    return depth\n",
    "################################\n",
    "\n",
    "######################\n",
    "#  controlnet模型准备\n",
    "def controlnet_diff(corrosion_with_bg_pil, mask_depth_pil, prompt = '',device = 'cuda',seed = 2024,use_freeu = False,controlnet_conditioning_scale_list=[1.0,1.0],\n",
    "                    config_dir = '/home/ubunto/Project/konglx/generate/ControlNet/models/stable-diffusion-v1-5',\n",
    "                    control_corrosion_with_bg_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_corrosion_with_background_merge_inpainting_h-512_w-512_2024-07-29_13:19:18_seeds-2024/checkpoint-5700/controlnet',\n",
    "                    control_depth_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_depth_h-512_w-512_2024-07-16_17:42:27_seeds-2024/checkpoint-2000/controlnet',\n",
    "                    scheduler_select = 'PNDM',\n",
    "                    inference_steps=20,\n",
    "                    guidance_scale=7.5,\n",
    "                    ):\n",
    "    with torch.no_grad():\n",
    "        print('scheduler_select:', scheduler_select)\n",
    "        controlnet_corrosion_with_bg = ControlNetModel.from_pretrained(control_corrosion_with_bg_trained_dir)\n",
    "        controlnet_depth = ControlNetModel.from_pretrained(control_depth_trained_dir)\n",
    "        if scheduler_select == 'PNDM' or scheduler_select == None:\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None).to(device)\n",
    "        elif scheduler_select == 'DDPM':\n",
    "            # scheduler DDPM\n",
    "            scheduler = DDPMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        elif scheduler_select == 'DDIM':\n",
    "            # scheduler DDIM\n",
    "            scheduler = DDIMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "        pipeline.unet.use_freeu = use_freeu \n",
    "        \n",
    "\n",
    "        mask_corrosion_with_bg_pil = load_image(corrosion_with_bg_pil)\n",
    "        mask_depth_pil = load_image(mask_depth_pil)\n",
    "        validation_image = [mask_corrosion_with_bg_pil, mask_depth_pil]\n",
    "        image = pipeline(prompt, validation_image, num_inference_steps=inference_steps, generator=generator, controlnet_conditioning_scale=controlnet_conditioning_scale_list,\n",
    "                        guidance_scale=guidance_scale,\n",
    "                            ).images[0]\n",
    "    torch.cuda.empty_cache()\n",
    "    return image\n",
    "#######################\n",
    "\n",
    "################################\n",
    "# gradio的功能接口定义\n",
    "def show_image(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "\n",
    "def show_image_draw(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img['composite']\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "# 绘图\n",
    "def create_canvas(w, h):\n",
    "    return np.zeros(shape=(h, w, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "brush_colors = gr.Brush()\n",
    "# brush_colors.colors=[\n",
    "#                 \"rgb(128, 0, 0)\", # fair\n",
    "#                 \"rgb(0, 128, 0)\", # poor\n",
    "#                 \"rgb(128, 128, 0)\",] # severe\n",
    "# brush_colors.colors=[\n",
    "#                 \"rgb(0, 128, 0)\", # poor\n",
    "#                 \"rgb(128, 0, 0)\", # fair\n",
    "#                 \"rgb(128, 128, 0)\",] # severe\n",
    "\n",
    "brush_colors.colors=[\n",
    "                \n",
    "                \"rgb(128, 128, 0)\",\"rgb(0, 128, 0)\",\"rgb(128, 0, 0)\",]\n",
    "# print()\n",
    "print(brush_colors.colors\n",
    "                # format=\"png\",\n",
    "                )\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "\n",
    "\n",
    "def sleep(im):\n",
    "    # # time.sleep(5)\n",
    "    # # return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1],im[\"composite\"]]\n",
    "    # return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    "    print('im:', im)\n",
    "    if len(im[\"layers\"]) == 0:\n",
    "        im[\"layers\"].append(np.zeros((512, 512, 4), np.uint8))\n",
    "    # im[\"layers\"][0]=cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB )\n",
    "    return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    " \n",
    "def upim(im_in,im):\n",
    "    print('******type(im_in), im_in.shape,im:******', type(im_in), im_in.shape,im)#, type(im), im)\n",
    "    height, width, channels = im_in.shape[:3]\n",
    "    im[\"background\"]=im_in\n",
    "    im[\"layers\"][0]=np.zeros((height, width, 4), np.uint8)\n",
    "    #im[\"layers\"][1]=None\n",
    "\n",
    "    print(f\" shape:{im_in.shape}, ndim:{im_in.ndim}, size:{im_in.size}\")\n",
    "    return gr.ImageMask(value=im,height=600,width=600)\n",
    "\n",
    "\n",
    "def saveimg(im):\n",
    "    #print(im[\"layers\"][0])\n",
    "    background=im[\"background\"]\n",
    "    composite=im[\"composite\"]\n",
    "    background=cv2.cvtColor(background, cv2.COLOR_BGR2RGB )\n",
    "    composite=cv2.cvtColor(composite, cv2.COLOR_BGR2RGB )\n",
    "    img_layer = cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"layers0.png\",img_layer)\n",
    "    cv2.imwrite(\"background.png\",background)\n",
    "    cv2.imwrite(\"composite.png\",composite)\n",
    "    return gr.ImageMask(value=im,height=600,width=600), background\n",
    "\n",
    "# inputs_np=gr.Image(type=\"numpy\")\n",
    "\n",
    "CACHE_EXAMPLES = torch.cuda.is_available() and os.getenv(\"CACHE_EXAMPLES\", \"0\") == \"1\"\n",
    "org_img_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/images/00003.jpg'\n",
    "masked_corrosion_with_bg_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/conditioning_images/00003.png'\n",
    "examples = [ [load_image(org_img_dir)]]\n",
    "examples_mask = [[load_image(masked_corrosion_with_bg_dir)]]\n",
    "\n",
    "MCD = gr.Blocks(title=\"Multi-Control corrosion generator\").queue()\n",
    "with MCD:\n",
    "    gr.Markdown('Multi-Control corrosion generator')\n",
    "    ###################################################  Tab 1  ###################################################\n",
    "\n",
    "    with gr.Tab('Draw corrosion images'):\n",
    "        # with gr.Blocks():\n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_img = gr.Image(type=\"numpy\", label=\"Original Image Tab 1\")\n",
    "                print('this is org_img:', np.array(org_img).shape)\n",
    "                \n",
    "                im = gr.ImageEditor(\n",
    "                    type=\"numpy\",\n",
    "                    crop_size=\"1:1\",\n",
    "                    height=512,\n",
    "                    width=512,\n",
    "                    brush=brush_colors,\n",
    "                    label='Draw',\n",
    "                    canvas_size=(512, 512),\n",
    "                    sources='upload',\n",
    "                )\n",
    "        \n",
    "        with gr.Row():\n",
    "            \n",
    "            uploadbtn = gr.Button(\"image upload\")\n",
    "            savebtn = gr.Button(\"save\")\n",
    "            print('this is org_img:', np.array(org_img).shape)\n",
    "            uploadbtn.click(upim,[org_img,im],[im])\n",
    "        \n",
    "        \n",
    "        # im =gr.Sketchpad(type=\"pil\",\n",
    "        #     crop_size=\"1:1\",)\n",
    "    \n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                im_out_1 = gr.Image(type=\"numpy\", label='background')\n",
    "                im_out_2 = gr.Image(type=\"numpy\", label='mask')\n",
    "                im_out_3 = gr.Image(type=\"numpy\", label='mask with background')\n",
    "                # im_out_4 = gr.Image(type=\"numpy\")\n",
    "        # btn = gr.Button()\n",
    "        im.change(sleep, outputs=[im_out_1, im_out_2, im_out_3], inputs=im)\n",
    "        savebtn.click(saveimg, outputs=[im, im_out_2], inputs=im)\n",
    "        # btn = gr.Button()\n",
    "\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "        #         org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "        #         ##\n",
    "        #         draw = gr.ImageEditor(label='Draw corrosion', type=\"numpy\")#,height=image_resolution, width=image_resolution)\n",
    "        #         print(draw, type(draw))\n",
    "\n",
    "                \n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "    # with gr.Tab('Use test images'):\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "                # org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_img, im, prompt, image_resolution, scheduler_select, inference_steps,scale, seed]\n",
    "        run_button.click(fn=show_image_draw, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=org_img,\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image_draw,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                # gr.Examples(\n",
    "                # label='Example: Masked corrosion with background',\n",
    "                # examples=examples_mask,\n",
    "                # inputs=inputs[1],\n",
    "                # outputs=[result_gallery_depth],\n",
    "                # fn=show_image,\n",
    "                # cache_examples=CACHE_EXAMPLES,\n",
    "                # )\n",
    "   ###################################################  Tab 2  ###################################################           \n",
    "    with gr.Tab('Use test images'):\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_image_pil = gr.Image(type=\"numpy\", label='Original Image Tab 2')\n",
    "                masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_image_pil, masked_corrosion_with_bg_pil, prompt, image_resolution, scheduler_select, inference_steps,scale, seed]\n",
    "        run_button.click(fn=show_image, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=inputs[0],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Masked corrosion with background',\n",
    "                examples=examples_mask,\n",
    "                inputs=inputs[1],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "        ###################################################  Tab 3  ###################################################           \n",
    "    with gr.Tab('Find members then draw corrosion images'):\n",
    "         # with gr.Blocks():\n",
    "        with gr.Group():\n",
    "            with gr.Row():\n",
    "                org_img = gr.Image(type=\"numpy\", label=\"Original Image Tab 3\")\n",
    "# MCD.launch(share=True)\n",
    "MCD.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录为 /home/ubunto/Project/konglx/generate/diffusers/UI\n",
      "目录修改成功 /home/ubunto/Project/konglx/generate/diffusers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rgb(0, 128, 0)', 'rgb(128, 0, 0)', 'rgb(128, 128, 0)']\n",
      "this is org_img: ()\n",
      "this is org_img: ()\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7f4730208a60>\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7f47301faee0>\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******type(im_in), im_in.shape,im:****** <class 'numpy.ndarray'> (512, 512, 3) {'background': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)}\n",
      " shape:(512, 512, 3), ndim:3, size:786432\n",
      "im: {'background': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8)}\n",
      "im: {'background': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8)}\n",
      "im: {'background': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.29it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im: {'background': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  4.53it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im: {'background': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.61it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.54it/s]\n"
     ]
    }
   ],
   "source": [
    "## 这个只有绘制腐蚀和腐蚀贴图\n",
    "# from share import *\n",
    "# import config\n",
    "import imgviz\n",
    "import os\n",
    "# 查看当前工作目录\n",
    "retval = os.getcwd()\n",
    "print(\"当前工作目录为 %s\" % retval)\n",
    "os.chdir('/home/ubunto/Project/konglx/generate/diffusers')\n",
    "\n",
    "# 查看修改后的工作目录\n",
    "retval = os.getcwd()\n",
    "\n",
    "print(\"目录修改成功 %s\" % retval)\n",
    "\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# from pytorch_lightning import seed_everything\n",
    "from annotator.util import resize_image, HWC3\n",
    "from annotator.midas import MidasDetector\n",
    "# from cldm.model import create_model, load_state_dict\n",
    "# from cldm.ddim_hacked import DDIMSampler\n",
    "from diffusers import DDPMPipeline, DDIMPipeline, DDIMScheduler, DDPMScheduler\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import PIL\n",
    "\n",
    "######################\n",
    "# rough深度的onnx推理准备\n",
    "import onnxruntime as ort\n",
    "\n",
    "import cv2\n",
    "from typing import Tuple, Dict, List\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "onnx_model_dir=\"/home/ubunto/Project/konglx/mono_depth/Metric3D-main/onnx/metric3d-vit-small/onnx/model.onnx\"\n",
    "\n",
    "def prepare_input(\n",
    "    rgb_image: np.ndarray, input_size: Tuple[int, int]\n",
    ") -> Tuple[Dict[str, np.ndarray], List[int]]:\n",
    "\n",
    "    h, w = rgb_image.shape[:2] # 原图尺寸\n",
    "    scale = min(input_size[0] / h, input_size[1] / w)\n",
    "    rgb = cv2.resize(\n",
    "        rgb_image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    padding = [123.675, 116.28, 103.53]\n",
    "    h, w = rgb.shape[:2]\n",
    "    pad_h = input_size[0] - h\n",
    "    pad_w = input_size[1] - w\n",
    "    pad_h_half = pad_h // 2  # h方向，每边padding的尺寸\n",
    "    pad_w_half = pad_w // 2  # w方向，每边padding的尺寸\n",
    "    rgb: np.ndarray = cv2.copyMakeBorder(\n",
    "        rgb,\n",
    "        pad_h_half,\n",
    "        pad_h - pad_h_half,\n",
    "        pad_w_half,\n",
    "        pad_w - pad_w_half,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=padding,\n",
    "    )\n",
    "    pad_info = [pad_h_half, pad_h - pad_h_half, pad_w_half, pad_w - pad_w_half]\n",
    "\n",
    "    onnx_input = {\n",
    "        # \"image\": np.ascontiguousarray(\n",
    "        \"pixel_values\": np.ascontiguousarray(\n",
    "            np.transpose(rgb, (2, 0, 1))[None], dtype=np.float32\n",
    "        ),  # 1, 3, H, W\n",
    "    }\n",
    "    return onnx_input, pad_info\n",
    "\n",
    "def onnx_inference(onnx_model_dir: str, input_image: np):\n",
    "\n",
    "    ## Dummy Test\n",
    "    B = 1\n",
    "    if \"vit\" in onnx_model_dir:\n",
    "        input_size = (616, 1064)  # [H, W]\n",
    "        if 'fp16' in onnx_model_dir:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float16)\n",
    "        else:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "    else:\n",
    "        input_size = (544, 1216)  # [H, W]\n",
    "        dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "\n",
    "    providers = [\n",
    "        (\n",
    "            \"CUDAExecutionProvider\",\n",
    "            {\"cudnn_conv_use_max_workspace\": \"0\", \"device_id\": str(0)},\n",
    "        )\n",
    "    ]\n",
    "    # providers = [(\"TensorrtExecutionProvider\", {'trt_engine_cache_enable': True, 'trt_fp16_enable': True, 'device_id': 0, 'trt_dla_enable': False})]\n",
    "    ort_session = ort.InferenceSession(onnx_model_dir, providers=providers)\n",
    "\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "    out_name = ort_session.get_outputs()[0].name\n",
    "    print(input_name, out_name, sep='\\n')\n",
    "    # outputs = ort_session.run(None, {\"image\": dummy_image})\n",
    "    outputs = ort_session.run(None, {input_name: dummy_image})\n",
    "\n",
    "    print(\n",
    "        f\"The actual output of onnxruntime session for the dummy set: outputs[0].shape={outputs[0].shape}\"\n",
    "    )\n",
    "    # input_iamge = input_image\n",
    "    # print(np.unique(input_image))\n",
    "\n",
    "    original_shape = input_image.shape[:2]\n",
    "    onnx_input, pad_info = prepare_input(input_image, input_size)  # rgb_image是原图形状[512,512], input_size = (616, 1064)\n",
    "    outputs = ort_session.run(None, onnx_input)\n",
    "    depth = outputs[0].squeeze()  # [H, W]\n",
    "    # plt.imshow(depth)\n",
    "    # Reshape the depth to the original size\n",
    "    depth = depth[\n",
    "        pad_info[0] : input_size[0] - pad_info[1],\n",
    "        pad_info[2] : input_size[1] - pad_info[3],\n",
    "    ]\n",
    "    depth = cv2.resize(\n",
    "        depth, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "    return depth\n",
    "################################\n",
    "\n",
    "######################\n",
    "#  controlnet模型准备\n",
    "def controlnet_diff(corrosion_with_bg_pil, mask_depth_pil, prompt = '',device = 'cuda',seed = 2024,use_freeu = False,controlnet_conditioning_scale_list=[1.0,1.0],\n",
    "                    config_dir = '/home/ubunto/Project/konglx/generate/ControlNet/models/stable-diffusion-v1-5',\n",
    "                    control_corrosion_with_bg_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_corrosion_with_background_merge_inpainting_h-512_w-512_2024-07-29_13:19:18_seeds-2024/checkpoint-5700/controlnet',\n",
    "                    control_depth_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_depth_h-512_w-512_2024-07-16_17:42:27_seeds-2024/checkpoint-2000/controlnet',\n",
    "                    scheduler_select = 'PNDM',\n",
    "                    inference_steps=20,\n",
    "                    guidance_scale=7.5,\n",
    "                    ):\n",
    "    with torch.no_grad():\n",
    "        print('scheduler_select:', scheduler_select)\n",
    "        controlnet_corrosion_with_bg = ControlNetModel.from_pretrained(control_corrosion_with_bg_trained_dir)\n",
    "        controlnet_depth = ControlNetModel.from_pretrained(control_depth_trained_dir)\n",
    "        if scheduler_select == 'PNDM' or scheduler_select == None:\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None).to(device)\n",
    "        elif scheduler_select == 'DDPM':\n",
    "            # scheduler DDPM\n",
    "            scheduler = DDPMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        elif scheduler_select == 'DDIM':\n",
    "            # scheduler DDIM\n",
    "            scheduler = DDIMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "        pipeline.unet.use_freeu = use_freeu \n",
    "        \n",
    "\n",
    "        mask_corrosion_with_bg_pil = load_image(corrosion_with_bg_pil)\n",
    "        mask_depth_pil = load_image(mask_depth_pil)\n",
    "        validation_image = [mask_corrosion_with_bg_pil, mask_depth_pil]\n",
    "        image = pipeline(prompt, validation_image, num_inference_steps=inference_steps, generator=generator, controlnet_conditioning_scale=controlnet_conditioning_scale_list,\n",
    "                        guidance_scale=guidance_scale,\n",
    "                            ).images[0]\n",
    "    torch.cuda.empty_cache()\n",
    "    return image\n",
    "#######################\n",
    "\n",
    "################################\n",
    "# gradio的功能接口定义\n",
    "def show_image(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "\n",
    "def show_image_draw(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img['composite']\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "# 绘图\n",
    "def create_canvas(w, h):\n",
    "    return np.zeros(shape=(h, w, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "brush_colors = gr.Brush()\n",
    "# brush_colors.colors=[\n",
    "#                 \"rgb(128, 0, 0)\", # fair\n",
    "#                 \"rgb(0, 128, 0)\", # poor\n",
    "#                 \"rgb(128, 128, 0)\",] # severe\n",
    "brush_colors.colors=[\n",
    "                \"rgb(0, 128, 0)\", # poor\n",
    "                \"rgb(128, 0, 0)\", # fair\n",
    "                \"rgb(128, 128, 0)\",] # severe\n",
    "\n",
    "# brush_colors.colors=[\n",
    "                \n",
    "#                 \"rgb(128, 128, 0)\",\"rgb(0, 128, 0)\",\"rgb(128, 0, 0)\",]\n",
    "# print()\n",
    "print(brush_colors.colors\n",
    "                # format=\"png\",\n",
    "                )\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "\n",
    "\n",
    "def sleep(im):\n",
    "    # # time.sleep(5)\n",
    "    # # return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1],im[\"composite\"]]\n",
    "    # return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    "    print('im:', im)\n",
    "    if len(im[\"layers\"]) == 0:\n",
    "        im[\"layers\"].append(np.zeros((512, 512, 4), np.uint8))\n",
    "    # im[\"layers\"][0]=cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB )\n",
    "    return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    " \n",
    "def upim(im_in,im):\n",
    "    print('******type(im_in), im_in.shape,im:******', type(im_in), im_in.shape,im)#, type(im), im)\n",
    "    height, width, channels = im_in.shape[:3]\n",
    "    im[\"background\"]=im_in\n",
    "    im[\"layers\"][0]=np.zeros((height, width, 4), np.uint8)\n",
    "    #im[\"layers\"][1]=None\n",
    "\n",
    "    print(f\" shape:{im_in.shape}, ndim:{im_in.ndim}, size:{im_in.size}\")\n",
    "    return gr.ImageMask(value=im,height=600,width=600)\n",
    "\n",
    "\n",
    "def saveimg(im):\n",
    "    #print(im[\"layers\"][0])\n",
    "    background=im[\"background\"]\n",
    "    composite=im[\"composite\"]\n",
    "    background=cv2.cvtColor(background, cv2.COLOR_BGR2RGB )\n",
    "    composite=cv2.cvtColor(composite, cv2.COLOR_BGR2RGB )\n",
    "    img_layer = cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"layers0.png\",img_layer)\n",
    "    cv2.imwrite(\"background.png\",background)\n",
    "    cv2.imwrite(\"composite.png\",composite)\n",
    "    return gr.ImageMask(value=im,height=600,width=600), background\n",
    "\n",
    "# inputs_np=gr.Image(type=\"numpy\")\n",
    "\n",
    "CACHE_EXAMPLES = torch.cuda.is_available() and os.getenv(\"CACHE_EXAMPLES\", \"0\") == \"1\"\n",
    "org_img_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/images/00003.jpg'\n",
    "masked_corrosion_with_bg_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/conditioning_images/00003.png'\n",
    "examples = [ [load_image(org_img_dir)]]\n",
    "examples_mask = [[load_image(masked_corrosion_with_bg_dir)]]\n",
    "\n",
    "MCD = gr.Blocks(title=\"Multi-Control corrosion generator\").queue()\n",
    "with MCD:\n",
    "    gr.Markdown('Multi-Control corrosion generator')\n",
    "    ###################################################  Tab 1  ###################################################\n",
    "\n",
    "    with gr.Tab('Draw corrosion images'):\n",
    "        # with gr.Blocks():\n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_img = gr.Image(type=\"numpy\", label=\"Original Image Tab 1\")\n",
    "                print('this is org_img:', np.array(org_img).shape)\n",
    "                \n",
    "                im = gr.ImageEditor(\n",
    "                    type=\"numpy\",\n",
    "                    crop_size=\"1:1\",\n",
    "                    height=512,\n",
    "                    width=512,\n",
    "                    brush=brush_colors,\n",
    "                    label='Draw',\n",
    "                    canvas_size=(512, 512),\n",
    "                    sources='upload',\n",
    "                )\n",
    "        \n",
    "        with gr.Row():\n",
    "            \n",
    "            uploadbtn = gr.Button(\"image upload\")\n",
    "            savebtn = gr.Button(\"save\")\n",
    "            print('this is org_img:', np.array(org_img).shape)\n",
    "            uploadbtn.click(upim,[org_img,im],[im])\n",
    "        \n",
    "        \n",
    "        # im =gr.Sketchpad(type=\"pil\",\n",
    "        #     crop_size=\"1:1\",)\n",
    "    \n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                im_out_1 = gr.Image(type=\"numpy\", label='background')\n",
    "                im_out_2 = gr.Image(type=\"numpy\", label='mask')\n",
    "                im_out_3 = gr.Image(type=\"numpy\", label='mask with background')\n",
    "                # im_out_4 = gr.Image(type=\"numpy\")\n",
    "        # btn = gr.Button()\n",
    "        im.change(sleep, outputs=[im_out_1, im_out_2, im_out_3], inputs=im)\n",
    "        savebtn.click(saveimg, outputs=[im, im_out_2], inputs=im)\n",
    "        # btn = gr.Button()\n",
    "\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "        #         org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "        #         ##\n",
    "        #         draw = gr.ImageEditor(label='Draw corrosion', type=\"numpy\")#,height=image_resolution, width=image_resolution)\n",
    "        #         print(draw, type(draw))\n",
    "\n",
    "                \n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "    # with gr.Tab('Use test images'):\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "                # org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_img, im, prompt, image_resolution, scheduler_select, inference_steps,scale, seed]\n",
    "        run_button.click(fn=show_image_draw, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=org_img,\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image_draw,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                # gr.Examples(\n",
    "                # label='Example: Masked corrosion with background',\n",
    "                # examples=examples_mask,\n",
    "                # inputs=inputs[1],\n",
    "                # outputs=[result_gallery_depth],\n",
    "                # fn=show_image,\n",
    "                # cache_examples=CACHE_EXAMPLES,\n",
    "                # )\n",
    "   ###################################################  Tab 2  ###################################################           \n",
    "    with gr.Tab('Use test images'):\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_image_pil = gr.Image(type=\"numpy\", label='Original Image Tab 2')\n",
    "                masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_image_pil, masked_corrosion_with_bg_pil, prompt, image_resolution, scheduler_select, inference_steps,scale, seed]\n",
    "        run_button.click(fn=show_image, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=inputs[0],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Masked corrosion with background',\n",
    "                examples=examples_mask,\n",
    "                inputs=inputs[1],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "        ###################################################  Tab 3  ###################################################           \n",
    "    with gr.Tab('Find members then draw corrosion images'):\n",
    "         # with gr.Blocks():\n",
    "        with gr.Group():\n",
    "            with gr.Row():\n",
    "                org_img = gr.Image(type=\"numpy\", label=\"Original Image Tab 3\")\n",
    "# MCD.launch(share=True)\n",
    "MCD.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这个有绘制腐蚀，腐蚀mask贴图以及自动分割构件，进行腐蚀生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录为 /home/ubunto/Project/konglx/generate/diffusers/UI\n",
      "目录修改成功 /home/ubunto/Project/konglx/generate/diffusers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rgb(128, 128, 0)', 'rgb(0, 128, 0)', 'rgb(128, 0, 0)']\n",
      "this is org_img: ()\n",
      "this is org_img: ()\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7fe4c03be1c0>\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7fe4c035e760>\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7fe4c0373880>\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******type(im_in), im_in.shape,im:****** <class 'numpy.ndarray'> (512, 512, 3) {'background': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)}\n",
      " shape:(512, 512, 3), ndim:3, size:786432\n",
      "im: {'background': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8)}\n",
      "im: {'background': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       [[104,  87,  65, 255],\n",
      "        [104,  87,  65, 255],\n",
      "        [105,  88,  67, 255],\n",
      "        ...,\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255],\n",
      "        [ 65,  63,  48, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [253, 255, 231, 255],\n",
      "        [254, 255, 232, 255],\n",
      "        [254, 255, 232, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255],\n",
      "        [250, 251, 230, 255]],\n",
      "\n",
      "       [[124,  75,  66, 255],\n",
      "        [124,  75,  66, 255],\n",
      "        [118,  69,  60, 255],\n",
      "        ...,\n",
      "        [247, 248, 228, 255],\n",
      "        [247, 248, 230, 255],\n",
      "        [247, 248, 230, 255]]], dtype=uint8)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: None\n",
      "Original controlnetconditioningembedding\n",
      "Original controlnetconditioningembedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.06it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.11it/s]\n"
     ]
    }
   ],
   "source": [
    "## 这个有绘制腐蚀，腐蚀mask贴图以及自动分割构件，进行腐蚀生成。\n",
    "# from share import *\n",
    "# import config\n",
    "import imgviz\n",
    "import os\n",
    "# 查看当前工作目录\n",
    "retval = os.getcwd()\n",
    "print(\"当前工作目录为 %s\" % retval)\n",
    "os.chdir('/home/ubunto/Project/konglx/generate/diffusers')\n",
    "\n",
    "# 查看修改后的工作目录\n",
    "retval = os.getcwd()\n",
    "\n",
    "print(\"目录修改成功 %s\" % retval)\n",
    "\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# from pytorch_lightning import seed_everything\n",
    "from annotator.util import resize_image, HWC3\n",
    "from annotator.midas import MidasDetector\n",
    "# from cldm.model import create_model, load_state_dict\n",
    "# from cldm.ddim_hacked import DDIMSampler\n",
    "from diffusers import DDPMPipeline, DDIMPipeline, DDIMScheduler, DDPMScheduler\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import PIL\n",
    "\n",
    "######################\n",
    "# rough深度的onnx推理准备\n",
    "import onnxruntime as ort\n",
    "\n",
    "import cv2\n",
    "from typing import Tuple, Dict, List\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter  \n",
    "\n",
    "\n",
    "\n",
    "onnx_model_dir=\"/home/ubunto/Project/konglx/mono_depth/Metric3D-main/onnx/metric3d-vit-small/onnx/model.onnx\"\n",
    "onnx_seg_dir = '/home/ubunto/Project/konglx/seg/UniMatch-main/resnet101_se_rand_cut_element.onnx'\n",
    "def prepare_input(\n",
    "    rgb_image: np.ndarray, input_size: Tuple[int, int]\n",
    ") -> Tuple[Dict[str, np.ndarray], List[int]]:\n",
    "\n",
    "    h, w = rgb_image.shape[:2] # 原图尺寸\n",
    "    scale = min(input_size[0] / h, input_size[1] / w)\n",
    "    rgb = cv2.resize(\n",
    "        rgb_image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    padding = [123.675, 116.28, 103.53]\n",
    "    h, w = rgb.shape[:2]\n",
    "    pad_h = input_size[0] - h\n",
    "    pad_w = input_size[1] - w\n",
    "    pad_h_half = pad_h // 2  # h方向，每边padding的尺寸\n",
    "    pad_w_half = pad_w // 2  # w方向，每边padding的尺寸\n",
    "    rgb: np.ndarray = cv2.copyMakeBorder(\n",
    "        rgb,\n",
    "        pad_h_half,\n",
    "        pad_h - pad_h_half,\n",
    "        pad_w_half,\n",
    "        pad_w - pad_w_half,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=padding,\n",
    "    )\n",
    "    pad_info = [pad_h_half, pad_h - pad_h_half, pad_w_half, pad_w - pad_w_half]\n",
    "\n",
    "    onnx_input = {\n",
    "        # \"image\": np.ascontiguousarray(\n",
    "        \"pixel_values\": np.ascontiguousarray(\n",
    "            np.transpose(rgb, (2, 0, 1))[None], dtype=np.float32\n",
    "        ),  # 1, 3, H, W\n",
    "    }\n",
    "    return onnx_input, pad_info\n",
    "\n",
    "def onnx_inference(onnx_model_dir: str, input_image: np):\n",
    "\n",
    "    ## Dummy Test\n",
    "    B = 1\n",
    "    if \"vit\" in onnx_model_dir:\n",
    "        input_size = (616, 1064)  # [H, W]\n",
    "        if 'fp16' in onnx_model_dir:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float16)\n",
    "        else:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "    else:\n",
    "        input_size = (544, 1216)  # [H, W]\n",
    "        dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "\n",
    "    providers = [\n",
    "        (\n",
    "            \"CUDAExecutionProvider\",\n",
    "            {\"cudnn_conv_use_max_workspace\": \"0\", \"device_id\": str(0)},\n",
    "        )\n",
    "    ]\n",
    "    # providers = [(\"TensorrtExecutionProvider\", {'trt_engine_cache_enable': True, 'trt_fp16_enable': True, 'device_id': 0, 'trt_dla_enable': False})]\n",
    "    ort_session = ort.InferenceSession(onnx_model_dir, providers=providers)\n",
    "\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "    out_name = ort_session.get_outputs()[0].name\n",
    "    print(input_name, out_name, sep='\\n')\n",
    "    # outputs = ort_session.run(None, {\"image\": dummy_image})\n",
    "    outputs = ort_session.run(None, {input_name: dummy_image})\n",
    "\n",
    "    print(\n",
    "        f\"The actual output of onnxruntime session for the dummy set: outputs[0].shape={outputs[0].shape}\"\n",
    "    )\n",
    "    # input_iamge = input_image\n",
    "    # print(np.unique(input_image))\n",
    "\n",
    "    original_shape = input_image.shape[:2]\n",
    "    onnx_input, pad_info = prepare_input(input_image, input_size)  # rgb_image是原图形状[512,512], input_size = (616, 1064)\n",
    "    outputs = ort_session.run(None, onnx_input)\n",
    "    depth = outputs[0].squeeze()  # [H, W]\n",
    "    # plt.imshow(depth)\n",
    "    # Reshape the depth to the original size\n",
    "    depth = depth[\n",
    "        pad_info[0] : input_size[0] - pad_info[1],\n",
    "        pad_info[2] : input_size[1] - pad_info[3],\n",
    "    ]\n",
    "    depth = cv2.resize(\n",
    "        depth, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "    return depth\n",
    "\n",
    "\n",
    "def merge_org_with_mask_for_org_mask(org_pil, mask_pil):\n",
    "    # img_name_list = os.listdir(org_dir)\n",
    "    # for each_name in img_name_list:\n",
    "    # name = each_name.split('.')[0]\n",
    "    image_np = np.array(load_image(org_pil))\n",
    "    image_pt = transforms.ToTensor()(image_np)\n",
    "    # print('image_pt.shape', image_pt.shape)\n",
    "    \n",
    "    conditioning_np = np.array(mask_pil)\n",
    "    conditioning_np_rgb = np.array(mask_pil.convert('RGB'))\n",
    "    # print('image_np.shape:', image_np.shape)\n",
    "    # print('conditioning_np.shape:', conditioning_np.shape, np.unique(conditioning_np))\n",
    "    # print('conditioning_np_rgb.shape:', conditioning_np_rgb.shape, np.unique(conditioning_np_rgb))\n",
    "    \n",
    "    # image_np[conditioning_np != 0] = conditioning_np_rgb[conditioning_np != 0]\n",
    "    # cv2.imshow('conditioning_np_rgb', np.array(conditioning_np_rgb)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    conditioning_pt = transforms.ToTensor()(conditioning_np)\n",
    "    conditioning_pt_rgb = transforms.ToTensor()(conditioning_np_rgb)\n",
    "    # print('conditioning_pt.shape', conditioning_pt.shape)\n",
    "    # print('conditioning_pt_rgb.shape', conditioning_pt_rgb.shape)\n",
    "    # print(conditioning_pt_rgb)\n",
    "\n",
    "    \n",
    "    ## image_with_conditioning_pt = image_pt * (torch.where(conditioning_pt_rgb>0.95, 0, 1)) + conditioning_pt_rgb\n",
    "    print('torch.max(conditioning_pt_rgb):', torch.max(conditioning_pt_rgb))\n",
    "    image_pt[conditioning_pt.repeat(3,1,1) != 0] = conditioning_pt_rgb[conditioning_pt.repeat(3,1,1) != 0]\n",
    "    image_with_conditioning_pil = transforms.ToPILImage()(image_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # image_with_conditioning_pil = transforms.ToPILImage()(image_with_conditioning_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return image_with_conditioning_pil\n",
    "\n",
    "def merge_org_with_mask_for_tag3_ellipse_corrosion(org_pil, mask_pil):\n",
    "    # img_name_list = os.listdir(org_dir)\n",
    "    # for each_name in img_name_list:\n",
    "    # name = each_name.split('.')[0]\n",
    "    image_np = np.array(load_image(org_pil))\n",
    "    image_pt = transforms.ToTensor()(image_np)\n",
    "    # print('image_pt.shape', image_pt.shape)\n",
    "    \n",
    "    conditioning_np = np.array(mask_pil)\n",
    "    conditioning_np_rgb = np.array(mask_pil.convert('RGB'))\n",
    "    # print('image_np.shape:', image_np.shape)\n",
    "    # print('conditioning_np.shape:', conditioning_np.shape, np.unique(conditioning_np))\n",
    "    # print('conditioning_np_rgb.shape:', conditioning_np_rgb.shape, np.unique(conditioning_np_rgb))\n",
    "    \n",
    "    # image_np[conditioning_np != 0] = conditioning_np_rgb[conditioning_np != 0]\n",
    "    # cv2.imshow('conditioning_np_rgb', np.array(conditioning_np_rgb)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    conditioning_pt = transforms.ToTensor()(conditioning_np)\n",
    "    conditioning_pt_rgb = transforms.ToTensor()(conditioning_np_rgb)\n",
    "    # print('conditioning_pt.shape', conditioning_pt.shape)\n",
    "    # print('conditioning_pt_rgb.shape', conditioning_pt_rgb.shape)\n",
    "    # print(conditioning_pt_rgb)\n",
    "\n",
    "    \n",
    "    ## image_with_conditioning_pt = image_pt * (torch.where(conditioning_pt_rgb>0.95, 0, 1)) + conditioning_pt_rgb\n",
    "    print('torch.max(conditioning_pt_rgb):', torch.max(conditioning_pt_rgb))\n",
    "    image_pt[conditioning_pt.repeat(3,1,1) != 0] = conditioning_pt_rgb[conditioning_pt.repeat(3,1,1) != 0]\n",
    "    image_with_conditioning_pil = transforms.ToPILImage()(image_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # image_with_conditioning_pil = transforms.ToPILImage()(image_with_conditioning_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return image_with_conditioning_pil\n",
    "################################\n",
    "# 1.用训练好的构件识别模型进行分割\n",
    "################################\n",
    "\n",
    "\n",
    "\n",
    "###### 定义选定区域内生成若干数量的椭圆的腐蚀#######\n",
    "################################\n",
    "# 1.定义分割构件和生成椭圆的函数\n",
    "################################\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "# from dataset.semi import normalize\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import imgviz\n",
    "\n",
    "\n",
    "\n",
    "def normalize(img, mask=None):\n",
    "    img = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])(img)\n",
    "    if mask is not None:\n",
    "        mask = torch.from_numpy(np.array(mask)).long()\n",
    "        return img, mask\n",
    "    return img\n",
    "\n",
    "\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "## 分割构件\n",
    "def seg_members(onnx_dir, img_pil):\n",
    "    # 加载模型\n",
    "    img_input = normalize(img_pil)\n",
    "    # 对于onnx需要指定输入的shape\n",
    "    resize = transforms.Resize([512,512])\n",
    "    img_input = resize(img_input)\n",
    "    print(img_input.shape)\n",
    "    # img_tensor = torch.from_numpy(img_input).type(torch.cuda.FloatTensor)\n",
    "    img_tensor = img_input.unsqueeze(0).cuda()\n",
    "    img_np = img_tensor.detach().cpu().numpy()\n",
    "    print(img_np.shape)\n",
    "    ort_session = ort.InferenceSession(onnx_dir) # 创建一个推理session\n",
    "\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: img_np}\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "    ort_outs = ort_session.run(None, ort_inputs)[0]\n",
    "    # 通过 get_inputs()[i].name来获取输入的名称\n",
    "    end = time.time()\n",
    "    print(\"onnx预测时间：\", end-start)\n",
    "    print(ort_outs.shape,  type(ort_outs))\n",
    "    # print(ort_outs)\n",
    "\n",
    "    # 输出为4分类，即，c=4的图像，取最大的通道，合并，即为预测图像\n",
    "    # numpy转torch\n",
    "    pred = torch.from_numpy(ort_outs)\n",
    "    pred_softmax = pred.softmax(dim=1).max(dim=1)[1]\n",
    "    print(pred_softmax.shape)\n",
    "    # print(pred_softmax)\n",
    "\n",
    "    pred_np = pred_softmax.numpy()[0]\n",
    "    # 对预测的mask用colored_mask上色\n",
    "    pred_pil_np = colored_mask(pred_np)\n",
    "    pred_np_cls = np.unique(pred_np)\n",
    "    \n",
    "    return pred_pil_np, pred_np_cls\n",
    "\n",
    "\n",
    "###### 定义选定区域内生成若干数量的椭圆的腐蚀#######\n",
    "def generate_ellipse_to_want_area(org_img_np, generate_ellipses, fill_value, want_area = [1,4], num_ellipses=25, a_min=30, a_max=100, b_min=20, b_max=40, split_everywhere=False):\n",
    "    \"\"\"\n",
    "    generate_ellipsepolygon_to_want_area based on function 'generate_polygon'.\n",
    "\n",
    "    Args:\n",
    "        org_img_np (numpy.ndarray): The input array.\n",
    "        generate_polygon (function): generate_polygon\n",
    "        want_area_list (list or tuple, optional): A list or tuple of values to consider as the selected region.\n",
    "                                          Default is [1,4].\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A new array with the same shape as the input array,\n",
    "                       containing the generated and filled polygon.\n",
    "    \"\"\"\n",
    "    fill_value = severe_dict[fill_value]\n",
    "    # 选择腐蚀类型\n",
    "    # corrosionType = [3] # 腐蚀类型： 1-fair，2-poor， 3-severe\n",
    "    list_area_corrosion = []\n",
    "    list_area_only_corrosion = []\n",
    "    for area in want_area:\n",
    "        gen_polygon, gen_polygon_blank = generate_ellipses(arr=org_img_np, fill_value=fill_value, values=area, num_ellipses=num_ellipses, a_min=a_min, a_max=a_max, b_min=b_min, b_max=b_max, split_everywhere=split_everywhere)\n",
    "        list_area_corrosion.append(gen_polygon)\n",
    "        list_area_only_corrosion.append(gen_polygon_blank)\n",
    "    sum_area = np.sum(list_area_corrosion, axis=0)\n",
    "    sum_area_only_corrosion = np.sum(list_area_only_corrosion, axis=0)\n",
    "    return sum_area, list_area_corrosion, sum_area_only_corrosion, list_area_only_corrosion\n",
    "\n",
    "########### 定义基于numpy选择构件的函数#####\n",
    "\n",
    "def filter_array(arr, values):\n",
    "    \"\"\"\n",
    "    Filter a NumPy array to keep only the specified values.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): The input array to be filtered.\n",
    "        values (list or tuple): A list or tuple of values to keep in the filtered array.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A new array with the same shape as the input array,\n",
    "                       containing only the specified values.\n",
    "    \"\"\"\n",
    "    conditions = [arr == value for value in values]\n",
    "    condition = np.logical_or.reduce(conditions)\n",
    "    filtered_arr = np.where(condition, arr, 0)\n",
    "    return filtered_arr\n",
    "\n",
    "################### 选择腐蚀类型 ######################\n",
    "# corrosionType = [3] # 腐蚀类型： 1-fair，2-poor， 3-severe\n",
    "def corrosionType_to_fill_value(corrosionType):\n",
    "    fill_value = []\n",
    "    for i in corrosionType:\n",
    "        if i==1:\n",
    "            fill_value.append(12)\n",
    "        elif i==2:\n",
    "            fill_value.append(6)\n",
    "        elif i==3:\n",
    "            fill_value.append(4)\n",
    "    return fill_value\n",
    "\n",
    "# fill_value_list = corrosionType_to_fill_value(corrosionType=corrosionType) # 以12为总数量，fill_value与corrosionType对应：腐蚀类型： 1-fair对应12/12，2-poor对应12/6， 3-severe对应12/4\n",
    "\n",
    "\n",
    "################### 定义和生成椭圆 ######################\n",
    "def generate_ellipses(arr, fill_value=1, values=[5], num_ellipses=5, a_min=30, a_max=120, b_min=10, b_max=80, split_everywhere=True):\n",
    "    \"\"\"\n",
    "    🕐用少数量的大椭圆，模拟大片的腐蚀；\n",
    "    🕑用多数量的小椭圆，模拟pitting corrosion\n",
    "    Generate random quadrilaterals within the specified regions of a NumPy array\n",
    "    and fill them with a specified value.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): The input array.\n",
    "        num_polygons (int): The number of quadrilaterals to generate.\n",
    "        fill_value (int, optional): The value to use for filling the quadrilaterals. Default is 1.\n",
    "        values (list or tuple, optional): A list or tuple of values to consider as the selected region.\n",
    "                                          Default is [1].\n",
    "\n",
    "    Returns:\n",
    "        tuple(numpy.ndarray): A new array with the same shape as the input array,\n",
    "                       containing the generated and filled quadrilaterals.\n",
    "    \"\"\"\n",
    "    \n",
    "    selected_region = np.isin(arr, values)\n",
    "    # print(selected_region)\n",
    "    selected_coords = np.argwhere(selected_region)\n",
    "    print('可选的坐标点数：',len(selected_coords))\n",
    "    # # 椭圆数量和范围\n",
    "    # num_ellipses = 5\n",
    "    # a_min, a_max = 20, 50\n",
    "    # b_min, b_max = 10, 30\n",
    "    \n",
    "    result = arr.copy()\n",
    "    image = Image.fromarray(result)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # 空白mask\n",
    "    result_blank = np.zeros_like(result)\n",
    "    # print(result_blank)\n",
    "    image_blank = Image.fromarray(result_blank)\n",
    "    draw_blank = ImageDraw.Draw(image_blank)\n",
    "    # # 生成图片\n",
    "    # im = Image.new('RGB', (100,100), color='white')  \n",
    "    # draw = ImageDraw.Draw(im)\n",
    "    if split_everywhere:\n",
    "        for i in range(num_ellipses):\n",
    "            xy_arr = random.sample(list(selected_coords), k=1)\n",
    "            # print(random.sample(list(selected_coords), k=2), random.sample(list(selected_coords), k=3))\n",
    "            print(xy_arr[0][0])\n",
    "            y, x = xy_arr[0][0], xy_arr[0][1]\n",
    "            # 随机生成长短半轴\n",
    "            a = random.randint(a_min, a_max)\n",
    "            b = random.randint(b_min, b_max)\n",
    "            \n",
    "            # 随机中心点\n",
    "            # x = random.randint(0, 100-a)\n",
    "            # y = random.randint(0, 100-b)\n",
    "            \n",
    "            # 绘制椭圆\n",
    "            draw.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "            draw_blank.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "        \n",
    "        result = np.array(image)\n",
    "        result_mask = np.array(image_blank)\n",
    "    else:\n",
    "        selected_coords_with_according_to_num_ellipses_list = []\n",
    "        xy_arr_0 = random.sample(list(selected_coords), k=1)[0]\n",
    "        selected_coords_with_according_to_num_ellipses_list.append(xy_arr_0)\n",
    "        count_num = 0\n",
    "        for i in list(selected_coords):\n",
    "            dist = ((i[0]-xy_arr_0[0])**2 + (i[1]-xy_arr_0[1])**2)**0.5\n",
    "            if dist<= (a_max + b_max):\n",
    "                selected_coords_with_according_to_num_ellipses_list.append(i)\n",
    "                xy_arr_0 = i\n",
    "                count_num += 1\n",
    "                # print(count_num)\n",
    "                # print('a')\n",
    "                if count_num == num_ellipses*3:\n",
    "                    break\n",
    "            \n",
    "        \n",
    "        # selected_coords_with_according_to_num_ellipses_np = np.array(selected_coords_with_according_to_num_ellipses_list)\n",
    "        for i in range(num_ellipses):\n",
    "            xy_arr = random.sample(selected_coords_with_according_to_num_ellipses_list, k=1)\n",
    "            # print(random.sample(list(selected_coords), k=2), random.sample(list(selected_coords), k=3))\n",
    "            # print(xy_arr[0][0])\n",
    "            y, x = xy_arr[0][0], xy_arr[0][1]\n",
    "            # 随机生成长短半轴\n",
    "            a = random.randint(a_min, a_max)\n",
    "            b = random.randint(b_min, b_max)\n",
    "            \n",
    "            # 随机中心点\n",
    "            # x = random.randint(0, 100-a)\n",
    "            # y = random.randint(0, 100-b)\n",
    "            \n",
    "            # 绘制椭圆\n",
    "            draw.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "            draw_blank.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "        \n",
    "        result = np.array(image)\n",
    "        result_mask = np.array(image_blank)\n",
    "\n",
    "            \n",
    "    \n",
    "    return result, result_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################\n",
    "#  controlnet模型准备\n",
    "def controlnet_diff(corrosion_with_bg_pil, mask_depth_pil, prompt = '',device = 'cuda',seed = 2024,use_freeu = False,controlnet_conditioning_scale_list=[1.0,1.0],\n",
    "                    config_dir = '/home/ubunto/Project/konglx/generate/ControlNet/models/stable-diffusion-v1-5',\n",
    "                    control_corrosion_with_bg_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_corrosion_with_background_merge_inpainting_h-512_w-512_2024-07-29_13:19:18_seeds-2024/checkpoint-5700/controlnet',\n",
    "                    control_depth_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_depth_h-512_w-512_2024-07-16_17:42:27_seeds-2024/checkpoint-2000/controlnet',\n",
    "                    scheduler_select = 'PNDM',\n",
    "                    inference_steps=20,\n",
    "                    guidance_scale=7.5,\n",
    "                    ):\n",
    "    with torch.no_grad():\n",
    "        print('scheduler_select:', scheduler_select)\n",
    "        controlnet_corrosion_with_bg = ControlNetModel.from_pretrained(control_corrosion_with_bg_trained_dir)\n",
    "        controlnet_depth = ControlNetModel.from_pretrained(control_depth_trained_dir)\n",
    "        if scheduler_select == 'PNDM' or scheduler_select == None:\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None).to(device)\n",
    "        elif scheduler_select == 'DDPM':\n",
    "            # scheduler DDPM\n",
    "            scheduler = DDPMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        elif scheduler_select == 'DDIM':\n",
    "            # scheduler DDIM\n",
    "            scheduler = DDIMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "        pipeline.unet.use_freeu = use_freeu \n",
    "        \n",
    "\n",
    "        mask_corrosion_with_bg_pil = load_image(corrosion_with_bg_pil)\n",
    "        mask_depth_pil = load_image(mask_depth_pil)\n",
    "        validation_image = [mask_corrosion_with_bg_pil, mask_depth_pil]\n",
    "        image = pipeline(prompt, validation_image, num_inference_steps=inference_steps, generator=generator, controlnet_conditioning_scale=controlnet_conditioning_scale_list,\n",
    "                        guidance_scale=guidance_scale,\n",
    "                            ).images[0]\n",
    "    torch.cuda.empty_cache()\n",
    "    return image\n",
    "#######################\n",
    "\n",
    "################################\n",
    "# gradio的功能接口定义\n",
    "def show_image(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    org_rgb_image_pil = Image.fromarray(org_rgb_image)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "    \n",
    "    # merged_org_img_with_mask_pil = merge_org_with_mask_for_org_mask(org_pil=org_rgb_image_pil, mask_pil=rgb_image_pil)\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "\n",
    "def show_image_draw(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img['composite']\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    org_rgb_image_pil = Image.fromarray(org_rgb_image)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "\n",
    "    # merged_org_img_with_mask_pil = merge_org_with_mask(org_pil=org_rgb_image_pil, mask_pil=rgb_image_pil)\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "\n",
    "def show_image_members_seg(org_img,  prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024,split_everywhere = False, fill_value_setting = 'poor', num_ellipse='15' ):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    \n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    org_rgb_image_pil = Image.fromarray(org_rgb_image)\n",
    "    # seg members->分割构件\n",
    "    # 定义numpy的随机模式\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    pred_pil, pred_np_cls = seg_members(onnx_dir='/home/ubunto/Project/konglx/seg/UniMatch-main/resnet101_se_rand_cut_element.onnx', \n",
    "                                       img_pil=org_rgb_image_pil)\n",
    "    print(np.array(pred_pil), pred_np_cls)\n",
    "    mask_members_np_mode_R = np.array(pred_pil)\n",
    "    # select_area_list = [np.random.choice(pred_np_cls[1:])]\n",
    "    print('******* Detected members *******',mask_members_np_mode_R)\n",
    "    # 选择构件区域\n",
    "    mask_members_np_mode_R_filter = filter_array(mask_members_np_mode_R, mask_members_np_mode_R)\n",
    "    print('构件mask的形状和元素值', mask_members_np_mode_R_filter.shape, np.unique(mask_members_np_mode_R_filter))\n",
    "    ## 找到最大的构件区域\n",
    "    # max_num_area = np.argmax(np.bincount(mask_members_np_mode_R_filter))\n",
    "    # 将数组展平成一维数组  \n",
    "    # flattened_mask_members_np_mode_R_filter = mask_members_np_mode_R_filter.flatten()  \n",
    "    flattened_mask_members_np_mode_R_filter = mask_members_np_mode_R_filter[mask_members_np_mode_R_filter != 0]\n",
    "    \n",
    "    # 使用Counter统计每个元素出现的次数  \n",
    "    counter = Counter(flattened_mask_members_np_mode_R_filter)  \n",
    "    \n",
    "    # 找到出现次数最多的元素及其值  \n",
    "    most_common_element, count = counter.most_common(1)[0] \n",
    "    print('最多出现的元素及其值:', most_common_element, count, members_text_dict[str(most_common_element.tolist())])\n",
    "    # cv2.imshow('pred_np_cls', mask_members_np_mode_R_filter)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # 4.在members指定区域生成任意数量的腐蚀，返回仅仅为腐蚀区域 （生成用）\n",
    "    num_ellipse = int(num_ellipse)\n",
    "    mask_corrosion_corr_to_members, mask_corrosion_corr_to_members_list, mask_only_corrosion_corr_to_members, mask_only_corrosion_corr_to_members_list = generate_ellipse_to_want_area(org_img_np=mask_members_np_mode_R, generate_ellipses=generate_ellipses, fill_value=fill_value_setting, want_area=[most_common_element], split_everywhere=split_everywhere, num_ellipses=num_ellipse)\n",
    "    # plt.imshow(mask_corrosion_corr_to_members)\n",
    "\n",
    "    # mask_only_corrosion_corr_to_members_devide_by_fill_value = (mask_only_corrosion_corr_to_members/fill_value_setting).astype((np.uint64))\n",
    "    mask_only_corrosion_corr_to_members_devide_by_fill_value = (12/mask_only_corrosion_corr_to_members).astype((np.uint64))\n",
    "    print(mask_only_corrosion_corr_to_members_devide_by_fill_value.min(), mask_only_corrosion_corr_to_members_devide_by_fill_value.max(), np.unique(mask_only_corrosion_corr_to_members_devide_by_fill_value), mask_only_corrosion_corr_to_members_devide_by_fill_value.dtype)\n",
    "    # print(np.unique(mask_only_corrosion_corr_to_members/12), mask_only_corrosion_corr_to_members.dtype, ((mask_only_corrosion_corr_to_members/12).astype(np.uint64)).dtype)\n",
    "\n",
    "    mask_only_corrosion_final_pil = colored_mask(mask_only_corrosion_corr_to_members_devide_by_fill_value)\n",
    "    # cv2.imshow('mask_only_corrosion_final_pil', mask_only_corrosion_final_pil)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # 5.在腐蚀区域生成椭圆，返回椭圆区域 （生成用）\n",
    "    # rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    # rgb_image_pil = Image.fromarray(rgb_image) \n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "    \n",
    "    merged_org_img_with_mask_pil = merge_org_with_mask_for_tag3_ellipse_corrosion(org_pil=org_rgb_image_pil, mask_pil=mask_only_corrosion_final_pil)\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=merged_org_img_with_mask_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8, pred_pil, mask_only_corrosion_final_pil, merged_org_img_with_mask_pil, out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "\n",
    "\n",
    "# 绘图\n",
    "def create_canvas(w, h):\n",
    "    return np.zeros(shape=(h, w, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "brush_colors = gr.Brush()\n",
    "# brush_colors.colors=[\n",
    "                \n",
    "#                 \"rgb(0, 128, 0)\", # poor\n",
    "                \n",
    "#                 ] \n",
    "brush_colors.colors=[\n",
    "                \n",
    "                \"rgb(128, 128, 0)\",\"rgb(0, 128, 0)\",\"rgb(128, 0, 0)\",]\n",
    "\n",
    "# brush_colors.colors=[\n",
    "                \n",
    "#                 \"rgb(128, 0, 0)\",\"rgb(128, 128, 0)\",\"rgb(0, 128, 0)\",]\n",
    "# print()\n",
    "print(brush_colors.colors\n",
    "                # format=\"png\",\n",
    "                )\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "\n",
    "\n",
    "def sleep(im):\n",
    "    # # time.sleep(5)\n",
    "    # # return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1],im[\"composite\"]]\n",
    "    # return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    "    print('im:', im)\n",
    "    if len(im[\"layers\"]) == 0:\n",
    "        im[\"layers\"].append(np.zeros((512, 512, 4), np.uint8))\n",
    "    # im[\"layers\"][0]=cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB )\n",
    "    return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    " \n",
    "def upim(im_in,im):\n",
    "    print('******type(im_in), im_in.shape,im:******', type(im_in), im_in.shape,im)#, type(im), im)\n",
    "    height, width, channels = im_in.shape[:3]\n",
    "    im[\"background\"]=im_in\n",
    "    im[\"layers\"][0]=np.zeros((height, width, 4), np.uint8)\n",
    "    #im[\"layers\"][1]=None\n",
    "\n",
    "    print(f\" shape:{im_in.shape}, ndim:{im_in.ndim}, size:{im_in.size}\")\n",
    "    return gr.ImageMask(value=im,height=600,width=600)\n",
    "\n",
    "\n",
    "def saveimg(im):\n",
    "    #print(im[\"layers\"][0])\n",
    "    background=im[\"background\"]\n",
    "    composite=im[\"composite\"]\n",
    "    background=cv2.cvtColor(background, cv2.COLOR_BGR2RGB )\n",
    "    composite=cv2.cvtColor(composite, cv2.COLOR_BGR2RGB )\n",
    "    img_layer = cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"layers0.png\",img_layer)\n",
    "    cv2.imwrite(\"background.png\",background)\n",
    "    cv2.imwrite(\"composite.png\",composite)\n",
    "    return gr.ImageMask(value=im,height=600,width=600), background\n",
    "\n",
    "# inputs_np=gr.Image(type=\"numpy\")\n",
    "\n",
    "CACHE_EXAMPLES = torch.cuda.is_available() and os.getenv(\"CACHE_EXAMPLES\", \"0\") == \"1\"\n",
    "org_img_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/images/00003.jpg'\n",
    "masked_corrosion_with_bg_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/conditioning_images/00003.png'\n",
    "examples = [ [load_image(org_img_dir)]]\n",
    "examples_mask = [[load_image(masked_corrosion_with_bg_dir)]]\n",
    "\n",
    "# 设置严重程度字典（这个用于生成椭圆）\n",
    "severe_dict = {'fair': 12, 'poor': 6,'severe': 4}\n",
    "\n",
    "members_text_dict = {'1': 'Bearing', '2': 'Bracing','3': 'Deck', '4':'Floor beam','5': 'Girder','6': 'Substructure','7': 'Gusset plate','8': 'Chord'\n",
    "                     ,'9': 'Vertical ','10': 'Diagonal','11': 'Railing'}\n",
    "def get_key(val, my_dict):\n",
    "    for key, value in my_dict.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "\n",
    "    return \"There is no such Key\"\n",
    "\n",
    "MCD = gr.Blocks(title=\"Multi-Control corrosion generator\").queue()\n",
    "with MCD:\n",
    "    gr.Markdown('Multi-Control corrosion generator')\n",
    "    ###################################################  Tab 1  ###################################################\n",
    "\n",
    "    with gr.Tab('Draw corrosion images'):\n",
    "        # with gr.Blocks():\n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_img = gr.Image(type=\"numpy\", label=\"Original Image Tab 1\")\n",
    "                print('this is org_img:', np.array(org_img).shape)\n",
    "                \n",
    "                im = gr.ImageEditor(\n",
    "                    type=\"numpy\",\n",
    "                    crop_size=\"1:1\",\n",
    "                    height=512,\n",
    "                    width=512,\n",
    "                    brush=brush_colors,\n",
    "                    label='Draw',\n",
    "                    canvas_size=(512, 512),\n",
    "                    sources='upload',\n",
    "                )\n",
    "        \n",
    "        with gr.Row():\n",
    "            \n",
    "            uploadbtn = gr.Button(\"image upload\")\n",
    "            savebtn = gr.Button(\"save\")\n",
    "            print('this is org_img:', np.array(org_img).shape)\n",
    "            uploadbtn.click(upim,[org_img,im],[im])\n",
    "        \n",
    "        \n",
    "        # im =gr.Sketchpad(type=\"pil\",\n",
    "        #     crop_size=\"1:1\",)\n",
    "    \n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                im_out_1 = gr.Image(type=\"numpy\", label='background')\n",
    "                im_out_2 = gr.Image(type=\"numpy\", label='mask')\n",
    "                im_out_3 = gr.Image(type=\"numpy\", label='mask with background')\n",
    "                # im_out_4 = gr.Image(type=\"numpy\")\n",
    "        # btn = gr.Button()\n",
    "        im.change(sleep, outputs=[im_out_1, im_out_2, im_out_3], inputs=im)\n",
    "        savebtn.click(saveimg, outputs=[im, im_out_2], inputs=im)\n",
    "        # btn = gr.Button()\n",
    "\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "        #         org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "        #         ##\n",
    "        #         draw = gr.ImageEditor(label='Draw corrosion', type=\"numpy\")#,height=image_resolution, width=image_resolution)\n",
    "        #         print(draw, type(draw))\n",
    "\n",
    "                \n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "    # with gr.Tab('Use test images'):\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "                # org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_img, im, prompt, image_resolution, scheduler_select, inference_steps,scale, seed]\n",
    "        run_button.click(fn=show_image_draw, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=org_img,\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image_draw,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                # gr.Examples(\n",
    "                # label='Example: Masked corrosion with background',\n",
    "                # examples=examples_mask,\n",
    "                # inputs=inputs[1],\n",
    "                # outputs=[result_gallery_depth],\n",
    "                # fn=show_image,\n",
    "                # cache_examples=CACHE_EXAMPLES,\n",
    "                # )\n",
    "   ###################################################  Tab 2  ###################################################           \n",
    "    with gr.Tab('Use test images'):\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_image_pil = gr.Image(type=\"numpy\", label='Original Image Tab 2')\n",
    "                masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_image_pil, masked_corrosion_with_bg_pil, prompt, image_resolution, scheduler_select, inference_steps,scale, seed]\n",
    "        run_button.click(fn=show_image, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=inputs[0],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Masked corrosion with background',\n",
    "                examples=examples_mask,\n",
    "                inputs=inputs[1],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "        ###################################################  Tab 3  ###################################################           \n",
    "    with gr.Tab('Find members then draw corrosion images'):\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_image_pil = gr.Image(type=\"numpy\", label='Original Image Tab 3')\n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                split_everywhere = gr.Radio(['True', 'False'], label='Split everywhere or not', info='Split everywhere or not', visible=True)\n",
    "                fill_value_setting = gr.Radio(severe_dict.keys(), label='Fill value setting', info='Fill value setting', visible=True)\n",
    "                num_ellipse = gr.Textbox(placeholder=\"How many ellipses do you want to draw?\",label=\"Number of ellipses\")\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=5.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    \n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_seg_members = gr.Gallery(label='Output segmented members', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_image_pil, prompt, image_resolution, scheduler_select, inference_steps,scale, seed, split_everywhere, fill_value_setting, num_ellipse]\n",
    "        run_button.click(fn=show_image_members_seg, inputs=inputs, outputs=[result_gallery_seg_members])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=inputs[0],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                # gr.Examples(\n",
    "                # label='Example: Masked corrosion with background',\n",
    "                # examples=examples_mask,\n",
    "                # inputs=inputs[1],\n",
    "                # outputs=[result_gallery_depth],\n",
    "                # fn=show_image,\n",
    "                # cache_examples=CACHE_EXAMPLES,\n",
    "                # )\n",
    "# MCD.launch(share=True)\n",
    "MCD.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这个有绘制腐蚀，腐蚀mask贴图以及自动分割构件，进行腐蚀以及裂缝生成的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录为 /home/ubunto/Project/konglx/generate/diffusers/UI\n",
      "目录修改成功 /home/ubunto/Project/konglx/generate/diffusers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rgb(0, 128, 0)', 'rgb(128, 128, 0)', 'rgb(128, 0, 0)']\n",
      "this is org_img: ()\n",
      "this is org_img: ()\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7f2e13f53be0>\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7f2e13f0e2b0>\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7f2e13f0eb50>\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7f2e13ee1550>\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******type(im_in), im_in.shape,im:****** <class 'numpy.ndarray'> (512, 512, 3) {'background': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)}\n",
      " shape:(512, 512, 3), ndim:3, size:786432\n",
      "im: {'background': array([[[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       [[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       [[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[169, 159, 165, 255],\n",
      "        [166, 156, 162, 255],\n",
      "        [166, 156, 162, 255],\n",
      "        ...,\n",
      "        [165, 160, 162, 255],\n",
      "        [173, 168, 170, 255],\n",
      "        [181, 177, 178, 255]],\n",
      "\n",
      "       [[174, 164, 170, 255],\n",
      "        [161, 151, 157, 255],\n",
      "        [161, 151, 157, 255],\n",
      "        ...,\n",
      "        [170, 165, 167, 255],\n",
      "        [178, 173, 175, 255],\n",
      "        [186, 181, 183, 255]],\n",
      "\n",
      "       [[178, 168, 173, 255],\n",
      "        [159, 149, 155, 255],\n",
      "        [159, 149, 155, 255],\n",
      "        ...,\n",
      "        [173, 168, 170, 255],\n",
      "        [181, 177, 178, 255],\n",
      "        [189, 185, 186, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       [[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       [[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[169, 159, 165, 255],\n",
      "        [166, 156, 162, 255],\n",
      "        [166, 156, 162, 255],\n",
      "        ...,\n",
      "        [165, 160, 162, 255],\n",
      "        [173, 168, 170, 255],\n",
      "        [181, 177, 178, 255]],\n",
      "\n",
      "       [[174, 164, 170, 255],\n",
      "        [161, 151, 157, 255],\n",
      "        [161, 151, 157, 255],\n",
      "        ...,\n",
      "        [170, 165, 167, 255],\n",
      "        [178, 173, 175, 255],\n",
      "        [186, 181, 183, 255]],\n",
      "\n",
      "       [[178, 168, 173, 255],\n",
      "        [159, 149, 155, 255],\n",
      "        [159, 149, 155, 255],\n",
      "        ...,\n",
      "        [173, 168, 170, 255],\n",
      "        [181, 177, 178, 255],\n",
      "        [189, 185, 186, 255]]], dtype=uint8)}\n",
      "im: {'background': array([[[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       [[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       [[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[169, 159, 165, 255],\n",
      "        [166, 156, 162, 255],\n",
      "        [166, 156, 162, 255],\n",
      "        ...,\n",
      "        [165, 160, 162, 255],\n",
      "        [173, 168, 170, 255],\n",
      "        [181, 177, 178, 255]],\n",
      "\n",
      "       [[174, 164, 170, 255],\n",
      "        [161, 151, 157, 255],\n",
      "        [161, 151, 157, 255],\n",
      "        ...,\n",
      "        [170, 165, 167, 255],\n",
      "        [178, 173, 175, 255],\n",
      "        [186, 181, 183, 255]],\n",
      "\n",
      "       [[178, 168, 173, 255],\n",
      "        [159, 149, 155, 255],\n",
      "        [159, 149, 155, 255],\n",
      "        ...,\n",
      "        [173, 168, 170, 255],\n",
      "        [181, 177, 178, 255],\n",
      "        [189, 185, 186, 255]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       [[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       [[156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        [156, 152, 148, 255],\n",
      "        ...,\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255],\n",
      "        [128, 123, 123, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[169, 159, 165, 255],\n",
      "        [166, 156, 162, 255],\n",
      "        [166, 156, 162, 255],\n",
      "        ...,\n",
      "        [165, 160, 162, 255],\n",
      "        [173, 168, 170, 255],\n",
      "        [181, 177, 178, 255]],\n",
      "\n",
      "       [[174, 164, 170, 255],\n",
      "        [161, 151, 157, 255],\n",
      "        [161, 151, 157, 255],\n",
      "        ...,\n",
      "        [170, 165, 167, 255],\n",
      "        [178, 173, 175, 255],\n",
      "        [186, 181, 183, 255]],\n",
      "\n",
      "       [[178, 168, 173, 255],\n",
      "        [159, 149, 155, 255],\n",
      "        [159, 149, 155, 255],\n",
      "        ...,\n",
      "        [173, 168, 170, 255],\n",
      "        [181, 177, 178, 255],\n",
      "        [189, 185, 186, 255]]], dtype=uint8)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: PNDM\n",
      "Original controlnetconditioningembedding\n",
      "Original controlnetconditioningembedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.24it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.12it/s]\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: PNDM\n",
      "Original controlnetconditioningembedding\n",
      "Original controlnetconditioningembedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  4.71it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.41it/s]\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: PNDM\n",
      "Original controlnetconditioningembedding\n",
      "Original controlnetconditioningembedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.65it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.47it/s]\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: PNDM\n",
      "Original controlnetconditioningembedding\n",
      "Original controlnetconditioningembedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  4.85it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.39it/s]\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: PNDM\n",
      "Original controlnetconditioningembedding\n",
      "Original controlnetconditioningembedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.19it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.42it/s]\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values\n",
      "predicted_depth\n",
      "The actual output of onnxruntime session for the dummy set: outputs[0].shape=(1, 616, 1064)\n",
      "scheduler_select: PNDM\n",
      "Original controlnetconditioningembedding\n",
      "Original controlnetconditioningembedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.54it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.23it/s]\n"
     ]
    }
   ],
   "source": [
    "## 这个有绘制腐蚀，腐蚀mask贴图以及自动分割构件，进行腐蚀生成。\n",
    "# from share import *\n",
    "# import config\n",
    "import imgviz\n",
    "import os\n",
    "# 查看当前工作目录\n",
    "retval = os.getcwd()\n",
    "print(\"当前工作目录为 %s\" % retval)\n",
    "os.chdir('/home/ubunto/Project/konglx/generate/diffusers')\n",
    "\n",
    "# 查看修改后的工作目录\n",
    "retval = os.getcwd()\n",
    "\n",
    "print(\"目录修改成功 %s\" % retval)\n",
    "\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# from pytorch_lightning import seed_everything\n",
    "from annotator.util import resize_image, HWC3\n",
    "from annotator.midas import MidasDetector\n",
    "# from cldm.model import create_model, load_state_dict\n",
    "# from cldm.ddim_hacked import DDIMSampler\n",
    "from diffusers import DDPMPipeline, DDIMPipeline, DDIMScheduler, DDPMScheduler\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import PIL\n",
    "\n",
    "######################\n",
    "# rough深度的onnx推理准备\n",
    "import onnxruntime as ort\n",
    "\n",
    "import cv2\n",
    "from typing import Tuple, Dict, List\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter  \n",
    "\n",
    "\n",
    "\n",
    "onnx_model_dir=\"/home/ubunto/Project/konglx/mono_depth/Metric3D-main/onnx/metric3d-vit-small/onnx/model.onnx\"\n",
    "onnx_seg_dir = '/home/ubunto/Project/konglx/seg/UniMatch-main/resnet101_se_rand_cut_element.onnx'\n",
    "def prepare_input(\n",
    "    rgb_image: np.ndarray, input_size: Tuple[int, int]\n",
    ") -> Tuple[Dict[str, np.ndarray], List[int]]:\n",
    "\n",
    "    h, w = rgb_image.shape[:2] # 原图尺寸\n",
    "    scale = min(input_size[0] / h, input_size[1] / w)\n",
    "    rgb = cv2.resize(\n",
    "        rgb_image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    padding = [123.675, 116.28, 103.53]\n",
    "    h, w = rgb.shape[:2]\n",
    "    pad_h = input_size[0] - h\n",
    "    pad_w = input_size[1] - w\n",
    "    pad_h_half = pad_h // 2  # h方向，每边padding的尺寸\n",
    "    pad_w_half = pad_w // 2  # w方向，每边padding的尺寸\n",
    "    rgb: np.ndarray = cv2.copyMakeBorder(\n",
    "        rgb,\n",
    "        pad_h_half,\n",
    "        pad_h - pad_h_half,\n",
    "        pad_w_half,\n",
    "        pad_w - pad_w_half,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=padding,\n",
    "    )\n",
    "    pad_info = [pad_h_half, pad_h - pad_h_half, pad_w_half, pad_w - pad_w_half]\n",
    "\n",
    "    onnx_input = {\n",
    "        # \"image\": np.ascontiguousarray(\n",
    "        \"pixel_values\": np.ascontiguousarray(\n",
    "            np.transpose(rgb, (2, 0, 1))[None], dtype=np.float32\n",
    "        ),  # 1, 3, H, W\n",
    "    }\n",
    "    return onnx_input, pad_info\n",
    "\n",
    "def onnx_inference(onnx_model_dir: str, input_image: np):\n",
    "\n",
    "    ## Dummy Test\n",
    "    B = 1\n",
    "    if \"vit\" in onnx_model_dir:\n",
    "        input_size = (616, 1064)  # [H, W]\n",
    "        if 'fp16' in onnx_model_dir:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float16)\n",
    "        else:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "    else:\n",
    "        input_size = (544, 1216)  # [H, W]\n",
    "        dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "\n",
    "    providers = [\n",
    "        (\n",
    "            \"CUDAExecutionProvider\",\n",
    "            {\"cudnn_conv_use_max_workspace\": \"0\", \"device_id\": str(0)},\n",
    "        )\n",
    "    ]\n",
    "    # providers = [(\"TensorrtExecutionProvider\", {'trt_engine_cache_enable': True, 'trt_fp16_enable': True, 'device_id': 0, 'trt_dla_enable': False})]\n",
    "    ort_session = ort.InferenceSession(onnx_model_dir, providers=providers)\n",
    "\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "    out_name = ort_session.get_outputs()[0].name\n",
    "    print(input_name, out_name, sep='\\n')\n",
    "    # outputs = ort_session.run(None, {\"image\": dummy_image})\n",
    "    outputs = ort_session.run(None, {input_name: dummy_image})\n",
    "\n",
    "    print(\n",
    "        f\"The actual output of onnxruntime session for the dummy set: outputs[0].shape={outputs[0].shape}\"\n",
    "    )\n",
    "    # input_iamge = input_image\n",
    "    # print(np.unique(input_image))\n",
    "\n",
    "    original_shape = input_image.shape[:2]\n",
    "    onnx_input, pad_info = prepare_input(input_image, input_size)  # rgb_image是原图形状[512,512], input_size = (616, 1064)\n",
    "    outputs = ort_session.run(None, onnx_input)\n",
    "    depth = outputs[0].squeeze()  # [H, W]\n",
    "    # plt.imshow(depth)\n",
    "    # Reshape the depth to the original size\n",
    "    depth = depth[\n",
    "        pad_info[0] : input_size[0] - pad_info[1],\n",
    "        pad_info[2] : input_size[1] - pad_info[3],\n",
    "    ]\n",
    "    depth = cv2.resize(\n",
    "        depth, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "    return depth\n",
    "\n",
    "\n",
    "def merge_org_with_mask_for_org_mask(org_pil, mask_pil):\n",
    "    # img_name_list = os.listdir(org_dir)\n",
    "    # for each_name in img_name_list:\n",
    "    # name = each_name.split('.')[0]\n",
    "    image_np = np.array(load_image(org_pil))\n",
    "    image_pt = transforms.ToTensor()(image_np)\n",
    "    # print('image_pt.shape', image_pt.shape)\n",
    "    \n",
    "    conditioning_np = np.array(mask_pil)\n",
    "    conditioning_np_rgb = np.array(mask_pil.convert('RGB'))\n",
    "    # print('image_np.shape:', image_np.shape)\n",
    "    # print('conditioning_np.shape:', conditioning_np.shape, np.unique(conditioning_np))\n",
    "    # print('conditioning_np_rgb.shape:', conditioning_np_rgb.shape, np.unique(conditioning_np_rgb))\n",
    "    \n",
    "    # image_np[conditioning_np != 0] = conditioning_np_rgb[conditioning_np != 0]\n",
    "    # cv2.imshow('conditioning_np_rgb', np.array(conditioning_np_rgb)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    conditioning_pt = transforms.ToTensor()(conditioning_np)\n",
    "    conditioning_pt_rgb = transforms.ToTensor()(conditioning_np_rgb)\n",
    "    # print('conditioning_pt.shape', conditioning_pt.shape)\n",
    "    # print('conditioning_pt_rgb.shape', conditioning_pt_rgb.shape)\n",
    "    # print(conditioning_pt_rgb)\n",
    "\n",
    "    \n",
    "    ## image_with_conditioning_pt = image_pt * (torch.where(conditioning_pt_rgb>0.95, 0, 1)) + conditioning_pt_rgb\n",
    "    print('torch.max(conditioning_pt_rgb):', torch.max(conditioning_pt_rgb))\n",
    "    image_pt[conditioning_pt.repeat(3,1,1) != 0] = conditioning_pt_rgb[conditioning_pt.repeat(3,1,1) != 0]\n",
    "    image_with_conditioning_pil = transforms.ToPILImage()(image_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # image_with_conditioning_pil = transforms.ToPILImage()(image_with_conditioning_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return image_with_conditioning_pil\n",
    "\n",
    "def merge_org_with_mask_for_tag3_ellipse_corrosion(org_pil, mask_pil):\n",
    "    # img_name_list = os.listdir(org_dir)\n",
    "    # for each_name in img_name_list:\n",
    "    # name = each_name.split('.')[0]\n",
    "    image_np = np.array(load_image(org_pil))\n",
    "    image_pt = transforms.ToTensor()(image_np)\n",
    "    # print('image_pt.shape', image_pt.shape)\n",
    "    \n",
    "    conditioning_np = np.array(mask_pil)\n",
    "    conditioning_np_rgb = np.array(mask_pil.convert('RGB'))\n",
    "    # print('image_np.shape:', image_np.shape)\n",
    "    # print('conditioning_np.shape:', conditioning_np.shape, np.unique(conditioning_np))\n",
    "    # print('conditioning_np_rgb.shape:', conditioning_np_rgb.shape, np.unique(conditioning_np_rgb))\n",
    "    \n",
    "    # image_np[conditioning_np != 0] = conditioning_np_rgb[conditioning_np != 0]\n",
    "    # cv2.imshow('conditioning_np_rgb', np.array(conditioning_np_rgb)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    conditioning_pt = transforms.ToTensor()(conditioning_np)\n",
    "    conditioning_pt_rgb = transforms.ToTensor()(conditioning_np_rgb)\n",
    "    # print('conditioning_pt.shape', conditioning_pt.shape)\n",
    "    # print('conditioning_pt_rgb.shape', conditioning_pt_rgb.shape)\n",
    "    # print(conditioning_pt_rgb)\n",
    "\n",
    "    \n",
    "    ## image_with_conditioning_pt = image_pt * (torch.where(conditioning_pt_rgb>0.95, 0, 1)) + conditioning_pt_rgb\n",
    "    print('torch.max(conditioning_pt_rgb):', torch.max(conditioning_pt_rgb))\n",
    "    image_pt[conditioning_pt.repeat(3,1,1) != 0] = conditioning_pt_rgb[conditioning_pt.repeat(3,1,1) != 0]\n",
    "    image_with_conditioning_pil = transforms.ToPILImage()(image_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # image_with_conditioning_pil = transforms.ToPILImage()(image_with_conditioning_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return image_with_conditioning_pil\n",
    "################################\n",
    "# 1.用训练好的构件识别模型进行分割\n",
    "################################\n",
    "\n",
    "\n",
    "\n",
    "###### 定义选定区域内生成若干数量的椭圆的腐蚀#######\n",
    "################################\n",
    "# 1.定义分割构件和生成椭圆的函数\n",
    "################################\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "# from dataset.semi import normalize\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import imgviz\n",
    "\n",
    "\n",
    "\n",
    "def normalize(img, mask=None):\n",
    "    img = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])(img)\n",
    "    if mask is not None:\n",
    "        mask = torch.from_numpy(np.array(mask)).long()\n",
    "        return img, mask\n",
    "    return img\n",
    "\n",
    "\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "## 分割构件\n",
    "def seg_members(onnx_dir, img_pil):\n",
    "    # 加载模型\n",
    "    img_input = normalize(img_pil)\n",
    "    # 对于onnx需要指定输入的shape\n",
    "    resize = transforms.Resize([512,512])\n",
    "    img_input = resize(img_input)\n",
    "    print(img_input.shape)\n",
    "    # img_tensor = torch.from_numpy(img_input).type(torch.cuda.FloatTensor)\n",
    "    img_tensor = img_input.unsqueeze(0).cuda()\n",
    "    img_np = img_tensor.detach().cpu().numpy()\n",
    "    print(img_np.shape)\n",
    "    ort_session = ort.InferenceSession(onnx_dir) # 创建一个推理session\n",
    "\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: img_np}\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "    ort_outs = ort_session.run(None, ort_inputs)[0]\n",
    "    # 通过 get_inputs()[i].name来获取输入的名称\n",
    "    end = time.time()\n",
    "    print(\"onnx预测时间：\", end-start)\n",
    "    print(ort_outs.shape,  type(ort_outs))\n",
    "    # print(ort_outs)\n",
    "\n",
    "    # 输出为4分类，即，c=4的图像，取最大的通道，合并，即为预测图像\n",
    "    # numpy转torch\n",
    "    pred = torch.from_numpy(ort_outs)\n",
    "    pred_softmax = pred.softmax(dim=1).max(dim=1)[1]\n",
    "    print(pred_softmax.shape)\n",
    "    # print(pred_softmax)\n",
    "\n",
    "    pred_np = pred_softmax.numpy()[0]\n",
    "    # 对预测的mask用colored_mask上色\n",
    "    pred_pil_np = colored_mask(pred_np)\n",
    "    pred_np_cls = np.unique(pred_np)\n",
    "    \n",
    "    return pred_pil_np, pred_np_cls\n",
    "\n",
    "\n",
    "###### 定义选定区域内生成若干数量的椭圆的腐蚀#######\n",
    "def generate_ellipse_to_want_area(org_img_np, generate_ellipses, fill_value, want_area = [1,4], num_ellipses=25, a_min=30, a_max=100, b_min=20, b_max=40, split_everywhere=False):\n",
    "    \"\"\"\n",
    "    generate_ellipsepolygon_to_want_area based on function 'generate_polygon'.\n",
    "\n",
    "    Args:\n",
    "        org_img_np (numpy.ndarray): The input array.\n",
    "        generate_polygon (function): generate_polygon\n",
    "        want_area_list (list or tuple, optional): A list or tuple of values to consider as the selected region.\n",
    "                                          Default is [1,4].\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A new array with the same shape as the input array,\n",
    "                       containing the generated and filled polygon.\n",
    "    \"\"\"\n",
    "    fill_value = severe_dict[fill_value]\n",
    "    # 选择腐蚀类型\n",
    "    # corrosionType = [3] # 腐蚀类型： 1-fair，2-poor， 3-severe\n",
    "    list_area_corrosion = []\n",
    "    list_area_only_corrosion = []\n",
    "    for area in want_area:\n",
    "        gen_polygon, gen_polygon_blank = generate_ellipses(arr=org_img_np, fill_value=fill_value, values=area, num_ellipses=num_ellipses, a_min=a_min, a_max=a_max, b_min=b_min, b_max=b_max, split_everywhere=split_everywhere)\n",
    "        list_area_corrosion.append(gen_polygon)\n",
    "        list_area_only_corrosion.append(gen_polygon_blank)\n",
    "    sum_area = np.sum(list_area_corrosion, axis=0)\n",
    "    sum_area_only_corrosion = np.sum(list_area_only_corrosion, axis=0)\n",
    "    return sum_area, list_area_corrosion, sum_area_only_corrosion, list_area_only_corrosion\n",
    "\n",
    "########### 定义基于numpy选择构件的函数#####\n",
    "\n",
    "def filter_array(arr, values):\n",
    "    \"\"\"\n",
    "    Filter a NumPy array to keep only the specified values.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): The input array to be filtered.\n",
    "        values (list or tuple): A list or tuple of values to keep in the filtered array.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A new array with the same shape as the input array,\n",
    "                       containing only the specified values.\n",
    "    \"\"\"\n",
    "    conditions = [arr == value for value in values]\n",
    "    condition = np.logical_or.reduce(conditions)\n",
    "    filtered_arr = np.where(condition, arr, 0)\n",
    "    return filtered_arr\n",
    "\n",
    "################### 选择腐蚀类型 ######################\n",
    "# corrosionType = [3] # 腐蚀类型： 1-fair，2-poor， 3-severe\n",
    "def corrosionType_to_fill_value(corrosionType):\n",
    "    fill_value = []\n",
    "    for i in corrosionType:\n",
    "        if i==1:\n",
    "            fill_value.append(12)\n",
    "        elif i==2:\n",
    "            fill_value.append(6)\n",
    "        elif i==3:\n",
    "            fill_value.append(4)\n",
    "    return fill_value\n",
    "\n",
    "# fill_value_list = corrosionType_to_fill_value(corrosionType=corrosionType) # 以12为总数量，fill_value与corrosionType对应：腐蚀类型： 1-fair对应12/12，2-poor对应12/6， 3-severe对应12/4\n",
    "\n",
    "\n",
    "################### 定义和生成椭圆 ######################\n",
    "def generate_ellipses(arr, fill_value=1, values=[5], num_ellipses=5, a_min=30, a_max=120, b_min=10, b_max=80, split_everywhere=True):\n",
    "    \"\"\"\n",
    "    🕐用少数量的大椭圆，模拟大片的腐蚀；\n",
    "    🕑用多数量的小椭圆，模拟pitting corrosion\n",
    "    Generate random quadrilaterals within the specified regions of a NumPy array\n",
    "    and fill them with a specified value.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): The input array.\n",
    "        num_polygons (int): The number of quadrilaterals to generate.\n",
    "        fill_value (int, optional): The value to use for filling the quadrilaterals. Default is 1.\n",
    "        values (list or tuple, optional): A list or tuple of values to consider as the selected region.\n",
    "                                          Default is [1].\n",
    "\n",
    "    Returns:\n",
    "        tuple(numpy.ndarray): A new array with the same shape as the input array,\n",
    "                       containing the generated and filled quadrilaterals.\n",
    "    \"\"\"\n",
    "    \n",
    "    selected_region = np.isin(arr, values)\n",
    "    # print(selected_region)\n",
    "    selected_coords = np.argwhere(selected_region)\n",
    "    print('可选的坐标点数：',len(selected_coords))\n",
    "    # # 椭圆数量和范围\n",
    "    # num_ellipses = 5\n",
    "    # a_min, a_max = 20, 50\n",
    "    # b_min, b_max = 10, 30\n",
    "    \n",
    "    result = arr.copy()\n",
    "    image = Image.fromarray(result)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # 空白mask\n",
    "    result_blank = np.zeros_like(result)\n",
    "    # print(result_blank)\n",
    "    image_blank = Image.fromarray(result_blank)\n",
    "    draw_blank = ImageDraw.Draw(image_blank)\n",
    "    # # 生成图片\n",
    "    # im = Image.new('RGB', (100,100), color='white')  \n",
    "    # draw = ImageDraw.Draw(im)\n",
    "    if split_everywhere:\n",
    "        for i in range(num_ellipses):\n",
    "            xy_arr = random.sample(list(selected_coords), k=1)\n",
    "            # print(random.sample(list(selected_coords), k=2), random.sample(list(selected_coords), k=3))\n",
    "            print(xy_arr[0][0])\n",
    "            y, x = xy_arr[0][0], xy_arr[0][1]\n",
    "            # 随机生成长短半轴\n",
    "            a = random.randint(a_min, a_max)\n",
    "            b = random.randint(b_min, b_max)\n",
    "            \n",
    "            # 随机中心点\n",
    "            # x = random.randint(0, 100-a)\n",
    "            # y = random.randint(0, 100-b)\n",
    "            \n",
    "            # 绘制椭圆\n",
    "            draw.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "            draw_blank.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "        \n",
    "        result = np.array(image)\n",
    "        result_mask = np.array(image_blank)\n",
    "    else:\n",
    "        selected_coords_with_according_to_num_ellipses_list = []\n",
    "        xy_arr_0 = random.sample(list(selected_coords), k=1)[0]\n",
    "        selected_coords_with_according_to_num_ellipses_list.append(xy_arr_0)\n",
    "        count_num = 0\n",
    "        for i in list(selected_coords):\n",
    "            dist = ((i[0]-xy_arr_0[0])**2 + (i[1]-xy_arr_0[1])**2)**0.5\n",
    "            if dist<= (a_max + b_max):\n",
    "                selected_coords_with_according_to_num_ellipses_list.append(i)\n",
    "                xy_arr_0 = i\n",
    "                count_num += 1\n",
    "                # print(count_num)\n",
    "                # print('a')\n",
    "                if count_num == num_ellipses*3:\n",
    "                    break\n",
    "            \n",
    "        \n",
    "        # selected_coords_with_according_to_num_ellipses_np = np.array(selected_coords_with_according_to_num_ellipses_list)\n",
    "        for i in range(num_ellipses):\n",
    "            xy_arr = random.sample(selected_coords_with_according_to_num_ellipses_list, k=1)\n",
    "            # print(random.sample(list(selected_coords), k=2), random.sample(list(selected_coords), k=3))\n",
    "            # print(xy_arr[0][0])\n",
    "            y, x = xy_arr[0][0], xy_arr[0][1]\n",
    "            # 随机生成长短半轴\n",
    "            a = random.randint(a_min, a_max)\n",
    "            b = random.randint(b_min, b_max)\n",
    "            \n",
    "            # 随机中心点\n",
    "            # x = random.randint(0, 100-a)\n",
    "            # y = random.randint(0, 100-b)\n",
    "            \n",
    "            # 绘制椭圆\n",
    "            draw.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "            draw_blank.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "        \n",
    "        result = np.array(image)\n",
    "        result_mask = np.array(image_blank)\n",
    "\n",
    "            \n",
    "    \n",
    "    return result, result_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################\n",
    "#  controlnet模型准备\n",
    "def controlnet_diff(corrosion_with_bg_pil, mask_depth_pil, prompt = '',device = 'cuda',seed = 2024,use_freeu = False,\n",
    "                    config_dir = '/home/ubunto/Project/konglx/generate/ControlNet/models/stable-diffusion-v1-5',\n",
    "                    control_corrosion_with_bg_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_corrosion_with_background_merge_inpainting_h-512_w-512_2024-07-29_13:19:18_seeds-2024/checkpoint-5700/controlnet',\n",
    "                    control_depth_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_depth_h-512_w-512_2024-07-16_17:42:27_seeds-2024/checkpoint-2000/controlnet',\n",
    "                    scheduler_select = 'PNDM',\n",
    "                    inference_steps=20,\n",
    "                    guidance_scale=7.5,control_strength=1.0\n",
    "                    ):\n",
    "    with torch.no_grad():\n",
    "        print('scheduler_select:', scheduler_select)\n",
    "        controlnet_corrosion_with_bg = ControlNetModel.from_pretrained(control_corrosion_with_bg_trained_dir)\n",
    "        controlnet_depth = ControlNetModel.from_pretrained(control_depth_trained_dir)\n",
    "        if scheduler_select == 'PNDM' or scheduler_select == None:\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None).to(device)\n",
    "        elif scheduler_select == 'DDPM':\n",
    "            # scheduler DDPM\n",
    "            scheduler = DDPMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        elif scheduler_select == 'DDIM':\n",
    "            # scheduler DDIM\n",
    "            scheduler = DDIMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "        pipeline.unet.use_freeu = use_freeu \n",
    "        \n",
    "        controlnet_conditioning_scale_list=[control_strength,1.0]\n",
    "        mask_corrosion_with_bg_pil = load_image(corrosion_with_bg_pil)\n",
    "        mask_depth_pil = load_image(mask_depth_pil)\n",
    "        validation_image = [mask_corrosion_with_bg_pil, mask_depth_pil]\n",
    "        image = pipeline(prompt, validation_image, num_inference_steps=inference_steps, generator=generator, controlnet_conditioning_scale=controlnet_conditioning_scale_list,\n",
    "                        guidance_scale=guidance_scale,\n",
    "                            ).images[0]\n",
    "    torch.cuda.empty_cache()\n",
    "    return image\n",
    "\n",
    "#######################\n",
    "# crack\n",
    "def controlnet_diff_crack(crack_pil, prompt = 'crack on concrete surface',device = 'cuda',seed = 2024,use_freeu = False,control_strength=1.0,\n",
    "                    config_dir = '/home/ubunto/Project/konglx/generate/ControlNet/models/stable-diffusion-v1-5',\n",
    "                    control_crack_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_crack_without_bg_with_prompt_inpainting_h-512_w-512_2024-11-22_13:28:33_seeds-2024/checkpoint-2400/controlnet',\n",
    "                    scheduler_select = 'PNDM',\n",
    "                    inference_steps=20,\n",
    "                    guidance_scale=7.5,\n",
    "                    ):\n",
    "    with torch.no_grad():\n",
    "        print('scheduler_select:', scheduler_select)\n",
    "        controlnet_crack = ControlNetModel.from_pretrained(control_crack_trained_dir)\n",
    " \n",
    "        if scheduler_select == 'PNDM' or scheduler_select == None:\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_crack], safety_checker=None, iter_times=5).to(device)\n",
    "        elif scheduler_select == 'DDPM':\n",
    "            # scheduler DDPM\n",
    "            scheduler = DDPMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_crack], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        elif scheduler_select == 'DDIM':\n",
    "            # scheduler DDIM\n",
    "            scheduler = DDIMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_crack], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "        pipeline.unet.use_freeu = use_freeu \n",
    "        \n",
    "\n",
    "        mask_crack_pil = load_image(crack_pil)\n",
    "        controlnet_conditioning_scale_list=[control_strength,1.0]\n",
    "        validation_image = [mask_crack_pil]\n",
    "        image = pipeline(prompt, validation_image, num_inference_steps=inference_steps, generator=generator, controlnet_conditioning_scale=controlnet_conditioning_scale_list,\n",
    "                        guidance_scale=guidance_scale,\n",
    "                            ).images[0]\n",
    "    torch.cuda.empty_cache()\n",
    "    return image\n",
    "#######################\n",
    "\n",
    "################################\n",
    "# gradio的功能接口定义\n",
    "def show_image(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024, control_strength=1.0):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    org_rgb_image_pil = Image.fromarray(org_rgb_image)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "    \n",
    "    # merged_org_img_with_mask_pil = merge_org_with_mask_for_org_mask(org_pil=org_rgb_image_pil, mask_pil=rgb_image_pil)\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,control_strength=control_strength)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "def show_image_crack(img, prompt='crack on concrete surface', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024, control_strength=1.0):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img\n",
    "    # org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    # org_rgb_image_pil = Image.fromarray(org_rgb_image)\n",
    "    masked_image =resize_image(input_image_np, image_resolution)\n",
    "    masked_image_pil = Image.fromarray(masked_image)\n",
    "    # tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    # vmin = np.percentile(tiff_np, 2)\n",
    "    # vmax = np.percentile(tiff_np, 85)\n",
    "    # # print(vmin, vmax)\n",
    "\n",
    "    # tiff_np -= vmin\n",
    "    # tiff_np /= vmax - vmin\n",
    "    # tiff_np = 1.0 - tiff_np\n",
    "    # tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    # tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "    \n",
    "    # merged_org_img_with_mask_pil = merge_org_with_mask_for_org_mask(org_pil=org_rgb_image_pil, mask_pil=rgb_image_pil)\n",
    "    out_control_diff_pil = controlnet_diff_crack(crack_pil=masked_image_pil, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,control_strength=control_strength)\n",
    "    \n",
    "    return [out_control_diff_pil]\n",
    "\n",
    "def show_image_draw(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024, control_strength=1.0):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img['composite']\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    org_rgb_image_pil = Image.fromarray(org_rgb_image)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "\n",
    "    # merged_org_img_with_mask_pil = merge_org_with_mask(org_pil=org_rgb_image_pil, mask_pil=rgb_image_pil)\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,control_strength=control_strength)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "\n",
    "def show_image_members_seg(org_img,  prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024,split_everywhere = False, fill_value_setting = 'poor', num_ellipse='15', control_strength=1.0 ):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    \n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    org_rgb_image_pil = Image.fromarray(org_rgb_image)\n",
    "    # seg members->分割构件\n",
    "    # 定义numpy的随机模式\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    pred_pil, pred_np_cls = seg_members(onnx_dir='/home/ubunto/Project/konglx/seg/UniMatch-main/resnet101_se_rand_cut_element.onnx', \n",
    "                                       img_pil=org_rgb_image_pil)\n",
    "    print(np.array(pred_pil), pred_np_cls)\n",
    "    mask_members_np_mode_R = np.array(pred_pil)\n",
    "    # select_area_list = [np.random.choice(pred_np_cls[1:])]\n",
    "    print('******* Detected members *******',mask_members_np_mode_R)\n",
    "    # 选择构件区域\n",
    "    mask_members_np_mode_R_filter = filter_array(mask_members_np_mode_R, mask_members_np_mode_R)\n",
    "    print('构件mask的形状和元素值', mask_members_np_mode_R_filter.shape, np.unique(mask_members_np_mode_R_filter))\n",
    "    ## 找到最大的构件区域\n",
    "    # max_num_area = np.argmax(np.bincount(mask_members_np_mode_R_filter))\n",
    "    # 将数组展平成一维数组  \n",
    "    # flattened_mask_members_np_mode_R_filter = mask_members_np_mode_R_filter.flatten()  \n",
    "    flattened_mask_members_np_mode_R_filter = mask_members_np_mode_R_filter[mask_members_np_mode_R_filter != 0]\n",
    "    \n",
    "    # 使用Counter统计每个元素出现的次数  \n",
    "    counter = Counter(flattened_mask_members_np_mode_R_filter)  \n",
    "    \n",
    "    # 找到出现次数最多的元素及其值  \n",
    "    most_common_element, count = counter.most_common(1)[0] \n",
    "    print('最多出现的元素及其值:', most_common_element, count, members_text_dict[str(most_common_element.tolist())])\n",
    "    # cv2.imshow('pred_np_cls', mask_members_np_mode_R_filter)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # 4.在members指定区域生成任意数量的腐蚀，返回仅仅为腐蚀区域 （生成用）\n",
    "    num_ellipse = int(num_ellipse)\n",
    "    mask_corrosion_corr_to_members, mask_corrosion_corr_to_members_list, mask_only_corrosion_corr_to_members, mask_only_corrosion_corr_to_members_list = generate_ellipse_to_want_area(org_img_np=mask_members_np_mode_R, generate_ellipses=generate_ellipses, fill_value=fill_value_setting, want_area=[most_common_element], split_everywhere=split_everywhere, num_ellipses=num_ellipse)\n",
    "    # plt.imshow(mask_corrosion_corr_to_members)\n",
    "\n",
    "    # mask_only_corrosion_corr_to_members_devide_by_fill_value = (mask_only_corrosion_corr_to_members/fill_value_setting).astype((np.uint64))\n",
    "    mask_only_corrosion_corr_to_members_devide_by_fill_value = (12/mask_only_corrosion_corr_to_members).astype((np.uint64))\n",
    "    print(mask_only_corrosion_corr_to_members_devide_by_fill_value.min(), mask_only_corrosion_corr_to_members_devide_by_fill_value.max(), np.unique(mask_only_corrosion_corr_to_members_devide_by_fill_value), mask_only_corrosion_corr_to_members_devide_by_fill_value.dtype)\n",
    "    # print(np.unique(mask_only_corrosion_corr_to_members/12), mask_only_corrosion_corr_to_members.dtype, ((mask_only_corrosion_corr_to_members/12).astype(np.uint64)).dtype)\n",
    "\n",
    "    mask_only_corrosion_final_pil = colored_mask(mask_only_corrosion_corr_to_members_devide_by_fill_value)\n",
    "    # cv2.imshow('mask_only_corrosion_final_pil', mask_only_corrosion_final_pil)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # 5.在腐蚀区域生成椭圆，返回椭圆区域 （生成用）\n",
    "    # rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    # rgb_image_pil = Image.fromarray(rgb_image) \n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "    \n",
    "    merged_org_img_with_mask_pil = merge_org_with_mask_for_tag3_ellipse_corrosion(org_pil=org_rgb_image_pil, mask_pil=mask_only_corrosion_final_pil)\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=merged_org_img_with_mask_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,control_strength=control_strength)\n",
    "    \n",
    "    return [tiff_pil_uint8, pred_pil, mask_only_corrosion_final_pil, merged_org_img_with_mask_pil, out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "\n",
    "\n",
    "# 绘图\n",
    "def create_canvas(w, h):\n",
    "    return np.zeros(shape=(h, w, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "brush_colors = gr.Brush()\n",
    "# brush_colors.colors=[\n",
    "                \n",
    "#                 \"rgb(0, 128, 0)\", # poor\n",
    "                \n",
    "#                 ] \n",
    "# brush_colors.colors=[\n",
    "                \n",
    "#                 \"rgb(128, 128, 0)\",\"rgb(0, 128, 0)\",\"rgb(128, 0, 0)\",]\n",
    "\n",
    "brush_colors.colors=[\n",
    "                \n",
    "                \"rgb(0, 128, 0)\",\"rgb(128, 128, 0)\",\"rgb(128, 0, 0)\",]\n",
    "\n",
    "# brush_colors.colors=[\n",
    "                \n",
    "#                 \"rgb(128, 0, 0)\",\"rgb(128, 128, 0)\",\"rgb(0, 128, 0)\",]\n",
    "# print()\n",
    "print(brush_colors.colors\n",
    "                # format=\"png\",\n",
    "                )\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "\n",
    "\n",
    "def sleep(im):\n",
    "    # # time.sleep(5)\n",
    "    # # return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1],im[\"composite\"]]\n",
    "    # return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    "    print('im:', im)\n",
    "    if len(im[\"layers\"]) == 0:\n",
    "        im[\"layers\"].append(np.zeros((512, 512, 4), np.uint8))\n",
    "    # im[\"layers\"][0]=cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB )\n",
    "    return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    " \n",
    "def upim(im_in,im):\n",
    "    print('******type(im_in), im_in.shape,im:******', type(im_in), im_in.shape,im)#, type(im), im)\n",
    "    height, width, channels = im_in.shape[:3]\n",
    "    im[\"background\"]=im_in\n",
    "    im[\"layers\"][0]=np.zeros((height, width, 4), np.uint8)\n",
    "    #im[\"layers\"][1]=None\n",
    "\n",
    "    print(f\" shape:{im_in.shape}, ndim:{im_in.ndim}, size:{im_in.size}\")\n",
    "    return gr.ImageMask(value=im,height=600,width=600)\n",
    "\n",
    "\n",
    "def saveimg(im):\n",
    "    #print(im[\"layers\"][0])\n",
    "    background=im[\"background\"]\n",
    "    composite=im[\"composite\"]\n",
    "    background=cv2.cvtColor(background, cv2.COLOR_BGR2RGB )\n",
    "    composite=cv2.cvtColor(composite, cv2.COLOR_BGR2RGB )\n",
    "    img_layer = cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"layers0.png\",img_layer)\n",
    "    cv2.imwrite(\"background.png\",background)\n",
    "    cv2.imwrite(\"composite.png\",composite)\n",
    "    return gr.ImageMask(value=im,height=600,width=600), background\n",
    "\n",
    "# inputs_np=gr.Image(type=\"numpy\")\n",
    "\n",
    "CACHE_EXAMPLES = torch.cuda.is_available() and os.getenv(\"CACHE_EXAMPLES\", \"0\") == \"1\"\n",
    "org_img_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/images/00003.jpg'\n",
    "masked_corrosion_with_bg_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/conditioning_images/00003.png'\n",
    "examples = [ [load_image(org_img_dir)]]\n",
    "examples_mask = [[load_image(masked_corrosion_with_bg_dir)]]\n",
    "\n",
    "\n",
    "org_crack_mask_dir1 = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/crack_without_bg_for_test/conditioning_images/DeepCrack_11158.png'\n",
    "org_crack_mask_dir2 = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/crack_without_bg_for_test/conditioning_images/CRACK500_20160222_164141_641_721.png'\n",
    "examples_crack_mask = [[load_image(org_crack_mask_dir1)], [load_image(org_crack_mask_dir2)]]\n",
    "\n",
    "\n",
    "# 设置严重程度字典（这个用于生成椭圆）\n",
    "severe_dict = {'fair': 12, 'poor': 6,'severe': 4}\n",
    "\n",
    "members_text_dict = {'1': 'Bearing', '2': 'Bracing','3': 'Deck', '4':'Floor beam','5': 'Girder','6': 'Substructure','7': 'Gusset plate','8': 'Chord'\n",
    "                     ,'9': 'Vertical ','10': 'Diagonal','11': 'Railing'}\n",
    "def get_key(val, my_dict):\n",
    "    for key, value in my_dict.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "\n",
    "    return \"There is no such Key\"\n",
    "\n",
    "MCD = gr.Blocks(title=\"Multi-Control corrosion generator\").queue()\n",
    "with MCD:\n",
    "    gr.Markdown('Multi-Control corrosion generator')\n",
    "    ###################################################  Tab 1  ###################################################\n",
    "\n",
    "    with gr.Tab('Draw corrosion images'):\n",
    "        # with gr.Blocks():\n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_img = gr.Image(type=\"numpy\", label=\"Original Image Tab 1\")\n",
    "                print('this is org_img:', np.array(org_img).shape)\n",
    "                \n",
    "                im = gr.ImageEditor(\n",
    "                    type=\"numpy\",\n",
    "                    crop_size=\"1:1\",\n",
    "                    height=512,\n",
    "                    width=512,\n",
    "                    brush=brush_colors,\n",
    "                    label='Draw',\n",
    "                    canvas_size=(512, 512),\n",
    "                    sources='upload',\n",
    "                )\n",
    "        \n",
    "        with gr.Row():\n",
    "            \n",
    "            uploadbtn = gr.Button(\"image upload\")\n",
    "            savebtn = gr.Button(\"save\")\n",
    "            print('this is org_img:', np.array(org_img).shape)\n",
    "            uploadbtn.click(upim,[org_img,im],[im])\n",
    "        \n",
    "        \n",
    "        # im =gr.Sketchpad(type=\"pil\",\n",
    "        #     crop_size=\"1:1\",)\n",
    "    \n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                im_out_1 = gr.Image(type=\"numpy\", label='background')\n",
    "                im_out_2 = gr.Image(type=\"numpy\", label='mask')\n",
    "                im_out_3 = gr.Image(type=\"numpy\", label='mask with background')\n",
    "                # im_out_4 = gr.Image(type=\"numpy\")\n",
    "        # btn = gr.Button()\n",
    "        im.change(sleep, outputs=[im_out_1, im_out_2, im_out_3], inputs=im)\n",
    "        savebtn.click(saveimg, outputs=[im, im_out_2], inputs=im)\n",
    "        # btn = gr.Button()\n",
    "\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "        #         org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "        #         ##\n",
    "        #         draw = gr.ImageEditor(label='Draw corrosion', type=\"numpy\")#,height=image_resolution, width=image_resolution)\n",
    "        #         print(draw, type(draw))\n",
    "\n",
    "                \n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "    # with gr.Tab('Use test images'):\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "                # org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_img, im, prompt, image_resolution, scheduler_select, inference_steps,scale, seed, strength]\n",
    "        run_button.click(fn=show_image_draw, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=org_img,\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image_draw,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                # gr.Examples(\n",
    "                # label='Example: Masked corrosion with background',\n",
    "                # examples=examples_mask,\n",
    "                # inputs=inputs[1],\n",
    "                # outputs=[result_gallery_depth],\n",
    "                # fn=show_image,\n",
    "                # cache_examples=CACHE_EXAMPLES,\n",
    "                # )\n",
    "   ###################################################  Tab 2  ###################################################           \n",
    "    with gr.Tab('Use test images for crack generation'):\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_image_pil = gr.Image(type=\"numpy\", label='Original Image Tab 2')\n",
    "                masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_image_pil, masked_corrosion_with_bg_pil, prompt, image_resolution, scheduler_select, inference_steps,scale, seed, strength]\n",
    "        run_button.click(fn=show_image, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=inputs[0],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Masked corrosion with background',\n",
    "                examples=examples_mask,\n",
    "                inputs=inputs[1],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "        ###################################################  Tab 3  ###################################################           \n",
    "    with gr.Tab('Find members then draw corrosion images'):\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_image_pil = gr.Image(type=\"numpy\", label='Original Image Tab 3')\n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                split_everywhere = gr.Radio(['True', 'False'], label='Split everywhere or not', info='Split everywhere or not', visible=True)\n",
    "                fill_value_setting = gr.Radio(severe_dict.keys(), label='Fill value setting', info='Fill value setting', visible=True)\n",
    "                num_ellipse = gr.Textbox(placeholder=\"How many ellipses do you want to draw?\",label=\"Number of ellipses\")\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=5.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    \n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_seg_members = gr.Gallery(label='Output segmented members', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_image_pil, prompt, image_resolution, scheduler_select, inference_steps,scale, seed, split_everywhere, fill_value_setting, num_ellipse, strength]\n",
    "        run_button.click(fn=show_image_members_seg, inputs=inputs, outputs=[result_gallery_seg_members])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=inputs[0],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                # gr.Examples(\n",
    "                # label='Example: Masked corrosion with background',\n",
    "                # examples=examples_mask,\n",
    "                # inputs=inputs[1],\n",
    "                # outputs=[result_gallery_depth],\n",
    "                # fn=show_image,\n",
    "                # cache_examples=CACHE_EXAMPLES,\n",
    "                # )\n",
    "   ###################################################  Tab 4  ###################################################           \n",
    "    with gr.Tab('Use test images for crack generation'):\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                # org_image_pil = gr.Image(type=\"numpy\", label='Original Image Tab 4')\n",
    "                masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked cracks')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='crack on concrete surface, high resolution')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=1024, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.1)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery = gr.Gallery(label='Output of Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [masked_corrosion_with_bg_pil, prompt, image_resolution, scheduler_select, inference_steps,scale, seed, strength]\n",
    "        run_button.click(fn=show_image_crack, inputs=inputs, outputs=[result_gallery])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Masked cracks',\n",
    "                examples=examples_crack_mask,\n",
    "                inputs=inputs[0],\n",
    "                outputs=[result_gallery],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                # gr.Examples(\n",
    "                # label='Example: Masked corrosion with background',\n",
    "                # examples=examples_mask,\n",
    "                # inputs=inputs[1],\n",
    "                # outputs=[result_gallery_depth],\n",
    "                # fn=show_image,\n",
    "                # cache_examples=CACHE_EXAMPLES,\n",
    "                # )\n",
    "# MCD.launch(share=True)\n",
    "MCD.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这个有绘制腐蚀，腐蚀mask贴图以及自动分割构件，进行腐蚀生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录为 /home/ubunto/Project/konglx/generate/diffusers/UI\n",
      "目录修改成功 /home/ubunto/Project/konglx/generate/diffusers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rgb(128, 128, 0)', 'rgb(0, 128, 0)', 'rgb(128, 0, 0)']\n",
      "this is org_img: ()\n",
      "this is org_img: ()\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7f4f81e5f3d0>\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7f4f81ea4970>\n",
      "<class 'gradio.components.radio.Radio'> <gradio.components.radio.Radio object at 0x7f4f81e5f040>\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 这个有绘制腐蚀，腐蚀mask贴图以及自动分割构件，进行腐蚀生成。\n",
    "# from share import *\n",
    "# import config\n",
    "import imgviz\n",
    "import os\n",
    "# 查看当前工作目录\n",
    "retval = os.getcwd()\n",
    "print(\"当前工作目录为 %s\" % retval)\n",
    "os.chdir('/home/ubunto/Project/konglx/generate/diffusers')\n",
    "\n",
    "# 查看修改后的工作目录\n",
    "retval = os.getcwd()\n",
    "\n",
    "print(\"目录修改成功 %s\" % retval)\n",
    "\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# from pytorch_lightning import seed_everything\n",
    "from annotator.util import resize_image, HWC3\n",
    "from annotator.midas import MidasDetector\n",
    "# from cldm.model import create_model, load_state_dict\n",
    "# from cldm.ddim_hacked import DDIMSampler\n",
    "from diffusers import DDPMPipeline, DDIMPipeline, DDIMScheduler, DDPMScheduler\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import PIL\n",
    "\n",
    "######################\n",
    "# rough深度的onnx推理准备\n",
    "import onnxruntime as ort\n",
    "\n",
    "import cv2\n",
    "from typing import Tuple, Dict, List\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter  \n",
    "\n",
    "\n",
    "\n",
    "onnx_model_dir=\"/home/ubunto/Project/konglx/mono_depth/Metric3D-main/onnx/metric3d-vit-small/onnx/model.onnx\"\n",
    "onnx_seg_dir = '/home/ubunto/Project/konglx/seg/UniMatch-main/resnet101_se_rand_cut_element.onnx'\n",
    "def prepare_input(\n",
    "    rgb_image: np.ndarray, input_size: Tuple[int, int]\n",
    ") -> Tuple[Dict[str, np.ndarray], List[int]]:\n",
    "\n",
    "    h, w = rgb_image.shape[:2] # 原图尺寸\n",
    "    scale = min(input_size[0] / h, input_size[1] / w)\n",
    "    rgb = cv2.resize(\n",
    "        rgb_image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    padding = [123.675, 116.28, 103.53]\n",
    "    h, w = rgb.shape[:2]\n",
    "    pad_h = input_size[0] - h\n",
    "    pad_w = input_size[1] - w\n",
    "    pad_h_half = pad_h // 2  # h方向，每边padding的尺寸\n",
    "    pad_w_half = pad_w // 2  # w方向，每边padding的尺寸\n",
    "    rgb: np.ndarray = cv2.copyMakeBorder(\n",
    "        rgb,\n",
    "        pad_h_half,\n",
    "        pad_h - pad_h_half,\n",
    "        pad_w_half,\n",
    "        pad_w - pad_w_half,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=padding,\n",
    "    )\n",
    "    pad_info = [pad_h_half, pad_h - pad_h_half, pad_w_half, pad_w - pad_w_half]\n",
    "\n",
    "    onnx_input = {\n",
    "        # \"image\": np.ascontiguousarray(\n",
    "        \"pixel_values\": np.ascontiguousarray(\n",
    "            np.transpose(rgb, (2, 0, 1))[None], dtype=np.float32\n",
    "        ),  # 1, 3, H, W\n",
    "    }\n",
    "    return onnx_input, pad_info\n",
    "\n",
    "def onnx_inference(onnx_model_dir: str, input_image: np):\n",
    "\n",
    "    ## Dummy Test\n",
    "    B = 1\n",
    "    if \"vit\" in onnx_model_dir:\n",
    "        input_size = (616, 1064)  # [H, W]\n",
    "        if 'fp16' in onnx_model_dir:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float16)\n",
    "        else:\n",
    "            dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "    else:\n",
    "        input_size = (544, 1216)  # [H, W]\n",
    "        dummy_image = np.zeros([B, 3, input_size[0], input_size[1]], dtype=np.float32)\n",
    "\n",
    "    providers = [\n",
    "        (\n",
    "            \"CUDAExecutionProvider\",\n",
    "            {\"cudnn_conv_use_max_workspace\": \"0\", \"device_id\": str(0)},\n",
    "        )\n",
    "    ]\n",
    "    # providers = [(\"TensorrtExecutionProvider\", {'trt_engine_cache_enable': True, 'trt_fp16_enable': True, 'device_id': 0, 'trt_dla_enable': False})]\n",
    "    ort_session = ort.InferenceSession(onnx_model_dir, providers=providers)\n",
    "\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "    out_name = ort_session.get_outputs()[0].name\n",
    "    print(input_name, out_name, sep='\\n')\n",
    "    # outputs = ort_session.run(None, {\"image\": dummy_image})\n",
    "    outputs = ort_session.run(None, {input_name: dummy_image})\n",
    "\n",
    "    print(\n",
    "        f\"The actual output of onnxruntime session for the dummy set: outputs[0].shape={outputs[0].shape}\"\n",
    "    )\n",
    "    # input_iamge = input_image\n",
    "    # print(np.unique(input_image))\n",
    "\n",
    "    original_shape = input_image.shape[:2]\n",
    "    onnx_input, pad_info = prepare_input(input_image, input_size)  # rgb_image是原图形状[512,512], input_size = (616, 1064)\n",
    "    outputs = ort_session.run(None, onnx_input)\n",
    "    depth = outputs[0].squeeze()  # [H, W]\n",
    "    # plt.imshow(depth)\n",
    "    # Reshape the depth to the original size\n",
    "    depth = depth[\n",
    "        pad_info[0] : input_size[0] - pad_info[1],\n",
    "        pad_info[2] : input_size[1] - pad_info[3],\n",
    "    ]\n",
    "    depth = cv2.resize(\n",
    "        depth, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "    return depth\n",
    "\n",
    "\n",
    "def merge_org_with_mask_for_org_mask(org_pil, mask_pil):\n",
    "    # img_name_list = os.listdir(org_dir)\n",
    "    # for each_name in img_name_list:\n",
    "    # name = each_name.split('.')[0]\n",
    "    image_np = np.array(load_image(org_pil))\n",
    "    image_pt = transforms.ToTensor()(image_np)\n",
    "    # print('image_pt.shape', image_pt.shape)\n",
    "    \n",
    "    conditioning_np = np.array(mask_pil)\n",
    "    conditioning_np_rgb = np.array(mask_pil.convert('RGB'))\n",
    "    # print('image_np.shape:', image_np.shape)\n",
    "    # print('conditioning_np.shape:', conditioning_np.shape, np.unique(conditioning_np))\n",
    "    # print('conditioning_np_rgb.shape:', conditioning_np_rgb.shape, np.unique(conditioning_np_rgb))\n",
    "    \n",
    "    # image_np[conditioning_np != 0] = conditioning_np_rgb[conditioning_np != 0]\n",
    "    # cv2.imshow('conditioning_np_rgb', np.array(conditioning_np_rgb)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    conditioning_pt = transforms.ToTensor()(conditioning_np)\n",
    "    conditioning_pt_rgb = transforms.ToTensor()(conditioning_np_rgb)\n",
    "    # print('conditioning_pt.shape', conditioning_pt.shape)\n",
    "    # print('conditioning_pt_rgb.shape', conditioning_pt_rgb.shape)\n",
    "    # print(conditioning_pt_rgb)\n",
    "\n",
    "    \n",
    "    ## image_with_conditioning_pt = image_pt * (torch.where(conditioning_pt_rgb>0.95, 0, 1)) + conditioning_pt_rgb\n",
    "    print('torch.max(conditioning_pt_rgb):', torch.max(conditioning_pt_rgb))\n",
    "    image_pt[conditioning_pt.repeat(3,1,1) != 0] = conditioning_pt_rgb[conditioning_pt.repeat(3,1,1) != 0]\n",
    "    image_with_conditioning_pil = transforms.ToPILImage()(image_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # image_with_conditioning_pil = transforms.ToPILImage()(image_with_conditioning_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return image_with_conditioning_pil\n",
    "\n",
    "def merge_org_with_mask_for_tag3_ellipse_corrosion(org_pil, mask_pil):\n",
    "    # img_name_list = os.listdir(org_dir)\n",
    "    # for each_name in img_name_list:\n",
    "    # name = each_name.split('.')[0]\n",
    "    image_np = np.array(load_image(org_pil))\n",
    "    image_pt = transforms.ToTensor()(image_np)\n",
    "    # print('image_pt.shape', image_pt.shape)\n",
    "    \n",
    "    conditioning_np = np.array(mask_pil)\n",
    "    conditioning_np_rgb = np.array(mask_pil.convert('RGB'))\n",
    "    # print('image_np.shape:', image_np.shape)\n",
    "    # print('conditioning_np.shape:', conditioning_np.shape, np.unique(conditioning_np))\n",
    "    # print('conditioning_np_rgb.shape:', conditioning_np_rgb.shape, np.unique(conditioning_np_rgb))\n",
    "    \n",
    "    # image_np[conditioning_np != 0] = conditioning_np_rgb[conditioning_np != 0]\n",
    "    # cv2.imshow('conditioning_np_rgb', np.array(conditioning_np_rgb)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    conditioning_pt = transforms.ToTensor()(conditioning_np)\n",
    "    conditioning_pt_rgb = transforms.ToTensor()(conditioning_np_rgb)\n",
    "    # print('conditioning_pt.shape', conditioning_pt.shape)\n",
    "    # print('conditioning_pt_rgb.shape', conditioning_pt_rgb.shape)\n",
    "    # print(conditioning_pt_rgb)\n",
    "\n",
    "    \n",
    "    ## image_with_conditioning_pt = image_pt * (torch.where(conditioning_pt_rgb>0.95, 0, 1)) + conditioning_pt_rgb\n",
    "    print('torch.max(conditioning_pt_rgb):', torch.max(conditioning_pt_rgb))\n",
    "    image_pt[conditioning_pt.repeat(3,1,1) != 0] = conditioning_pt_rgb[conditioning_pt.repeat(3,1,1) != 0]\n",
    "    image_with_conditioning_pil = transforms.ToPILImage()(image_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # image_with_conditioning_pil = transforms.ToPILImage()(image_with_conditioning_pt)\n",
    "    # cv2.imshow('image_with_conditioning_pil', np.array(image_with_conditioning_pil)[:,:,::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return image_with_conditioning_pil\n",
    "################################\n",
    "# 1.用训练好的构件识别模型进行分割\n",
    "################################\n",
    "\n",
    "\n",
    "\n",
    "###### 定义选定区域内生成若干数量的椭圆的腐蚀#######\n",
    "################################\n",
    "# 1.定义分割构件和生成椭圆的函数\n",
    "################################\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "# from dataset.semi import normalize\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import imgviz\n",
    "\n",
    "\n",
    "\n",
    "def normalize(img, mask=None):\n",
    "    img = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])(img)\n",
    "    if mask is not None:\n",
    "        mask = torch.from_numpy(np.array(mask)).long()\n",
    "        return img, mask\n",
    "    return img\n",
    "\n",
    "\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "## 分割构件\n",
    "def seg_members(onnx_dir, img_pil):\n",
    "    # 加载模型\n",
    "    img_input = normalize(img_pil)\n",
    "    # 对于onnx需要指定输入的shape\n",
    "    resize = transforms.Resize([512,512])\n",
    "    img_input = resize(img_input)\n",
    "    print(img_input.shape)\n",
    "    # img_tensor = torch.from_numpy(img_input).type(torch.cuda.FloatTensor)\n",
    "    img_tensor = img_input.unsqueeze(0).cuda()\n",
    "    img_np = img_tensor.detach().cpu().numpy()\n",
    "    print(img_np.shape)\n",
    "    ort_session = ort.InferenceSession(onnx_dir) # 创建一个推理session\n",
    "\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: img_np}\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "    ort_outs = ort_session.run(None, ort_inputs)[0]\n",
    "    # 通过 get_inputs()[i].name来获取输入的名称\n",
    "    end = time.time()\n",
    "    print(\"onnx预测时间：\", end-start)\n",
    "    print(ort_outs.shape,  type(ort_outs))\n",
    "    # print(ort_outs)\n",
    "\n",
    "    # 输出为4分类，即，c=4的图像，取最大的通道，合并，即为预测图像\n",
    "    # numpy转torch\n",
    "    pred = torch.from_numpy(ort_outs)\n",
    "    pred_softmax = pred.softmax(dim=1).max(dim=1)[1]\n",
    "    print(pred_softmax.shape)\n",
    "    # print(pred_softmax)\n",
    "\n",
    "    pred_np = pred_softmax.numpy()[0]\n",
    "    # 对预测的mask用colored_mask上色\n",
    "    pred_pil_np = colored_mask(pred_np)\n",
    "    pred_np_cls = np.unique(pred_np)\n",
    "    \n",
    "    return pred_pil_np, pred_np_cls\n",
    "\n",
    "\n",
    "###### 定义选定区域内生成若干数量的椭圆的腐蚀#######\n",
    "def generate_ellipse_to_want_area(org_img_np, generate_ellipses, fill_value, want_area = [1,4], num_ellipses=25, a_min=30, a_max=100, b_min=20, b_max=40, split_everywhere=False):\n",
    "    \"\"\"\n",
    "    generate_ellipsepolygon_to_want_area based on function 'generate_polygon'.\n",
    "\n",
    "    Args:\n",
    "        org_img_np (numpy.ndarray): The input array.\n",
    "        generate_polygon (function): generate_polygon\n",
    "        want_area_list (list or tuple, optional): A list or tuple of values to consider as the selected region.\n",
    "                                          Default is [1,4].\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A new array with the same shape as the input array,\n",
    "                       containing the generated and filled polygon.\n",
    "    \"\"\"\n",
    "    fill_value = severe_dict[fill_value]\n",
    "    # 选择腐蚀类型\n",
    "    # corrosionType = [3] # 腐蚀类型： 1-fair，2-poor， 3-severe\n",
    "    list_area_corrosion = []\n",
    "    list_area_only_corrosion = []\n",
    "    for area in want_area:\n",
    "        gen_polygon, gen_polygon_blank = generate_ellipses(arr=org_img_np, fill_value=fill_value, values=area, num_ellipses=num_ellipses, a_min=a_min, a_max=a_max, b_min=b_min, b_max=b_max, split_everywhere=split_everywhere)\n",
    "        list_area_corrosion.append(gen_polygon)\n",
    "        list_area_only_corrosion.append(gen_polygon_blank)\n",
    "    sum_area = np.sum(list_area_corrosion, axis=0)\n",
    "    sum_area_only_corrosion = np.sum(list_area_only_corrosion, axis=0)\n",
    "    return sum_area, list_area_corrosion, sum_area_only_corrosion, list_area_only_corrosion\n",
    "\n",
    "########### 定义基于numpy选择构件的函数#####\n",
    "\n",
    "def filter_array(arr, values):\n",
    "    \"\"\"\n",
    "    Filter a NumPy array to keep only the specified values.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): The input array to be filtered.\n",
    "        values (list or tuple): A list or tuple of values to keep in the filtered array.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A new array with the same shape as the input array,\n",
    "                       containing only the specified values.\n",
    "    \"\"\"\n",
    "    conditions = [arr == value for value in values]\n",
    "    condition = np.logical_or.reduce(conditions)\n",
    "    filtered_arr = np.where(condition, arr, 0)\n",
    "    return filtered_arr\n",
    "\n",
    "################### 选择腐蚀类型 ######################\n",
    "# corrosionType = [3] # 腐蚀类型： 1-fair，2-poor， 3-severe\n",
    "def corrosionType_to_fill_value(corrosionType):\n",
    "    fill_value = []\n",
    "    for i in corrosionType:\n",
    "        if i==1:\n",
    "            fill_value.append(12)\n",
    "        elif i==2:\n",
    "            fill_value.append(6)\n",
    "        elif i==3:\n",
    "            fill_value.append(4)\n",
    "    return fill_value\n",
    "\n",
    "# fill_value_list = corrosionType_to_fill_value(corrosionType=corrosionType) # 以12为总数量，fill_value与corrosionType对应：腐蚀类型： 1-fair对应12/12，2-poor对应12/6， 3-severe对应12/4\n",
    "\n",
    "\n",
    "################### 定义和生成椭圆 ######################\n",
    "def generate_ellipses(arr, fill_value=1, values=[5], num_ellipses=5, a_min=30, a_max=120, b_min=10, b_max=80, split_everywhere=True):\n",
    "    \"\"\"\n",
    "    🕐用少数量的大椭圆，模拟大片的腐蚀；\n",
    "    🕑用多数量的小椭圆，模拟pitting corrosion\n",
    "    Generate random quadrilaterals within the specified regions of a NumPy array\n",
    "    and fill them with a specified value.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): The input array.\n",
    "        num_polygons (int): The number of quadrilaterals to generate.\n",
    "        fill_value (int, optional): The value to use for filling the quadrilaterals. Default is 1.\n",
    "        values (list or tuple, optional): A list or tuple of values to consider as the selected region.\n",
    "                                          Default is [1].\n",
    "\n",
    "    Returns:\n",
    "        tuple(numpy.ndarray): A new array with the same shape as the input array,\n",
    "                       containing the generated and filled quadrilaterals.\n",
    "    \"\"\"\n",
    "    \n",
    "    selected_region = np.isin(arr, values)\n",
    "    # print(selected_region)\n",
    "    selected_coords = np.argwhere(selected_region)\n",
    "    print('可选的坐标点数：',len(selected_coords))\n",
    "    # # 椭圆数量和范围\n",
    "    # num_ellipses = 5\n",
    "    # a_min, a_max = 20, 50\n",
    "    # b_min, b_max = 10, 30\n",
    "    \n",
    "    result = arr.copy()\n",
    "    image = Image.fromarray(result)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # 空白mask\n",
    "    result_blank = np.zeros_like(result)\n",
    "    # print(result_blank)\n",
    "    image_blank = Image.fromarray(result_blank)\n",
    "    draw_blank = ImageDraw.Draw(image_blank)\n",
    "    # # 生成图片\n",
    "    # im = Image.new('RGB', (100,100), color='white')  \n",
    "    # draw = ImageDraw.Draw(im)\n",
    "    if split_everywhere:\n",
    "        for i in range(num_ellipses):\n",
    "            xy_arr = random.sample(list(selected_coords), k=1)\n",
    "            # print(random.sample(list(selected_coords), k=2), random.sample(list(selected_coords), k=3))\n",
    "            print(xy_arr[0][0])\n",
    "            y, x = xy_arr[0][0], xy_arr[0][1]\n",
    "            # 随机生成长短半轴\n",
    "            a = random.randint(a_min, a_max)\n",
    "            b = random.randint(b_min, b_max)\n",
    "            \n",
    "            # 随机中心点\n",
    "            # x = random.randint(0, 100-a)\n",
    "            # y = random.randint(0, 100-b)\n",
    "            \n",
    "            # 绘制椭圆\n",
    "            draw.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "            draw_blank.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "        \n",
    "        result = np.array(image)\n",
    "        result_mask = np.array(image_blank)\n",
    "    else:\n",
    "        selected_coords_with_according_to_num_ellipses_list = []\n",
    "        xy_arr_0 = random.sample(list(selected_coords), k=1)[0]\n",
    "        selected_coords_with_according_to_num_ellipses_list.append(xy_arr_0)\n",
    "        count_num = 0\n",
    "        for i in list(selected_coords):\n",
    "            dist = ((i[0]-xy_arr_0[0])**2 + (i[1]-xy_arr_0[1])**2)**0.5\n",
    "            if dist<= (a_max + b_max):\n",
    "                selected_coords_with_according_to_num_ellipses_list.append(i)\n",
    "                xy_arr_0 = i\n",
    "                count_num += 1\n",
    "                # print(count_num)\n",
    "                # print('a')\n",
    "                if count_num == num_ellipses*3:\n",
    "                    break\n",
    "            \n",
    "        \n",
    "        # selected_coords_with_according_to_num_ellipses_np = np.array(selected_coords_with_according_to_num_ellipses_list)\n",
    "        for i in range(num_ellipses):\n",
    "            xy_arr = random.sample(selected_coords_with_according_to_num_ellipses_list, k=1)\n",
    "            # print(random.sample(list(selected_coords), k=2), random.sample(list(selected_coords), k=3))\n",
    "            # print(xy_arr[0][0])\n",
    "            y, x = xy_arr[0][0], xy_arr[0][1]\n",
    "            # 随机生成长短半轴\n",
    "            a = random.randint(a_min, a_max)\n",
    "            b = random.randint(b_min, b_max)\n",
    "            \n",
    "            # 随机中心点\n",
    "            # x = random.randint(0, 100-a)\n",
    "            # y = random.randint(0, 100-b)\n",
    "            \n",
    "            # 绘制椭圆\n",
    "            draw.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "            draw_blank.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "        \n",
    "        result = np.array(image)\n",
    "        result_mask = np.array(image_blank)\n",
    "\n",
    "            \n",
    "    \n",
    "    return result, result_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################\n",
    "#  controlnet模型准备\n",
    "def controlnet_diff(corrosion_with_bg_pil, mask_depth_pil, prompt = '',device = 'cuda',seed = 2024,use_freeu = False,controlnet_conditioning_scale_list=[1.0,1.0],\n",
    "                    config_dir = '/home/ubunto/Project/konglx/generate/ControlNet/models/stable-diffusion-v1-5',\n",
    "                    control_corrosion_with_bg_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_corrosion_with_background_merge_inpainting_h-512_w-512_2024-07-29_13:19:18_seeds-2024/checkpoint-5700/controlnet',\n",
    "                    control_depth_trained_dir = '/home/ubunto/Project/konglx/generate/diffusers/examples/controlnet/controlnet-model_depth_h-512_w-512_2024-07-16_17:42:27_seeds-2024/checkpoint-2000/controlnet',\n",
    "                    scheduler_select = 'PNDM',\n",
    "                    inference_steps=20,\n",
    "                    guidance_scale=7.5,\n",
    "                    ):\n",
    "    with torch.no_grad():\n",
    "        print('scheduler_select:', scheduler_select)\n",
    "        controlnet_corrosion_with_bg = ControlNetModel.from_pretrained(control_corrosion_with_bg_trained_dir)\n",
    "        controlnet_depth = ControlNetModel.from_pretrained(control_depth_trained_dir)\n",
    "        if scheduler_select == 'PNDM' or scheduler_select == None:\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None).to(device)\n",
    "        elif scheduler_select == 'DDPM':\n",
    "            # scheduler DDPM\n",
    "            scheduler = DDPMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        elif scheduler_select == 'DDIM':\n",
    "            # scheduler DDIM\n",
    "            scheduler = DDIMScheduler.from_pretrained(config_dir, subfolder=\"scheduler\")\n",
    "            pipeline = StableDiffusionControlNetPipeline.from_pretrained(config_dir, controlnet=[controlnet_corrosion_with_bg, controlnet_depth], safety_checker=None, scheduler=scheduler).to(device)\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "        pipeline.unet.use_freeu = use_freeu \n",
    "        \n",
    "\n",
    "        mask_corrosion_with_bg_pil = load_image(corrosion_with_bg_pil)\n",
    "        mask_depth_pil = load_image(mask_depth_pil)\n",
    "        validation_image = [mask_corrosion_with_bg_pil, mask_depth_pil]\n",
    "        image = pipeline(prompt, validation_image, num_inference_steps=inference_steps, generator=generator, controlnet_conditioning_scale=controlnet_conditioning_scale_list,\n",
    "                        guidance_scale=guidance_scale,\n",
    "                            ).images[0]\n",
    "    torch.cuda.empty_cache()\n",
    "    return image\n",
    "#######################\n",
    "\n",
    "################################\n",
    "# gradio的功能接口定义\n",
    "def show_image(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    org_rgb_image_pil = Image.fromarray(org_rgb_image)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "    \n",
    "    # merged_org_img_with_mask_pil = merge_org_with_mask_for_org_mask(org_pil=org_rgb_image_pil, mask_pil=rgb_image_pil)\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "\n",
    "def show_image_draw(org_img, img, prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    input_image_np = img['composite']\n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    org_rgb_image_pil = Image.fromarray(org_rgb_image)\n",
    "    rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "\n",
    "    # merged_org_img_with_mask_pil = merge_org_with_mask(org_pil=org_rgb_image_pil, mask_pil=rgb_image_pil)\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=rgb_image_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8,out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "\n",
    "def show_image_members_seg(org_img,  prompt='', image_resolution=512, scheduler_select='PNDM',\n",
    "               inference_steps=20, guidance_scale=7.5,seed=2024,split_everywhere = False, fill_value_setting = 'poor', num_ellipse='15' ):\n",
    "\n",
    "    # Convert To PIL Image\n",
    "    # image = Image.open(img)\n",
    "    # print(type(image))\n",
    "\n",
    "    # # Convert the image to a NumPy array\n",
    "    # image_array = np.array(image)\n",
    "    # print(type(image_array))\n",
    "    # input_image_np = (img.astype(np.float32) / 255.0) * 2 - 1\n",
    "    # print('scheduler_select:', scheduler_select)\n",
    "    \n",
    "    org_rgb_image =resize_image(org_img, image_resolution)\n",
    "    org_rgb_image_pil = Image.fromarray(org_rgb_image)\n",
    "    # seg members->分割构件\n",
    "    # 定义numpy的随机模式\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    pred_pil, pred_np_cls = seg_members(onnx_dir='/home/ubunto/Project/konglx/seg/UniMatch-main/resnet101_se_rand_cut_element.onnx', \n",
    "                                       img_pil=org_rgb_image_pil)\n",
    "    print(np.array(pred_pil), pred_np_cls)\n",
    "    mask_members_np_mode_R = np.array(pred_pil)\n",
    "    # select_area_list = [np.random.choice(pred_np_cls[1:])]\n",
    "    print('******* Detected members *******',mask_members_np_mode_R)\n",
    "    # 选择构件区域\n",
    "    mask_members_np_mode_R_filter = filter_array(mask_members_np_mode_R, mask_members_np_mode_R)\n",
    "    print('构件mask的形状和元素值', mask_members_np_mode_R_filter.shape, np.unique(mask_members_np_mode_R_filter))\n",
    "    ## 找到最大的构件区域\n",
    "    # max_num_area = np.argmax(np.bincount(mask_members_np_mode_R_filter))\n",
    "    # 将数组展平成一维数组  \n",
    "    # flattened_mask_members_np_mode_R_filter = mask_members_np_mode_R_filter.flatten()  \n",
    "    flattened_mask_members_np_mode_R_filter = mask_members_np_mode_R_filter[mask_members_np_mode_R_filter != 0]\n",
    "    \n",
    "    # 使用Counter统计每个元素出现的次数  \n",
    "    counter = Counter(flattened_mask_members_np_mode_R_filter)  \n",
    "    \n",
    "    # 找到出现次数最多的元素及其值  \n",
    "    most_common_element, count = counter.most_common(1)[0] \n",
    "    print('最多出现的元素及其值:', most_common_element, count, members_text_dict[str(most_common_element.tolist())])\n",
    "    # cv2.imshow('pred_np_cls', mask_members_np_mode_R_filter)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # 4.在members指定区域生成任意数量的腐蚀，返回仅仅为腐蚀区域 （生成用）\n",
    "    num_ellipse = int(num_ellipse)\n",
    "    mask_corrosion_corr_to_members, mask_corrosion_corr_to_members_list, mask_only_corrosion_corr_to_members, mask_only_corrosion_corr_to_members_list = generate_ellipse_to_want_area(org_img_np=mask_members_np_mode_R, generate_ellipses=generate_ellipses, fill_value=fill_value_setting, want_area=[most_common_element], split_everywhere=split_everywhere, num_ellipses=num_ellipse)\n",
    "    # plt.imshow(mask_corrosion_corr_to_members)\n",
    "\n",
    "    # mask_only_corrosion_corr_to_members_devide_by_fill_value = (mask_only_corrosion_corr_to_members/fill_value_setting).astype((np.uint64))\n",
    "    mask_only_corrosion_corr_to_members_devide_by_fill_value = (12/mask_only_corrosion_corr_to_members).astype((np.uint64))\n",
    "    print(mask_only_corrosion_corr_to_members_devide_by_fill_value.min(), mask_only_corrosion_corr_to_members_devide_by_fill_value.max(), np.unique(mask_only_corrosion_corr_to_members_devide_by_fill_value), mask_only_corrosion_corr_to_members_devide_by_fill_value.dtype)\n",
    "    # print(np.unique(mask_only_corrosion_corr_to_members/12), mask_only_corrosion_corr_to_members.dtype, ((mask_only_corrosion_corr_to_members/12).astype(np.uint64)).dtype)\n",
    "\n",
    "    mask_only_corrosion_final_pil = colored_mask(mask_only_corrosion_corr_to_members_devide_by_fill_value)\n",
    "    # cv2.imshow('mask_only_corrosion_final_pil', mask_only_corrosion_final_pil)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # 5.在腐蚀区域生成椭圆，返回椭圆区域 （生成用）\n",
    "    # rgb_image =resize_image(input_image_np, image_resolution)\n",
    "    # rgb_image_pil = Image.fromarray(rgb_image) \n",
    "    tiff_np = onnx_inference(onnx_model_dir=onnx_model_dir, input_image=org_rgb_image)\n",
    "    vmin = np.percentile(tiff_np, 2)\n",
    "    vmax = np.percentile(tiff_np, 85)\n",
    "    # print(vmin, vmax)\n",
    "\n",
    "    tiff_np -= vmin\n",
    "    tiff_np /= vmax - vmin\n",
    "    tiff_np = 1.0 - tiff_np\n",
    "    tiff_np_uint8 = (tiff_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    tiff_pil_uint8 = Image.fromarray(tiff_np_uint8)\n",
    "    # print(np.unique(tiff_np_uint8))\n",
    "    # print(type(tiff_np_uint8))\n",
    "    \n",
    "    merged_org_img_with_mask_pil = merge_org_with_mask_for_tag3_ellipse_corrosion(org_pil=org_rgb_image_pil, mask_pil=mask_only_corrosion_final_pil)\n",
    "    out_control_diff_pil = controlnet_diff(corrosion_with_bg_pil=merged_org_img_with_mask_pil, mask_depth_pil=tiff_pil_uint8, \n",
    "                                           prompt=prompt,scheduler_select=scheduler_select, \n",
    "                                           inference_steps=inference_steps, guidance_scale=guidance_scale,\n",
    "                                           seed=seed,)\n",
    "    \n",
    "    return [tiff_pil_uint8, pred_pil, mask_only_corrosion_final_pil, merged_org_img_with_mask_pil, out_control_diff_pil]\n",
    "    # return tiff_pil_uint8,out_control_diff_pil\n",
    "\n",
    "\n",
    "\n",
    "# 绘图\n",
    "def create_canvas(w, h):\n",
    "    return np.zeros(shape=(h, w, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "brush_colors = gr.Brush()\n",
    "# brush_colors.colors=[\n",
    "                \n",
    "#                 \"rgb(0, 128, 0)\", # poor\n",
    "                \n",
    "#                 ] \n",
    "brush_colors.colors=[\n",
    "                \n",
    "                \"rgb(128, 128, 0)\",\"rgb(0, 128, 0)\",\"rgb(128, 0, 0)\",]\n",
    "\n",
    "# brush_colors.colors=[\n",
    "                \n",
    "#                 \"rgb(128, 0, 0)\",\"rgb(128, 128, 0)\",\"rgb(0, 128, 0)\",]\n",
    "# print()\n",
    "print(brush_colors.colors\n",
    "                # format=\"png\",\n",
    "                )\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "\n",
    "\n",
    "def sleep(im):\n",
    "    # # time.sleep(5)\n",
    "    # # return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1],im[\"composite\"]]\n",
    "    # return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    "    print('im:', im)\n",
    "    if len(im[\"layers\"]) == 0:\n",
    "        im[\"layers\"].append(np.zeros((512, 512, 4), np.uint8))\n",
    "    # im[\"layers\"][0]=cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB )\n",
    "    return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    " \n",
    "def upim(im_in,im):\n",
    "    print('******type(im_in), im_in.shape,im:******', type(im_in), im_in.shape,im)#, type(im), im)\n",
    "    height, width, channels = im_in.shape[:3]\n",
    "    im[\"background\"]=im_in\n",
    "    im[\"layers\"][0]=np.zeros((height, width, 4), np.uint8)\n",
    "    #im[\"layers\"][1]=None\n",
    "\n",
    "    print(f\" shape:{im_in.shape}, ndim:{im_in.ndim}, size:{im_in.size}\")\n",
    "    return gr.ImageMask(value=im,height=600,width=600)\n",
    "\n",
    "\n",
    "def saveimg(im):\n",
    "    #print(im[\"layers\"][0])\n",
    "    background=im[\"background\"]\n",
    "    composite=im[\"composite\"]\n",
    "    background=cv2.cvtColor(background, cv2.COLOR_BGR2RGB )\n",
    "    composite=cv2.cvtColor(composite, cv2.COLOR_BGR2RGB )\n",
    "    img_layer = cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"layers0.png\",img_layer)\n",
    "    cv2.imwrite(\"background.png\",background)\n",
    "    cv2.imwrite(\"composite.png\",composite)\n",
    "    return gr.ImageMask(value=im,height=600,width=600), background\n",
    "\n",
    "# inputs_np=gr.Image(type=\"numpy\")\n",
    "\n",
    "CACHE_EXAMPLES = torch.cuda.is_available() and os.getenv(\"CACHE_EXAMPLES\", \"0\") == \"1\"\n",
    "org_img_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/images/00003.jpg'\n",
    "masked_corrosion_with_bg_dir = '/home/ubunto/Project/konglx/generate/diffusers/datasets/corrosion_and_crack/corrosion_with_background_for_test/conditioning_images/00003.png'\n",
    "examples = [ [load_image(org_img_dir)]]\n",
    "examples_mask = [[load_image(masked_corrosion_with_bg_dir)]]\n",
    "\n",
    "# 设置严重程度字典（这个用于生成椭圆）\n",
    "severe_dict = {'fair': 12, 'poor': 6,'severe': 4}\n",
    "\n",
    "members_text_dict = {'1': 'Bearing', '2': 'Bracing','3': 'Deck', '4':'Floor beam','5': 'Girder','6': 'Substructure','7': 'Gusset plate','8': 'Chord'\n",
    "                     ,'9': 'Vertical ','10': 'Diagonal','11': 'Railing'}\n",
    "def get_key(val, my_dict):\n",
    "    for key, value in my_dict.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "\n",
    "    return \"There is no such Key\"\n",
    "\n",
    "MCD = gr.Blocks(title=\"Multi-Control corrosion generator\").queue()\n",
    "with MCD:\n",
    "    gr.Markdown('Multi-Control corrosion generator')\n",
    "    ###################################################  Tab 1  ###################################################\n",
    "\n",
    "    with gr.Tab('Draw corrosion images'):\n",
    "        # with gr.Blocks():\n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_img = gr.Image(type=\"numpy\", label=\"Original Image Tab 1\")\n",
    "                print('this is org_img:', np.array(org_img).shape)\n",
    "                \n",
    "                im = gr.ImageEditor(\n",
    "                    type=\"numpy\",\n",
    "                    crop_size=\"1:1\",\n",
    "                    height=512,\n",
    "                    width=512,\n",
    "                    brush=brush_colors,\n",
    "                    label='Draw',\n",
    "                    canvas_size=(512, 512),\n",
    "                    sources='upload',\n",
    "                )\n",
    "        \n",
    "        with gr.Row():\n",
    "            \n",
    "            uploadbtn = gr.Button(\"image upload\")\n",
    "            savebtn = gr.Button(\"save\")\n",
    "            print('this is org_img:', np.array(org_img).shape)\n",
    "            uploadbtn.click(upim,[org_img,im],[im])\n",
    "        \n",
    "        \n",
    "        # im =gr.Sketchpad(type=\"pil\",\n",
    "        #     crop_size=\"1:1\",)\n",
    "    \n",
    "        # with gr.Group():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                im_out_1 = gr.Image(type=\"numpy\", label='background')\n",
    "                im_out_2 = gr.Image(type=\"numpy\", label='mask')\n",
    "                im_out_3 = gr.Image(type=\"numpy\", label='mask with background')\n",
    "                # im_out_4 = gr.Image(type=\"numpy\")\n",
    "        # btn = gr.Button()\n",
    "        im.change(sleep, outputs=[im_out_1, im_out_2, im_out_3], inputs=im)\n",
    "        savebtn.click(saveimg, outputs=[im, im_out_2], inputs=im)\n",
    "        # btn = gr.Button()\n",
    "\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "        #         org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "        #         ##\n",
    "        #         draw = gr.ImageEditor(label='Draw corrosion', type=\"numpy\")#,height=image_resolution, width=image_resolution)\n",
    "        #         print(draw, type(draw))\n",
    "\n",
    "                \n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "    # with gr.Tab('Use test images'):\n",
    "        # with gr.Column():\n",
    "        #     with gr.Row():\n",
    "                # org_image_pil = gr.Image(type=\"numpy\", label='Original image')\n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_img, im, prompt, image_resolution, scheduler_select, inference_steps,scale, seed]\n",
    "        run_button.click(fn=show_image_draw, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=org_img,\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image_draw,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                # gr.Examples(\n",
    "                # label='Example: Masked corrosion with background',\n",
    "                # examples=examples_mask,\n",
    "                # inputs=inputs[1],\n",
    "                # outputs=[result_gallery_depth],\n",
    "                # fn=show_image,\n",
    "                # cache_examples=CACHE_EXAMPLES,\n",
    "                # )\n",
    "   ###################################################  Tab 2  ###################################################           \n",
    "    with gr.Tab('Use test images'):\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_image_pil = gr.Image(type=\"numpy\", label='Original Image Tab 2')\n",
    "                masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=2.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_image_pil, masked_corrosion_with_bg_pil, prompt, image_resolution, scheduler_select, inference_steps,scale, seed]\n",
    "        run_button.click(fn=show_image, inputs=inputs, outputs=[result_gallery_depth])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=inputs[0],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Masked corrosion with background',\n",
    "                examples=examples_mask,\n",
    "                inputs=inputs[1],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "        ###################################################  Tab 3  ###################################################           \n",
    "    with gr.Tab('Find members then draw corrosion images'):\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                org_image_pil = gr.Image(type=\"numpy\", label='Original Image Tab 3')\n",
    "                # masked_corrosion_with_bg_pil = gr.Image(type=\"numpy\", label='Masked corrosion with background')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                scheduler_select = gr.Radio(['PNDM', 'DDPM', 'DDIM'], label='Scheduler', info='Which scheduler to use for diffusion')\n",
    "                split_everywhere = gr.Radio(['True', 'False'], label='Split everywhere or not', info='Split everywhere or not', visible=True)\n",
    "                fill_value_setting = gr.Radio(severe_dict.keys(), label='Fill value setting', info='Fill value setting', visible=True)\n",
    "                num_ellipse = gr.Textbox(placeholder=\"How many ellipses do you want to draw?\",label=\"Number of ellipses\")\n",
    "                print(type(scheduler_select), scheduler_select)\n",
    "                with gr.Accordion(\"Advanced options\", open=False):\n",
    "                    prompt = gr.Textbox(label=\"Prompt\", value='')\n",
    "                    # num_samples = gr.Slider(label=\"Images\", minimum=1, maximum=12, value=1, step=1)\n",
    "                    image_resolution = gr.Slider(label=\"Image Resolution\", minimum=256, maximum=768, value=512, step=64)\n",
    "                    strength = gr.Slider(label=\"Control Strength\", minimum=0.0, maximum=5.0, value=1.0, step=0.01)\n",
    "                    # guess_mode = gr.Checkbox(label='Guess Mode', value=False)\n",
    "                    # detect_resolution = gr.Slider(label=\"Depth Resolution\", minimum=128, maximum=1024, value=384, step=1)\n",
    "                    inference_steps = gr.Slider(label=\"Steps\", minimum=1, maximum=100, value=20, step=1)\n",
    "                    scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1)\n",
    "                    seed = gr.Slider(label=\"Seed\", minimum=-1, maximum=7000, step=1, randomize=False, value=2024)\n",
    "                    \n",
    "                    # eta = gr.Number(label=\"eta (DDIM)\", value=0.0)\n",
    "                    # a_prompt = gr.Textbox(label=\"Added Prompt\", value='best quality, extremely detailed')\n",
    "                    # n_prompt = gr.Textbox(label=\"Negative Prompt\",\n",
    "                    #                     value='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality')\n",
    "                run_button = gr.Button()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                result_gallery_seg_members = gr.Gallery(label='Output segmented members', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # result_gallery_depth = gr.Gallery(label='Output depth & Generated image', show_label=True, elem_id=\"gallery\", height='auto')\n",
    "                # gr.Interface(\n",
    "                # fn=show_image, \n",
    "                # inputs=[org_image_pil, ],  # 原图， \n",
    "                # outputs=[gr.Image(type=\"pil\", label='Depth inference'),\n",
    "                #         gr.Image(type=\"pil\", label='Generated image'),\n",
    "                #         ],\n",
    "                #         title=\"For test images\",)\n",
    "                # result_gallery_final = gr.Gallery(label='Generated image', show_label=False, elem_id=\"gallery\", height='auto')\n",
    "        inputs = [org_image_pil, prompt, image_resolution, scheduler_select, inference_steps,scale, seed, split_everywhere, fill_value_setting, num_ellipse]\n",
    "        run_button.click(fn=show_image_members_seg, inputs=inputs, outputs=[result_gallery_seg_members])\n",
    "\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                \n",
    "                gr.Examples(\n",
    "                label='Example: Original image',\n",
    "                examples=examples,\n",
    "                inputs=inputs[0],\n",
    "                outputs=[result_gallery_depth],\n",
    "                fn=show_image,\n",
    "                cache_examples=CACHE_EXAMPLES,\n",
    "                )\n",
    "                # gr.Examples(\n",
    "                # label='Example: Masked corrosion with background',\n",
    "                # examples=examples_mask,\n",
    "                # inputs=inputs[1],\n",
    "                # outputs=[result_gallery_depth],\n",
    "                # fn=show_image,\n",
    "                # cache_examples=CACHE_EXAMPLES,\n",
    "                # )\n",
    "# MCD.launch(share=True)\n",
    "MCD.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数组a中出现最多的元素的值是: 1, 5 1\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from collections import Counter  \n",
    "  \n",
    "# 定义数组  \n",
    "a = np.array([[[1, 2, 3], [1, 2, 1], [1, 1, 3]]])  \n",
    "  \n",
    "# 将数组展平成一维数组  \n",
    "flattened_a = a.flatten()  \n",
    "  \n",
    "# 使用Counter统计每个元素出现的次数  \n",
    "counter = Counter(flattened_a)  \n",
    "  \n",
    "# 找到出现次数最多的元素及其值  \n",
    "most_common_element, count = counter.most_common(1)[0]  \n",
    "  \n",
    "print(f\"数组a中出现最多的元素的值是: {most_common_element}, {count}\", str(most_common_element.tolist()))\n",
    "print(type(most_common_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, numpy.int64, int)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c = np.array([1,2,5,9,9,9,3])\n",
    "d = np.argmax(np.bincount(c))\n",
    "d, type(d), type(d.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4, 9, 3],\n",
      "         [0, 3, 9],\n",
      "         [7, 3, 7]],\n",
      "\n",
      "        [[3, 1, 6],\n",
      "         [6, 9, 8],\n",
      "         [6, 6, 8]]]) tensor([[0, 1, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 1, 1]]) tensor([[[13, 12, 13],\n",
      "         [14, 14, 13],\n",
      "         [11, 12, 12]],\n",
      "\n",
      "        [[12, 12, 11],\n",
      "         [12, 11, 14],\n",
      "         [11, 14, 12]]]) tensor([[[0, 1, 1],\n",
      "         [0, 0, 1],\n",
      "         [0, 1, 1]],\n",
      "\n",
      "        [[0, 1, 1],\n",
      "         [0, 0, 1],\n",
      "         [0, 1, 1]]])\n",
      "tensor([[[ 4, 12, 13],\n",
      "         [ 0,  3, 13],\n",
      "         [ 7, 12, 12]],\n",
      "\n",
      "        [[ 3, 12, 11],\n",
      "         [ 6,  9, 14],\n",
      "         [ 6, 14, 12]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "a = torch.randint(0, 10, (2, 3, 3))\n",
    "c = torch.randint(11, 15, (2, 3, 3))\n",
    "b = torch.randint(0, 2, ( 3, 3))\n",
    "d = b.repeat(2,1,1)\n",
    "print(a,b,c,d)\n",
    "a[b.repeat(2,1,1)!=0] = c[b.repeat(2,1,1)!=0]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n",
      "(1, 3, 512, 512)\n",
      "onnx预测时间： 0.15800142288208008\n",
      "(1, 12, 512, 512) <class 'numpy.ndarray'>\n",
      "torch.Size([1, 512, 512])\n",
      "[0 1 2 5 6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "# File      :onnx_infer.py.py\n",
    "# Date      :2023/9/14 下午8:27\n",
    "# Author    :konglx\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "# from dataset.semi import normalize\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import imgviz\n",
    "\n",
    "\n",
    "def normalize(img, mask=None):\n",
    "    img = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])(img)\n",
    "    if mask is not None:\n",
    "        mask = torch.from_numpy(np.array(mask)).long()\n",
    "        return img, mask\n",
    "    return img\n",
    "\n",
    "\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # onnx_dir = '/home/ubunto/Project/konglx/seg/UniMatch-main/demo.onnx'\n",
    "    onnx_dir = '/home/ubunto/Project/konglx/seg/UniMatch-main/resnet101_se_rand_cut_element.onnx'\n",
    "    img_num = '00000'#'3__1__2772___0'#'00003'#'00002'#'00012'#'1__1__1848___1848'#'00007'#'2__1__1848___924'#'00012'#'2__1__1848___924' #'12__1__924___0'#'152'#'2__1__1848___924' #'1__1__4256___924' # '1__1__3696___924'\n",
    "\n",
    "    img_dir = '/home/ubunto/Project/konglx/seg/UniMatch-main/data/open_dataset_plus_with_my_plus/JPEGImages/%s.jpg' % img_num\n",
    "\n",
    "    # img_cv2 = cv2.imread(img_dir)\n",
    "    # print(img_cv2.shape)\n",
    "    # cv2.imshow('i', img_cv2)\n",
    "    # # hwc->chw\n",
    "    # img_chw = img_cv2[:, :, ::-1].transpose((2,0,1))\n",
    "    # # continuous\n",
    "    # img_chw = np.ascontiguousarray(img_chw)\n",
    "    #\n",
    "    # print(img_chw.shape)\n",
    "    # # model = onnx.load()\n",
    "    # # cv2.imshow('j', img_chw)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    # 按照dataloader进行数据预处理！！！！！！！！！！\n",
    "    img_pil = Image.open(img_dir).convert('RGB')\n",
    "\n",
    "\n",
    "    img_input = normalize(img_pil)\n",
    "    # 对于onnx需要指定输入的shape\n",
    "    resize = transforms.Resize([512,512])\n",
    "    img_input = resize(img_input)\n",
    "    print(img_input.shape)\n",
    "    # img_tensor = torch.from_numpy(img_input).type(torch.cuda.FloatTensor)\n",
    "    img_tensor = img_input.unsqueeze(0).cuda()\n",
    "    img_np = img_tensor.detach().cpu().numpy()\n",
    "    print(img_np.shape)\n",
    "    ort_session = ort.InferenceSession(onnx_dir) # 创建一个推理session\n",
    "\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: img_np}\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "    ort_outs = ort_session.run(None, ort_inputs)[0]\n",
    "    # 通过 get_inputs()[i].name来获取输入的名称\n",
    "    end = time.time()\n",
    "    print(\"onnx预测时间：\", end-start)\n",
    "    print(ort_outs.shape,  type(ort_outs))\n",
    "    # print(ort_outs)\n",
    "\n",
    "    # 输出为4分类，即，c=4的图像，取最大的通道，合并，即为预测图像\n",
    "    # numpy转torch\n",
    "    pred = torch.from_numpy(ort_outs)\n",
    "    pred_softmax = pred.softmax(dim=1).max(dim=1)[1]\n",
    "    print(pred_softmax.shape)\n",
    "    # print(pred_softmax)\n",
    "\n",
    "    pred_np = pred_softmax.numpy()[0]\n",
    "    # 对预测的mask用colored_mask上色\n",
    "    pred_pil_np = colored_mask(pred_np)\n",
    "    pred_np_cls = np.unique(pred_pil_np)\n",
    "    print(np.unique(pred_np))\n",
    "    plt.imshow(pred_pil_np)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# 1.定义分割构件和生成椭圆的函数\n",
    "################################\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "# from dataset.semi import normalize\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import imgviz\n",
    "\n",
    "\n",
    "\n",
    "def normalize(img, mask=None):\n",
    "    img = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])(img)\n",
    "    if mask is not None:\n",
    "        mask = torch.from_numpy(np.array(mask)).long()\n",
    "        return img, mask\n",
    "    return img\n",
    "\n",
    "\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "## 分割构件\n",
    "def seg_members(onnx_dir, img_pil):\n",
    "    # 加载模型\n",
    "    img_input = normalize(img_pil)\n",
    "    # 对于onnx需要指定输入的shape\n",
    "    resize = transforms.Resize([512,512])\n",
    "    img_input = resize(img_input)\n",
    "    print(img_input.shape)\n",
    "    # img_tensor = torch.from_numpy(img_input).type(torch.cuda.FloatTensor)\n",
    "    img_tensor = img_input.unsqueeze(0).cuda()\n",
    "    img_np = img_tensor.detach().cpu().numpy()\n",
    "    print(img_np.shape)\n",
    "    ort_session = ort.InferenceSession(onnx_dir) # 创建一个推理session\n",
    "\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: img_np}\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "    ort_outs = ort_session.run(None, ort_inputs)[0]\n",
    "    # 通过 get_inputs()[i].name来获取输入的名称\n",
    "    end = time.time()\n",
    "    print(\"onnx预测时间：\", end-start)\n",
    "    print(ort_outs.shape,  type(ort_outs))\n",
    "    # print(ort_outs)\n",
    "\n",
    "    # 输出为4分类，即，c=4的图像，取最大的通道，合并，即为预测图像\n",
    "    # numpy转torch\n",
    "    pred = torch.from_numpy(ort_outs)\n",
    "    pred_softmax = pred.softmax(dim=1).max(dim=1)[1]\n",
    "    print(pred_softmax.shape)\n",
    "    # print(pred_softmax)\n",
    "\n",
    "    pred_np = pred_softmax.numpy()[0]\n",
    "    # 对预测的mask用colored_mask上色\n",
    "    pred_pil_np = colored_mask(pred_np)\n",
    "    pred_np_cls = np.unique(pred_np)\n",
    "    \n",
    "    return pred_pil_np, pred_np_cls\n",
    "\n",
    "\n",
    "###### 定义选定区域内生成若干数量的椭圆的腐蚀#######\n",
    "def generate_ellipse_to_want_area(org_img_np, generate_ellipses, fill_value, want_area = [1,4], num_ellipses=15, a_min=30, a_max=100, b_min=20, b_max=40, split_everywhere=False):\n",
    "    \"\"\"\n",
    "    generate_ellipsepolygon_to_want_area based on function 'generate_polygon'.\n",
    "\n",
    "    Args:\n",
    "        org_img_np (numpy.ndarray): The input array.\n",
    "        generate_polygon (function): generate_polygon\n",
    "        want_area_list (list or tuple, optional): A list or tuple of values to consider as the selected region.\n",
    "                                          Default is [1,4].\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A new array with the same shape as the input array,\n",
    "                       containing the generated and filled polygon.\n",
    "    \"\"\"\n",
    "    list_area_corrosion = []\n",
    "    list_area_only_corrosion = []\n",
    "    for area in want_area:\n",
    "        gen_polygon, gen_polygon_blank = generate_ellipses(arr=org_img_np, fill_value=fill_value, values=area, num_ellipses=num_ellipses, a_min=a_min, a_max=a_max, b_min=b_min, b_max=b_max, split_everywhere=split_everywhere)\n",
    "        list_area_corrosion.append(gen_polygon)\n",
    "        list_area_only_corrosion.append(gen_polygon_blank)\n",
    "    sum_area = np.sum(list_area_corrosion, axis=0)\n",
    "    sum_area_only_corrosion = np.sum(list_area_only_corrosion, axis=0)\n",
    "    return sum_area, list_area_corrosion, sum_area_only_corrosion, list_area_only_corrosion\n",
    "\n",
    "########### 定义基于numpy选择构件的函数#####\n",
    "\n",
    "def filter_array(arr, values):\n",
    "    \"\"\"\n",
    "    Filter a NumPy array to keep only the specified values.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): The input array to be filtered.\n",
    "        values (list or tuple): A list or tuple of values to keep in the filtered array.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A new array with the same shape as the input array,\n",
    "                       containing only the specified values.\n",
    "    \"\"\"\n",
    "    conditions = [arr == value for value in values]\n",
    "    condition = np.logical_or.reduce(conditions)\n",
    "    filtered_arr = np.where(condition, arr, 0)\n",
    "    return filtered_arr\n",
    "\n",
    "################### 选择腐蚀类型 ######################\n",
    "# corrosionType = [3] # 腐蚀类型： 1-fair，2-poor， 3-severe\n",
    "def corrosionType_to_fill_value(corrosionType):\n",
    "    fill_value = []\n",
    "    for i in corrosionType:\n",
    "        if i==1:\n",
    "            fill_value.append(12)\n",
    "        elif i==2:\n",
    "            fill_value.append(6)\n",
    "        elif i==3:\n",
    "            fill_value.append(4)\n",
    "    return fill_value\n",
    "\n",
    "# fill_value_list = corrosionType_to_fill_value(corrosionType=corrosionType) # 以12为总数量，fill_value与corrosionType对应：腐蚀类型： 1-fair对应12/12，2-poor对应12/6， 3-severe对应12/4\n",
    "\n",
    "\n",
    "################### 定义和生成椭圆 ######################\n",
    "def generate_ellipses(arr, fill_value=1, values=[5], num_ellipses=5, a_min=30, a_max=120, b_min=10, b_max=80, split_everywhere=True):\n",
    "    \"\"\"\n",
    "    🕐用少数量的大椭圆，模拟大片的腐蚀；\n",
    "    🕑用多数量的小椭圆，模拟pitting corrosion\n",
    "    Generate random quadrilaterals within the specified regions of a NumPy array\n",
    "    and fill them with a specified value.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): The input array.\n",
    "        num_polygons (int): The number of quadrilaterals to generate.\n",
    "        fill_value (int, optional): The value to use for filling the quadrilaterals. Default is 1.\n",
    "        values (list or tuple, optional): A list or tuple of values to consider as the selected region.\n",
    "                                          Default is [1].\n",
    "\n",
    "    Returns:\n",
    "        tuple(numpy.ndarray): A new array with the same shape as the input array,\n",
    "                       containing the generated and filled quadrilaterals.\n",
    "    \"\"\"\n",
    "    \n",
    "    selected_region = np.isin(arr, values)\n",
    "    # print(selected_region)\n",
    "    selected_coords = np.argwhere(selected_region)\n",
    "    print('可选的坐标点数：',len(selected_coords))\n",
    "    # # 椭圆数量和范围\n",
    "    # num_ellipses = 5\n",
    "    # a_min, a_max = 20, 50\n",
    "    # b_min, b_max = 10, 30\n",
    "    \n",
    "    result = arr.copy()\n",
    "    image = Image.fromarray(result)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # 空白mask\n",
    "    result_blank = np.zeros_like(result)\n",
    "    # print(result_blank)\n",
    "    image_blank = Image.fromarray(result_blank)\n",
    "    draw_blank = ImageDraw.Draw(image_blank)\n",
    "    # # 生成图片\n",
    "    # im = Image.new('RGB', (100,100), color='white')  \n",
    "    # draw = ImageDraw.Draw(im)\n",
    "    if split_everywhere:\n",
    "        for i in range(num_ellipses):\n",
    "            xy_arr = random.sample(list(selected_coords), k=1)\n",
    "            # print(random.sample(list(selected_coords), k=2), random.sample(list(selected_coords), k=3))\n",
    "            print(xy_arr[0][0])\n",
    "            y, x = xy_arr[0][0], xy_arr[0][1]\n",
    "            # 随机生成长短半轴\n",
    "            a = random.randint(a_min, a_max)\n",
    "            b = random.randint(b_min, b_max)\n",
    "            \n",
    "            # 随机中心点\n",
    "            # x = random.randint(0, 100-a)\n",
    "            # y = random.randint(0, 100-b)\n",
    "            \n",
    "            # 绘制椭圆\n",
    "            draw.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "            draw_blank.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "        \n",
    "        result = np.array(image)\n",
    "        result_mask = np.array(image_blank)\n",
    "    else:\n",
    "        selected_coords_with_according_to_num_ellipses_list = []\n",
    "        xy_arr_0 = random.sample(list(selected_coords), k=1)[0]\n",
    "        selected_coords_with_according_to_num_ellipses_list.append(xy_arr_0)\n",
    "        count_num = 0\n",
    "        for i in list(selected_coords):\n",
    "            dist = ((i[0]-xy_arr_0[0])**2 + (i[1]-xy_arr_0[1])**2)**0.5\n",
    "            if dist<= (a_max + b_max):\n",
    "                selected_coords_with_according_to_num_ellipses_list.append(i)\n",
    "                xy_arr_0 = i\n",
    "                count_num += 1\n",
    "                # print(count_num)\n",
    "                # print('a')\n",
    "                if count_num == num_ellipses*3:\n",
    "                    break\n",
    "            \n",
    "        \n",
    "        # selected_coords_with_according_to_num_ellipses_np = np.array(selected_coords_with_according_to_num_ellipses_list)\n",
    "        for i in range(num_ellipses):\n",
    "            xy_arr = random.sample(selected_coords_with_according_to_num_ellipses_list, k=1)\n",
    "            # print(random.sample(list(selected_coords), k=2), random.sample(list(selected_coords), k=3))\n",
    "            # print(xy_arr[0][0])\n",
    "            y, x = xy_arr[0][0], xy_arr[0][1]\n",
    "            # 随机生成长短半轴\n",
    "            a = random.randint(a_min, a_max)\n",
    "            b = random.randint(b_min, b_max)\n",
    "            \n",
    "            # 随机中心点\n",
    "            # x = random.randint(0, 100-a)\n",
    "            # y = random.randint(0, 100-b)\n",
    "            \n",
    "            # 绘制椭圆\n",
    "            draw.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "            draw_blank.ellipse((x, y, x+a, y+b), fill=fill_value)\n",
    "        \n",
    "        result = np.array(image)\n",
    "        result_mask = np.array(image_blank)\n",
    "\n",
    "            \n",
    "    \n",
    "    return result, result_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n",
      "(1, 3, 512, 512)\n",
      "onnx预测时间： 0.1539468765258789\n",
      "(1, 12, 512, 512) <class 'numpy.ndarray'>\n",
      "torch.Size([1, 512, 512])\n",
      "[[5 5 5 ... 2 2 2]\n",
      " [5 5 5 ... 2 2 2]\n",
      " [5 5 5 ... 2 2 2]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] [0 1 2 5 6]\n",
      "[2]\n",
      "可选的坐标点数： 30226\n",
      "0 3 [0 3] uint64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_106182/1195477243.py:38: RuntimeWarning: divide by zero encountered in divide\n",
      "  mask_only_corrosion_corr_to_members_devide_by_fill_value = (12/mask_only_corrosion_corr_to_members).astype((np.uint64))\n",
      "/tmp/ipykernel_106182/1195477243.py:38: RuntimeWarning: invalid value encountered in cast\n",
      "  mask_only_corrosion_corr_to_members_devide_by_fill_value = (12/mask_only_corrosion_corr_to_members).astype((np.uint64))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################\n",
    "# 2.使用\n",
    "################################\n",
    "\n",
    "img_num = '00000'#'3__1__2772___0'#'00003'#'00002'#'00012'#'1__1__1848___1848'#'00007'#'2__1__1848___924'#'00012'#'2__1__1848___924' #'12__1__924___0'#'152'#'2__1__1848___924' #'1__1__4256___924' # '1__1__3696___924'\n",
    "\n",
    "img_dir = '/home/ubunto/Project/konglx/seg/UniMatch-main/data/open_dataset_plus_with_my_plus/JPEGImages/%s.jpg' % img_num\n",
    "img_pil = Image.open(img_dir)\n",
    "\n",
    "pred_pil, pred_np_cls = seg_members(onnx_dir='/home/ubunto/Project/konglx/seg/UniMatch-main/resnet101_se_rand_cut_element.onnx', \n",
    "                                       img_pil=img_pil)\n",
    "print(np.array(pred_pil), pred_np_cls)\n",
    "\n",
    "## 超参数 ##\n",
    "# corrosionType = [3] # 腐蚀类型： 1-fair，2-poor， 3-severe\n",
    "seed = 1\n",
    "split_everywhere = False\n",
    "fill_value_setting = 4 # 以12 为填充数据，与memberstype分开，而后再通过corrosionType_to_fill_value返回对应corrosionType\n",
    "                        # 以12为总数量，fill_value与corrosionType对应：腐蚀类型： fill_value_setting=12:  1-fair对应12/fill_value_setting，\n",
    "                        #                                                    fill_value_setting=6:   2-poor对应12/fill_value_setting， \n",
    "                        #                                                    fill_value_setting=4:   3-severe对应12/fill_value_setting\n",
    "# 基于预测的类别选择区域\n",
    "\n",
    "# 定义numpy的随机模式\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "mask_members_np_mode_R = np.array(pred_pil)\n",
    "select_area_list = [np.random.choice(pred_np_cls[1:])]\n",
    "print(select_area_list)\n",
    "# 选择构件区域\n",
    "mask_members_np_mode_R_filter = filter_array(mask_members_np_mode_R, select_area_list)\n",
    "# 4.在members指定区域生成任意数量的腐蚀，返回仅仅为腐蚀区域 （生成用）\n",
    "mask_corrosion_corr_to_members, mask_corrosion_corr_to_members_list, mask_only_corrosion_corr_to_members, mask_only_corrosion_corr_to_members_list = generate_ellipse_to_want_area(org_img_np=mask_members_np_mode_R, generate_ellipses=generate_ellipses, fill_value=fill_value_setting, want_area=select_area_list, split_everywhere=split_everywhere)\n",
    "plt.imshow(mask_corrosion_corr_to_members)\n",
    "\n",
    "# mask_only_corrosion_corr_to_members_devide_by_fill_value = (mask_only_corrosion_corr_to_members/fill_value_setting).astype((np.uint64))\n",
    "mask_only_corrosion_corr_to_members_devide_by_fill_value = (12/mask_only_corrosion_corr_to_members).astype((np.uint64))\n",
    "print(mask_only_corrosion_corr_to_members_devide_by_fill_value.min(), mask_only_corrosion_corr_to_members_devide_by_fill_value.max(), np.unique(mask_only_corrosion_corr_to_members_devide_by_fill_value), mask_only_corrosion_corr_to_members_devide_by_fill_value.dtype)\n",
    "# print(np.unique(mask_only_corrosion_corr_to_members/12), mask_only_corrosion_corr_to_members.dtype, ((mask_only_corrosion_corr_to_members/12).astype(np.uint64)).dtype)\n",
    "\n",
    "mask_only_corrosion_final_pil = colored_mask(mask_only_corrosion_corr_to_members_devide_by_fill_value)\n",
    "# plt.imshow(mask_only_corrosion_final_pil) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rgb(128, 0, 0)', 'rgb(0, 128, 0)', 'rgb(128, 128, 0)']\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******type(im_in), im_in.shape,im:****** <class 'numpy.ndarray'> (512, 512, 3) {'background': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)}\n",
      " shape:(512, 512, 3), ndim:3, size:786432\n",
      "im {'background': array([[[137, 144, 155, 255],\n",
      "        [138, 145, 156, 255],\n",
      "        [139, 146, 158, 255],\n",
      "        ...,\n",
      "        [ 79,  81,  80, 255],\n",
      "        [ 75,  78,  77, 255],\n",
      "        [ 72,  74,  73, 255]],\n",
      "\n",
      "       [[133, 141, 152, 255],\n",
      "        [135, 142, 153, 255],\n",
      "        [137, 144, 155, 255],\n",
      "        ...,\n",
      "        [ 82,  85,  84, 255],\n",
      "        [ 79,  81,  80, 255],\n",
      "        [ 75,  78,  77, 255]],\n",
      "\n",
      "       [[133, 141, 152, 255],\n",
      "        [135, 142, 153, 255],\n",
      "        [136, 143, 154, 255],\n",
      "        ...,\n",
      "        [ 86,  88,  87, 255],\n",
      "        [ 82,  85,  84, 255],\n",
      "        [ 79,  81,  80, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[205, 201, 193, 255],\n",
      "        [207, 204, 196, 255],\n",
      "        [214, 211, 203, 255],\n",
      "        ...,\n",
      "        [223, 231, 237, 255],\n",
      "        [230, 238, 244, 255],\n",
      "        [233, 242, 246, 255]],\n",
      "\n",
      "       [[205, 201, 193, 255],\n",
      "        [214, 211, 203, 255],\n",
      "        [221, 218, 210, 255],\n",
      "        ...,\n",
      "        [230, 238, 244, 255],\n",
      "        [231, 239, 246, 255],\n",
      "        [232, 240, 247, 255]],\n",
      "\n",
      "       [[221, 218, 210, 255],\n",
      "        [230, 227, 219, 255],\n",
      "        [230, 227, 219, 255],\n",
      "        ...,\n",
      "        [240, 249, 255, 255],\n",
      "        [239, 247, 254, 255],\n",
      "        [238, 246, 253, 255]]], dtype=uint8), 'layers': [], 'composite': array([[[137, 144, 155, 255],\n",
      "        [138, 145, 156, 255],\n",
      "        [139, 146, 158, 255],\n",
      "        ...,\n",
      "        [ 79,  81,  80, 255],\n",
      "        [ 75,  78,  77, 255],\n",
      "        [ 72,  74,  73, 255]],\n",
      "\n",
      "       [[133, 141, 152, 255],\n",
      "        [135, 142, 153, 255],\n",
      "        [137, 144, 155, 255],\n",
      "        ...,\n",
      "        [ 82,  85,  84, 255],\n",
      "        [ 79,  81,  80, 255],\n",
      "        [ 75,  78,  77, 255]],\n",
      "\n",
      "       [[133, 141, 152, 255],\n",
      "        [135, 142, 153, 255],\n",
      "        [136, 143, 154, 255],\n",
      "        ...,\n",
      "        [ 86,  88,  87, 255],\n",
      "        [ 82,  85,  84, 255],\n",
      "        [ 79,  81,  80, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[205, 201, 193, 255],\n",
      "        [207, 204, 196, 255],\n",
      "        [214, 211, 203, 255],\n",
      "        ...,\n",
      "        [223, 231, 237, 255],\n",
      "        [230, 238, 244, 255],\n",
      "        [233, 242, 246, 255]],\n",
      "\n",
      "       [[205, 201, 193, 255],\n",
      "        [214, 211, 203, 255],\n",
      "        [221, 218, 210, 255],\n",
      "        ...,\n",
      "        [230, 238, 244, 255],\n",
      "        [231, 239, 246, 255],\n",
      "        [232, 240, 247, 255]],\n",
      "\n",
      "       [[221, 218, 210, 255],\n",
      "        [230, 227, 219, 255],\n",
      "        [230, 227, 219, 255],\n",
      "        ...,\n",
      "        [240, 249, 255, 255],\n",
      "        [239, 247, 254, 255],\n",
      "        [238, 246, 253, 255]]], dtype=uint8)}\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "# from gradio import Brush\n",
    "import time\n",
    "import imgviz\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "brush_colors = gr.Brush()\n",
    "brush_colors.colors=[\n",
    "                \"rgb(128, 0, 0)\",\n",
    "                \"rgb(0, 128, 0)\",\n",
    "                \"rgb(128, 128, 0)\"]\n",
    "# print()\n",
    "print(brush_colors.colors\n",
    "                # format=\"png\",\n",
    "                )\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "\n",
    "\n",
    "def sleep(im):\n",
    "    # time.sleep(5)\n",
    "    # return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1],im[\"composite\"]]\n",
    "    print('im', im)\n",
    "    if len(im[\"layers\"]) == 0:\n",
    "        im[\"layers\"].append(np.zeros((512, 512, 4), np.uint8))\n",
    "    # im[\"layers\"][0]=cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB )\n",
    "    return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    " \n",
    "def upim(im_in,im):\n",
    "    # print(type(im_in), im)\n",
    "    print('******type(im_in), im_in.shape,im:******', type(im_in), im_in.shape,im)#, type(im), im)\n",
    "    # if len(im[\"layers\"]) == 0:\n",
    "    #     im[\"layers\"]=im[\"layers\"].append(np.zeros((512, 512, 4), np.uint8))\n",
    "    height, width, channels = im_in.shape[:3]\n",
    "    im[\"background\"]=im_in\n",
    "    im[\"layers\"][0]=np.zeros((height, width, 4), np.uint8)\n",
    "    #im[\"layers\"][1]=None\n",
    "\n",
    "    print(f\" shape:{im_in.shape}, ndim:{im_in.ndim}, size:{im_in.size}\")\n",
    "    return gr.ImageMask(value=im,height=600,width=600)\n",
    "\n",
    "\n",
    "def saveimg(im):\n",
    "    #print(im[\"layers\"][0])\n",
    "    background=im[\"background\"]\n",
    "    composite=im[\"composite\"]\n",
    "    background=cv2.cvtColor(background, cv2.COLOR_BGR2RGB )\n",
    "    composite=cv2.cvtColor(composite, cv2.COLOR_BGR2RGB )\n",
    "    img_layer = cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"layers0.png\",img_layer)\n",
    "    cv2.imwrite(\"background.png\",background)\n",
    "    cv2.imwrite(\"composite.png\",composite)\n",
    "    return gr.ImageMask(value=im,height=600,width=600), background\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Column():\n",
    "        with gr.Row():\n",
    "            org_img = gr.Image(type=\"numpy\", label=\"Original Image\")\n",
    "            \n",
    "            im = gr.ImageEditor(\n",
    "                type=\"numpy\",\n",
    "                crop_size=\"1:1\",\n",
    "                height=512,\n",
    "                width=512,\n",
    "                brush=brush_colors,\n",
    "            )\n",
    "    \n",
    "    with gr.Row():\n",
    "        \n",
    "        uploadbtn = gr.Button(\"image upload\")\n",
    "        savebtn = gr.Button(\"save\")\n",
    "        uploadbtn.click(upim,[org_img,im],[im])\n",
    "    \n",
    "    # im =gr.Sketchpad(type=\"pil\",\n",
    "    #     crop_size=\"1:1\",)\n",
    " \n",
    "    with gr.Column():\n",
    "        with gr.Row():\n",
    "            im_out_1 = gr.Image(type=\"numpy\")\n",
    "            im_out_2 = gr.Image(type=\"numpy\")\n",
    "            im_out_3 = gr.Image(type=\"numpy\")\n",
    "            # im_out_4 = gr.Image(type=\"numpy\")\n",
    " \n",
    "    btn = gr.Button()\n",
    "    im.change(sleep, outputs=[im_out_1, im_out_2, im_out_3], inputs=im)\n",
    "    savebtn.click(saveimg, outputs=[im, im_out_2], inputs=im)\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rgb(128, 0, 0)', 'rgb(0, 128, 0)', 'rgb(128, 128, 0)']\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> {'background': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8), 'layers': [array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)], 'composite': array([[[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]], dtype=uint8)}\n",
      " shape:(512, 512, 3), ndim:3, size:786432\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "# from gradio import Brush\n",
    "import time\n",
    "import imgviz\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "brush_colors = gr.Brush()\n",
    "brush_colors.colors=[\n",
    "                \"rgb(128, 0, 0)\",\n",
    "                \"rgb(0, 128, 0)\",\n",
    "                \"rgb(128, 128, 0)\"]\n",
    "# print()\n",
    "print(brush_colors.colors\n",
    "                # format=\"png\",\n",
    "                )\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil\n",
    "\n",
    "\n",
    "\n",
    "def sleep(im):\n",
    "    # time.sleep(5)\n",
    "    # return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1],im[\"composite\"]]\n",
    "    return [im[\"background\"], im[\"layers\"][0],im[\"composite\"]]\n",
    " \n",
    "def upim(im_in,im):\n",
    "    print(type(im_in), im)\n",
    "    height, width, channels = im_in.shape[:3]\n",
    "    im[\"background\"]=im_in\n",
    "    im[\"layers\"][0]=np.zeros((height, width, 4), np.uint8)\n",
    "    #im[\"layers\"][1]=None\n",
    "\n",
    "    print(f\" shape:{im_in.shape}, ndim:{im_in.ndim}, size:{im_in.size}\")\n",
    "    return gr.ImageMask(value=im,height=600)\n",
    "\n",
    "\n",
    "def saveimg(im):\n",
    "    #print(im[\"layers\"][0])\n",
    "    background=im[\"background\"]\n",
    "    composite=im[\"composite\"]\n",
    "    background=cv2.cvtColor(background, cv2.COLOR_BGR2RGB )\n",
    "    composite=cv2.cvtColor(composite, cv2.COLOR_BGR2RGB )\n",
    "    img_layer = cv2.cvtColor(im[\"layers\"][0], cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"layers0.png\",img_layer)\n",
    "    cv2.imwrite(\"background.png\",background)\n",
    "    cv2.imwrite(\"composite.png\",composite)\n",
    "    return gr.ImageMask(value=im,height=600), background\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Column():\n",
    "        with gr.Row():\n",
    "            org_img = gr.Image(type=\"numpy\", label=\"Original Image\")\n",
    "            \n",
    "            im = gr.ImageEditor(\n",
    "                type=\"numpy\",\n",
    "                crop_size=\"1:1\",\n",
    "                height=512,\n",
    "                width=512,\n",
    "                brush=brush_colors,\n",
    "            )\n",
    "    \n",
    "    with gr.Row():\n",
    "        \n",
    "        uploadbtn = gr.Button(\"image upload\")\n",
    "        savebtn = gr.Button(\"save\")\n",
    "        uploadbtn.click(upim,[org_img,im],[im])\n",
    "    \n",
    "    # im =gr.Sketchpad(type=\"pil\",\n",
    "    #     crop_size=\"1:1\",)\n",
    " \n",
    "    with gr.Column():\n",
    "        with gr.Row():\n",
    "            im_out_1 = gr.Image(type=\"numpy\")\n",
    "            im_out_2 = gr.Image(type=\"numpy\")\n",
    "            im_out_3 = gr.Image(type=\"numpy\")\n",
    "            # im_out_4 = gr.Image(type=\"numpy\")\n",
    " \n",
    "    btn = gr.Button()\n",
    "    im.change(sleep, outputs=[im_out_1, im_out_2, im_out_3], inputs=im)\n",
    "    savebtn.click(saveimg, outputs=[im, im_out_2], inputs=im)\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/gradio/utils.py:1002: UserWarning: Expected 1 arguments for function <function <lambda> at 0x7f65941664c0>, received 0.\n",
      "  warnings.warn(\n",
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/gradio/utils.py:1006: UserWarning: Expected at least 1 arguments for function <function <lambda> at 0x7f65941664c0>, received 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"1024\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubunto/software/miniconda3/envs/dif/lib/python3.9/site-packages/gradio/helpers.py:978: UserWarning: Unexpected argument. Filling with None.\n",
      "  warnings.warn(\"Unexpected argument. Filling with None.\")\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "\n",
    "brush_colors = gr.Brush()\n",
    "brush_colors.colors=[\n",
    "                \"rgb(128, 0, 0)\",\n",
    "                \"rgb(0, 128, 0)\",\n",
    "                \"rgb(128, 128, 0)\"]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    img = gr.ImageEditor(\n",
    "        brush=gr.Brush(\n",
    "            # default_color=\"rgb(200, 200, 200)\",\n",
    "            colors=brush_colors.colors,\n",
    "            color_mode=\"fixed\",\n",
    "\n",
    "        ),\n",
    "        interactive=True,\n",
    "        height=512,\n",
    "        width=512,\n",
    "    )\n",
    "\n",
    "    change_color = gr.Button(\n",
    "        value=\"Change color\",\n",
    "    )\n",
    "\n",
    "    change_color.click(\n",
    "        fn=lambda brush_colors:  gr.update(\n",
    "            brush=brush_colors\n",
    "        ),\n",
    "        inputs=None,\n",
    "        outputs=img,\n",
    "    )\n",
    "    \n",
    "    # change_color.click(\n",
    "    #     fn=lambda: gr.update(\n",
    "    #         brush=gr.Brush(colors=[\"rgb(128, 0, 0)\", \"rgb(200, 200, 255)\"], color_mode=\"fixed\")\n",
    "    #     ),\n",
    "    #     inputs=None,\n",
    "    #     outputs=img,\n",
    "    # )\n",
    "\n",
    "demo.launch(height=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  50 204]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_dir = '/home/ubunto/Project/konglx/generate/diffusers/UI/layers0.png'\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the layer image\n",
    "layer_img = Image.open(layer_dir)\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "layer_arr = np.array(layer_img)\n",
    "print(np.unique(layer_arr))\n",
    "# Plot the image\n",
    "plt.imshow(layer_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:8044\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:8044/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      " shape:(512, 512, 3), ndim:3, size:786432\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def saveimg(im):\n",
    "    #print(im[\"layers\"][0])\n",
    "    background=im[\"background\"]\n",
    "    composite=im[\"composite\"]\n",
    "    background=cv2.cvtColor(background, cv2.COLOR_BGR2RGB )\n",
    "    composite=cv2.cvtColor(composite, cv2.COLOR_BGR2RGB )\n",
    "    cv2.imwrite(\"layers0.png\",im[\"layers\"][0])\n",
    "    cv2.imwrite(\"background.png\",background)\n",
    "    cv2.imwrite(\"composite.png\",composite)\n",
    "    return gr.ImageMask(value=im,height=600), background\n",
    "\n",
    "def loadimg(im):\n",
    "    layers0=cv2.imread(\"layers0.png\",-1)\n",
    "    background=cv2.imread(\"background.png\")\n",
    "    composite=cv2.imread(\"composite.png\")\n",
    "    #layers0=cv2.cvtColor(layers0, cv2.COLOR_RGB2BGR, cv2.IMREAD_UNCHANGED )\n",
    "    background=cv2.cvtColor(background, cv2.COLOR_RGB2BGR )\n",
    "    composite=cv2.cvtColor(composite, cv2.COLOR_RGB2BGR )\n",
    "    \n",
    "    im[\"layers\"][0]=layers0\n",
    "    im[\"background\"]=background\n",
    "    im[\"composite\"]=composite\n",
    "    return gr.ImageMask(value=im,height=600), background\n",
    "\n",
    "def upim(im_in,im):\n",
    "    print(type(im_in))\n",
    "    height, width, channels = im_in.shape[:3]\n",
    "    im[\"background\"]=im_in\n",
    "    im[\"layers\"][0]=np.zeros((height, width, 4), np.uint8)\n",
    "    #im[\"layers\"][1]=None\n",
    "\n",
    "    print(f\" shape:{im_in.shape}, ndim:{im_in.ndim}, size:{im_in.size}\")\n",
    "    return gr.ImageMask(value=im,height=600)\n",
    "def getmask(im):\n",
    "    im.save(\"i.png\")\n",
    "    #dst = Image.new('RGBA', (im.width + o_img.width, im.height))\n",
    "    \n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(\"カウント\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                im_in = gr.Image(sources=\"upload\")\n",
    "                uploadbtn = gr.Button(\"image upload\")\n",
    "            with gr.Column():    \n",
    "                with gr.Row():\n",
    "                    im = gr.ImageMask(height=600)\n",
    "                with gr.Row():\n",
    "                    savebtn = gr.Button(\"save\")\n",
    "                    loadbtn = gr.Button(\"load\")\n",
    "                with gr.Accordion():\n",
    "                    with gr.Row():\n",
    "                        im2 = gr.Image(height=600)\n",
    "            uploadbtn.click(upim,[im_in,im],[im])\n",
    "            savebtn.click(saveimg, outputs=[im, im2], inputs=im)\n",
    "            \n",
    "            loadbtn.click(loadimg, outputs=[im, im2], inputs=im)\n",
    "    with gr.Tab(\"症例一覧\"):\n",
    "        with gr.Row():\n",
    "            im3 = gr.Image(height=600)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.queue()\n",
    "    demo.launch(server_name=\"0.0.0.0\",server_port=8044, root_path=\"/8044\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
